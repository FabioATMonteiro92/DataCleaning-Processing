{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f5509bc",
   "metadata": {},
   "source": [
    "This is a data pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf633239",
   "metadata": {},
   "source": [
    "# 0 - Imports librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8e338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 - Generates DB with data that was used to screen whetehr participants met the inclusion/exclusion criteria to participate in the study.\n",
    "##Imports libraries\n",
    "import pandas as pd\n",
    "import os, datetime\n",
    "from pathlib import Path\n",
    "from datetime import timedelta, datetime\n",
    "import time, re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce803a0",
   "metadata": {},
   "source": [
    "# 1. Screening database\n",
    "Generates DB with data that was used to screen whetehr participants met the inclusion/exclusion criteria to participate in the study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d35945",
   "metadata": {},
   "source": [
    "## 1.1. Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c469270a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Opens the excel file where data from participants are stored.\n",
    "# Go up one folder (from /notebook to project root)\n",
    "PROJ_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "# Build the path safely\n",
    "excel_part_data_path = PROJ_ROOT / \"Screening_Data\" / \"data.xlsx\"\n",
    "\n",
    "# Read the Excel file\n",
    "df_excel_Screening = pd.read_excel(excel_part_data_path)\n",
    "##Drops redundant columns (empty columns regarding Q1,Q7,Q14,Q15) in the dataframe df_excel_Screening.\n",
    "df_excel_Screening.drop(df_excel_Screening.columns[[33, *range(104,108)]], axis=1, inplace=True)\n",
    "df_excel_Screening.columns = [\n",
    "    'subject_nr', 'Idade', 'Sexo', 'Nacionalidade', 'FreqEnsSup',\n",
    "    'CicloEstudosEnsSup_1','CicloEstudosEnsSup_2','CicloEstudosEnsSup_3','CicloEstudosEnsSup_4',\n",
    "    'HabAcademicas_1','HabAcademicas_2','HabAcademicas_3','HabAcademicas_4','HabAcademicas_5','HabAcademicas_6',\n",
    "    'Curso','SituacaoLaboral','SituacaoLaboralTurnos_1','SituacaoLaboralTurnos_2',\n",
    "    'PresencaDoencasAnter','ListaDoencasAnter','MedicacaoPsicotropica','ListaMedicacaoPsicotropica',\n",
    "    'Fumador','NrCigarros','ProdutosSessaoTabagica_1','ProdutosSessaoTabagica_2',\n",
    "    'ConsomeCafeina','QuantidadeDiaCafeina','ConsomeAlcool','QuantidadeDiaAlcool','ConsomeDrogas','Viagens',\n",
    "    'Pergunta1','Pergunta2','Pergunta3','Pergunta4','Pergunta5','Pergunta6','Pergunta7','Pergunta8',\n",
    "    'Pergunta9','Pergunta10','Pergunta11','Pergunta12','Pergunta13','Pergunta14','Pergunta15','Pergunta16',\n",
    "    'MEQscore',\n",
    "    *[f'BSI:{i}' for i in range(1,54)],\n",
    "    'TIME_start','TIME_end','TIME_total'\n",
    "]\n",
    "\n",
    "df_excel_Screening.sort_values(by='TIME_end', kind='mergesort', ascending=True, inplace=True)\n",
    "df_excel_Screening.reset_index(drop=True, inplace=True)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)  \n",
    "df_excel_Screening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a11a62",
   "metadata": {},
   "source": [
    "## 1.2. Replacing values in multiple columns by values that make more sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0c81d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel_Screening[['Pergunta1', 'Pergunta7','Pergunta14','Pergunta15','Sexo','Nacionalidade','FreqEnsSup','CicloEstudosEnsSup_1','CicloEstudosEnsSup_2','CicloEstudosEnsSup_3','CicloEstudosEnsSup_4','HabAcademicas_1','HabAcademicas_2','HabAcademicas_3','HabAcademicas_4','HabAcademicas_5','HabAcademicas_6','SituacaoLaboral','SituacaoLaboralTurnos_1','SituacaoLaboralTurnos_2','PresencaDoencasAnter','MedicacaoPsicotropica','Fumador','ProdutosSessaoTabagica_1','ProdutosSessaoTabagica_2','ConsomeCafeina','ConsomeAlcool','ConsomeDrogas','Viagens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe64e491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PROJ_ROOT = Path(\"..\").resolve()\n",
    "meq_dir = PROJ_ROOT / \"Screening_Data\" / \"experiment_data\"\n",
    "\n",
    "file_to_value = {}\n",
    "for fp in sorted(meq_dir.glob(\"*.txt\")):\n",
    "    try:\n",
    "        # Plain-text read is most robust for these tiny files\n",
    "        token = fp.read_text(encoding=\"utf-8\", errors=\"ignore\").strip().split()[0]\n",
    "        file_to_value[fp.name] = int(token)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {fp.name}: {e}\")\n",
    "\n",
    "for col in ['Pergunta1','Pergunta7','Pergunta14','Pergunta15']:\n",
    "    # Map filenames in the column to their numeric value; keep original if not found\n",
    "    df_excel_Screening[col] = df_excel_Screening[col].map(file_to_value).fillna(df_excel_Screening[col])\n",
    "\n",
    "df_excel_Screening[['Pergunta1', 'Pergunta7','Pergunta14','Pergunta15']]\n",
    "\n",
    "##Replaces the integer that codes the informations in the dataframe with data from the participants with the correct label.\n",
    "for i in range(0,len(df_excel_Screening['Sexo'])):\n",
    "        if df_excel_Screening.loc[i,'Sexo'] == 1:\n",
    "            df_excel_Screening.loc[i,'Sexo'] = \"Masculino\"\n",
    "        elif df_excel_Screening.loc[i,'Sexo'] == 2:\n",
    "            df_excel_Screening.loc[i,'Sexo'] = \"Feminino\"\n",
    "        else:\n",
    "            df_excel_Screening.loc[i,'Sexo'] = \"Outro\"\n",
    "\n",
    "for i in range(0,len(df_excel_Screening['Nacionalidade'])):\n",
    "        if df_excel_Screening.loc[i,'Nacionalidade'] == 1:\n",
    "            df_excel_Screening.loc[i,'Nacionalidade'] = \"PT\"\n",
    "        else:\n",
    "            df_excel_Screening.loc[i,'Nacionalidade'] = \"Outra\"\n",
    "\n",
    "for i in range(0,len(df_excel_Screening['FreqEnsSup'])):\n",
    "        if df_excel_Screening.loc[i,'FreqEnsSup'] == 1:\n",
    "            df_excel_Screening.loc[i,'FreqEnsSup'] = \"Sim\"\n",
    "        else :\n",
    "            df_excel_Screening.loc[i,'FreqEnsSup'] = \"Não\"\n",
    "\n",
    "CicloEstudosEnsSup = []\n",
    "for i in range(0,len(df_excel_Screening['subject_nr'])):\n",
    "        indexx = 0\n",
    "        if df_excel_Screening.loc[i,'CicloEstudosEnsSup_1'] == 1:\n",
    "            aaa = \"Licenciatura\"\n",
    "            CicloEstudosEnsSup.append(aaa)\n",
    "            indexx += 1\n",
    "        elif df_excel_Screening.loc[i,'CicloEstudosEnsSup_2'] == 1:\n",
    "            aaa = \"Mestrado\"\n",
    "            CicloEstudosEnsSup.append(aaa)\n",
    "            indexx += 1\n",
    "        elif df_excel_Screening.loc[i,'CicloEstudosEnsSup_3'] == 1:\n",
    "            aaa = \"Doutoramento\"\n",
    "            CicloEstudosEnsSup.append(aaa)\n",
    "            indexx += 1\n",
    "        elif df_excel_Screening.loc[i,'CicloEstudosEnsSup_4'] == 1:\n",
    "            aaa = \"Outro Ciclo\"\n",
    "            CicloEstudosEnsSup.append(aaa)\n",
    "            indexx +=1\n",
    "        elif indexx == 0:\n",
    "            aaa = \"\"\n",
    "            CicloEstudosEnsSup.append(aaa)\n",
    "\n",
    "\n",
    "df_excel_Screening.drop(columns=['CicloEstudosEnsSup_1','CicloEstudosEnsSup_2','CicloEstudosEnsSup_3','CicloEstudosEnsSup_4'],inplace=True)\n",
    "df_excel_Screening['CicloEstudosEnsSup'] = CicloEstudosEnsSup\n",
    "TransCol = df_excel_Screening.pop('CicloEstudosEnsSup')\n",
    "df_excel_Screening.insert(5,\"CicloEstudosEnsSup\",TransCol)\n",
    "\n",
    "HabAcademicas = []\n",
    "for i in range(0,len(df_excel_Screening['subject_nr'])):\n",
    "        if df_excel_Screening.loc[i,\"FreqEnsSup\"] == \"Não\" and df_excel_Screening.loc[i,'HabAcademicas_1'] == 1:\n",
    "            aaa = \"Ensino Obrigatório\"\n",
    "            HabAcademicas.append(aaa)\n",
    "        elif df_excel_Screening.loc[i, \"FreqEnsSup\"] == \"Não\" and df_excel_Screening.loc[i,'HabAcademicas_2'] == 1:\n",
    "            aaa = \"Licenciatura\"\n",
    "            HabAcademicas.append(aaa)\n",
    "        elif df_excel_Screening.loc[i, \"FreqEnsSup\"] == \"Não\" and df_excel_Screening.loc[i,'HabAcademicas_3'] == 1:\n",
    "            aaa = \"Pós-graduação\"\n",
    "            HabAcademicas.append(aaa)\n",
    "        elif df_excel_Screening.loc[i, \"FreqEnsSup\"] == \"Não\" and df_excel_Screening.loc[i,'HabAcademicas_4'] == 1:\n",
    "            aaa = \"Mestrado\"\n",
    "            HabAcademicas.append(aaa)\n",
    "        elif df_excel_Screening.loc[i, \"FreqEnsSup\"] == \"Não\" and df_excel_Screening.loc[i,'HabAcademicas_5'] == 1:\n",
    "            aaa = \"Doutoramento\"\n",
    "            HabAcademicas.append(aaa)\n",
    "        elif df_excel_Screening.loc[i, \"FreqEnsSup\"] == \"Não\" and df_excel_Screening.loc[i,'HabAcademicas_6'] == 1:\n",
    "            aaa = \"Nenhuma das opções anteriores se aplica\"\n",
    "            HabAcademicas.append(aaa)\n",
    "        elif df_excel_Screening.loc[i, \"FreqEnsSup\"] == \"Sim\" and df_excel_Screening.loc[i,'CicloEstudosEnsSup'] == \"Licenciatura\":\n",
    "            aaa = \"Ensino Obrigatório\"\n",
    "            HabAcademicas.append(aaa)\n",
    "        elif df_excel_Screening.loc[i, \"FreqEnsSup\"] == \"Sim\" and df_excel_Screening.loc[i,'CicloEstudosEnsSup'] == \"Mestrado\":\n",
    "            aaa = \"Licenciatura\"\n",
    "            HabAcademicas.append(aaa)\n",
    "        elif df_excel_Screening.loc[i, \"FreqEnsSup\"] == \"Sim\" and df_excel_Screening.loc[i,'CicloEstudosEnsSup'] == \"Doutoramento\":\n",
    "            aaa = \"Mestrado\"\n",
    "            HabAcademicas.append(aaa)\n",
    "        elif df_excel_Screening.loc[i, \"FreqEnsSup\"] == \"Sim\" and df_excel_Screening.loc[i,'CicloEstudosEnsSup'] == \"Outro Ciclo\":\n",
    "            aaa = \"Outro Ciclo\"\n",
    "            HabAcademicas.append(aaa)\n",
    "\n",
    "df_excel_Screening.drop(columns=['HabAcademicas_1','HabAcademicas_2','HabAcademicas_3','HabAcademicas_4','HabAcademicas_5','HabAcademicas_6'],inplace=True)\n",
    "df_excel_Screening['HabAcademicas'] = HabAcademicas\n",
    "TransCol = df_excel_Screening.pop('HabAcademicas')\n",
    "df_excel_Screening.insert(6,\"HabAcademicas\",TransCol)\n",
    "\n",
    "\n",
    "for i in range(0,len(df_excel_Screening['SituacaoLaboral'])):\n",
    "        if df_excel_Screening.loc[i,'SituacaoLaboral'] == 1:\n",
    "            df_excel_Screening.loc[i,'SituacaoLaboral'] = \"Sim\"\n",
    "        else:\n",
    "            df_excel_Screening.loc[i,'SituacaoLaboral'] = \"Não\"\n",
    "\n",
    "SituacaoLaboralTurnos = []\n",
    "for i in range(0,len(df_excel_Screening['subject_nr'])):\n",
    "        if df_excel_Screening.loc[i,'SituacaoLaboralTurnos_1'] == 1:\n",
    "            aaa = \"Sim\"\n",
    "            SituacaoLaboralTurnos.append(aaa)\n",
    "        elif df_excel_Screening.loc[i, 'SituacaoLaboralTurnos_1'] == 0:\n",
    "            aaa = \"Não\"\n",
    "            SituacaoLaboralTurnos.append(aaa)\n",
    "        elif df_excel_Screening.loc[i,'SituacaoLaboralTurnos_2'] == 1 or df_excel_Screening.loc[i,'SituacaoLaboralTurnos_2'] == 0:\n",
    "            aaa = \"Não\"\n",
    "            SituacaoLaboralTurnos.append(aaa)\n",
    "\n",
    "df_excel_Screening.drop(columns=['SituacaoLaboralTurnos_1','SituacaoLaboralTurnos_2'],inplace=True)\n",
    "df_excel_Screening['SituacaoLaboralTurnos'] = SituacaoLaboralTurnos\n",
    "TransCol = df_excel_Screening.pop('SituacaoLaboralTurnos')\n",
    "df_excel_Screening.insert(9,\"SituacaoLaboralTurnos\",TransCol)\n",
    "\n",
    "for i in range(0,len(df_excel_Screening['PresencaDoencasAnter'])):\n",
    "        if df_excel_Screening.loc[i,'PresencaDoencasAnter'] == 1:\n",
    "            df_excel_Screening.loc[i,'PresencaDoencasAnter'] = \"Sim\"\n",
    "        else:\n",
    "            df_excel_Screening.loc[i,'PresencaDoencasAnter'] = \"Não\"\n",
    "\n",
    "for i in range(0,len(df_excel_Screening['MedicacaoPsicotropica'])):\n",
    "        if df_excel_Screening.loc[i,'MedicacaoPsicotropica'] == 1:\n",
    "            df_excel_Screening.loc[i,'MedicacaoPsicotropica'] = \"Sim\"\n",
    "        else:\n",
    "            df_excel_Screening.loc[i,'MedicacaoPsicotropica'] = \"Não\"\n",
    "\n",
    "for i in range(0,len(df_excel_Screening['Fumador'])):\n",
    "        if df_excel_Screening.loc[i,'Fumador'] == 1:\n",
    "            df_excel_Screening.loc[i,'Fumador'] = \"Sou fumador\"\n",
    "        elif df_excel_Screening.loc[i,'Fumador'] == 2:\n",
    "            df_excel_Screening.loc[i,'Fumador'] = \"Deixei de fumar há menos de 3 meses\"\n",
    "        else:\n",
    "            df_excel_Screening.loc[i,'Fumador'] = \"Não sou fumador nem deixei de fumar há menos de 3 meses\"\n",
    "\n",
    "ProdutosSessaoTabagica = []\n",
    "for i in range(0,len(df_excel_Screening['subject_nr'])):\n",
    "        if df_excel_Screening.loc[i,'ProdutosSessaoTabagica_1'] == 1:\n",
    "            aaa = \"Sim\"\n",
    "            ProdutosSessaoTabagica.append(aaa)\n",
    "        elif df_excel_Screening.loc[i,'ProdutosSessaoTabagica_2'] == 1:\n",
    "            aaa = \"Não\"\n",
    "            ProdutosSessaoTabagica.append(aaa)\n",
    "        elif df_excel_Screening.loc[i,'ProdutosSessaoTabagica_1'] == 0 and df_excel_Screening.loc[i,'ProdutosSessaoTabagica_2'] == 0:\n",
    "            aaa = None\n",
    "            ProdutosSessaoTabagica.append(aaa)\n",
    "\n",
    "df_excel_Screening.drop(columns=['ProdutosSessaoTabagica_1','ProdutosSessaoTabagica_2'],inplace=True)\n",
    "\n",
    "df_excel_Screening['ProdutosSessaoTabagica'] = ProdutosSessaoTabagica\n",
    "TransCol = df_excel_Screening.pop('ProdutosSessaoTabagica')\n",
    "df_excel_Screening.insert(16,\"ProdutosSessaoTabagica\",TransCol)\n",
    "\n",
    "for i in range(0,len(df_excel_Screening['ConsomeCafeina'])):\n",
    "        if df_excel_Screening.loc[i,'ConsomeCafeina'] == 1:\n",
    "            df_excel_Screening.loc[i,'ConsomeCafeina'] = \"Sim\"\n",
    "        else:\n",
    "            df_excel_Screening.loc[i,'ConsomeCafeina'] = \"Não\"\n",
    "\n",
    "for i in range(0,len(df_excel_Screening['ConsomeAlcool'])):\n",
    "        if df_excel_Screening.loc[i,'ConsomeAlcool'] == 1:\n",
    "            df_excel_Screening.loc[i,'ConsomeAlcool'] = \"Sim\"\n",
    "        else:\n",
    "            df_excel_Screening.loc[i,'ConsomeAlcool'] = \"Não\"\n",
    "\n",
    "for i in range(0,len(df_excel_Screening['ConsomeDrogas'])):\n",
    "        if df_excel_Screening.loc[i,'ConsomeDrogas'] == 1:\n",
    "            df_excel_Screening.loc[i,'ConsomeDrogas'] = \"Sim\"\n",
    "        else:\n",
    "            df_excel_Screening.loc[i,'ConsomeDrogas'] = \"Não\"\n",
    "\n",
    "for i in range(0,len(df_excel_Screening['Viagens'])):\n",
    "        if df_excel_Screening.loc[i,'Viagens'] == 1:\n",
    "            df_excel_Screening.loc[i,'Viagens'] = \"Sim\"\n",
    "        else:\n",
    "            df_excel_Screening.loc[i,'Viagens'] = \"Não\"\n",
    "\n",
    "df_excel_Screening[['Pergunta1', 'Pergunta7','Pergunta14','Pergunta15','Sexo','Nacionalidade','FreqEnsSup','CicloEstudosEnsSup',\n",
    "                    'HabAcademicas','SituacaoLaboral','SituacaoLaboralTurnos','PresencaDoencasAnter','MedicacaoPsicotropica',\n",
    "                    'Fumador','ProdutosSessaoTabagica','ConsomeCafeina','ConsomeAlcool','ConsomeDrogas','Viagens']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff74cf8",
   "metadata": {},
   "source": [
    "## 1.3. Calculating the MEQ score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d977b365",
   "metadata": {},
   "outputs": [],
   "source": [
    "colChronotype = []\n",
    "for i in range(0,len(df_excel_Screening['MEQscore'])):\n",
    "    if df_excel_Screening.loc[i,'MEQscore'] < 31:\n",
    "        temp_hold_chrono = 'Definitivamente Vespertino'\n",
    "    elif df_excel_Screening.loc[i,'MEQscore'] >=  31 and df_excel_Screening.loc[i,'MEQscore'] <= 42:\n",
    "        temp_hold_chrono = 'Moderadamente Vespertino'\n",
    "    elif df_excel_Screening.loc[i,'MEQscore'] >=  43 and df_excel_Screening.loc[i,'MEQscore'] <= 53:\n",
    "        temp_hold_chrono = 'Intermédio'\n",
    "    elif df_excel_Screening.loc[i,'MEQscore'] >=  54 and df_excel_Screening.loc[i,'MEQscore'] <= 59:\n",
    "        temp_hold_chrono = 'Moderadamente Matutino'\n",
    "    elif df_excel_Screening.loc[i,'MEQscore'] > 59:\n",
    "        temp_hold_chrono = 'Definitivamente Matutino'\n",
    "    colChronotype.append(temp_hold_chrono)\n",
    "\n",
    "df_excel_Screening['Cronotipo'] = colChronotype\n",
    "TransCol = df_excel_Screening.pop('Cronotipo')\n",
    "df_excel_Screening.insert(40,\"Cronotipo\",TransCol)\n",
    "\n",
    "df_excel_Screening[['Cronotipo']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8880882d",
   "metadata": {},
   "source": [
    "## 1.4. Calculating the Factors and indexes of the brief symptom inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e703a9a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#############Somatizacao\n",
    "FatorSomatizacao = []\n",
    "for i in range(0,len(df_excel_Screening['subject_nr'])):\n",
    "    temp_somatizacao = (df_excel_Screening.loc[i,'BSI:2'] + df_excel_Screening.loc[i,'BSI:7'] + df_excel_Screening.loc[i,'BSI:23'] + df_excel_Screening.loc[i,'BSI:29'] + df_excel_Screening.loc[i,'BSI:30'] + df_excel_Screening.loc[i,'BSI:33'] + df_excel_Screening.loc[i,'BSI:37'])/7\n",
    "    FatorSomatizacao.append(temp_somatizacao)\n",
    "\n",
    "df_excel_Screening['Somatizacao'] = FatorSomatizacao\n",
    "TransCol = df_excel_Screening.pop('Somatizacao')\n",
    "df_excel_Screening.insert(94,\"Somatizacao\",TransCol)\n",
    "##############FatorObsessoesCompulsoes\n",
    "FatorObsessoesCompulsoes = []\n",
    "for i in range(0,len(df_excel_Screening['subject_nr'])):\n",
    "    temp_FatorObsessoesCompulsoes = (df_excel_Screening.loc[i,'BSI:5'] + df_excel_Screening.loc[i,'BSI:15'] + df_excel_Screening.loc[i,'BSI:26'] + df_excel_Screening.loc[i,'BSI:27'] + df_excel_Screening.loc[i,'BSI:32'] + df_excel_Screening.loc[i,'BSI:36'])/6\n",
    "    FatorObsessoesCompulsoes.append(temp_FatorObsessoesCompulsoes)\n",
    "\n",
    "df_excel_Screening['FatorObsessoesCompulsoes'] = FatorObsessoesCompulsoes\n",
    "TransCol = df_excel_Screening.pop('FatorObsessoesCompulsoes')\n",
    "df_excel_Screening.insert(95,\"FatorObsessoesCompulsoes\",TransCol)\n",
    "\n",
    "##############FatorSensibilidadeInterpessoal\n",
    "FatorSensibilidadeInterpessoal = []\n",
    "for i in range(0,len(df_excel_Screening['subject_nr'])):\n",
    "    temp_FatorSensibilidadeInterpessoal = (df_excel_Screening.loc[i,'BSI:20'] + df_excel_Screening.loc[i,'BSI:21'] + df_excel_Screening.loc[i,'BSI:22'] + df_excel_Screening.loc[i,'BSI:42'])/4\n",
    "    FatorSensibilidadeInterpessoal.append(temp_FatorSensibilidadeInterpessoal)\n",
    "\n",
    "df_excel_Screening['FatorSensibilidadeInterpessoal'] = FatorSensibilidadeInterpessoal\n",
    "TransCol = df_excel_Screening.pop('FatorSensibilidadeInterpessoal')\n",
    "df_excel_Screening.insert(96,\"FatorSensibilidadeInterpessoal\",TransCol)\n",
    "\n",
    "\n",
    "##############FatorDepressao\n",
    "FatorDepressao = []\n",
    "for i in range(0,len(df_excel_Screening['subject_nr'])):\n",
    "    temp_FatorDepressao = (df_excel_Screening.loc[i,'BSI:9'] + df_excel_Screening.loc[i,'BSI:16'] + df_excel_Screening.loc[i,'BSI:17'] + df_excel_Screening.loc[i,'BSI:18'] + df_excel_Screening.loc[i,'BSI:35'] + df_excel_Screening.loc[i,'BSI:50'])/6\n",
    "    FatorDepressao.append(temp_FatorDepressao)\n",
    "\n",
    "df_excel_Screening['FatorDepressao'] = FatorDepressao\n",
    "TransCol = df_excel_Screening.pop('FatorDepressao')\n",
    "df_excel_Screening.insert(97,\"FatorDepressao\",TransCol)\n",
    "\n",
    "##############FatorAnsiedade\n",
    "FatorAnsiedade = []\n",
    "for i in range(0,len(df_excel_Screening['subject_nr'])):\n",
    "    temp_FatorAnsiedade = (df_excel_Screening.loc[i,'BSI:1'] + df_excel_Screening.loc[i,'BSI:12'] + df_excel_Screening.loc[i,'BSI:19'] + df_excel_Screening.loc[i,'BSI:38'] + df_excel_Screening.loc[i,'BSI:45'] + df_excel_Screening.loc[i,'BSI:49'])/6\n",
    "    FatorAnsiedade.append(temp_FatorAnsiedade)\n",
    "\n",
    "df_excel_Screening['FatorAnsiedade'] = FatorAnsiedade\n",
    "TransCol = df_excel_Screening.pop('FatorAnsiedade')\n",
    "df_excel_Screening.insert(98,\"FatorAnsiedade\",TransCol)\n",
    "\n",
    "##############FatorHostilidade\n",
    "FatorHostilidade = []\n",
    "for i in range(0,len(df_excel_Screening['subject_nr'])):\n",
    "    temp_FatorHostilidade = (df_excel_Screening.loc[i,'BSI:6'] + df_excel_Screening.loc[i,'BSI:13'] + df_excel_Screening.loc[i,'BSI:40'] + df_excel_Screening.loc[i,'BSI:41'] + df_excel_Screening.loc[i,'BSI:46'])/5\n",
    "    FatorHostilidade.append(temp_FatorHostilidade)\n",
    "\n",
    "df_excel_Screening['FatorHostilidade'] = FatorHostilidade\n",
    "TransCol = df_excel_Screening.pop('FatorHostilidade')\n",
    "df_excel_Screening.insert(99,\"FatorHostilidade\",TransCol)\n",
    "\n",
    "##############FatorAnsiedadeFobica\n",
    "FatorAnsiedadeFobica = []\n",
    "for i in range(0,len(df_excel_Screening['subject_nr'])):\n",
    "    temp_FatorAnsiedadeFobica = (df_excel_Screening.loc[i,'BSI:8'] + df_excel_Screening.loc[i,'BSI:28'] + df_excel_Screening.loc[i,'BSI:31'] + df_excel_Screening.loc[i,'BSI:43'] + df_excel_Screening.loc[i,'BSI:47'])/5\n",
    "    FatorAnsiedadeFobica.append(temp_FatorAnsiedadeFobica)\n",
    "\n",
    "df_excel_Screening['FatorAnsiedadeFobica'] = FatorAnsiedadeFobica\n",
    "TransCol = df_excel_Screening.pop('FatorAnsiedadeFobica')\n",
    "df_excel_Screening.insert(100,\"FatorAnsiedadeFobica\",TransCol)\n",
    "\n",
    "##############FatorIdeacaoParanoide\n",
    "FatorIdeacaoParanoide = []\n",
    "for i in range(0,len(df_excel_Screening['subject_nr'])):\n",
    "    temp_FatorIdeacaoParanoide = (df_excel_Screening.loc[i,'BSI:4'] + df_excel_Screening.loc[i,'BSI:10'] + df_excel_Screening.loc[i,'BSI:24'] + df_excel_Screening.loc[i,'BSI:48'] + df_excel_Screening.loc[i,'BSI:51'])/5\n",
    "    FatorIdeacaoParanoide.append(temp_FatorIdeacaoParanoide)\n",
    "\n",
    "df_excel_Screening['FatorIdeacaoParanoide'] = FatorIdeacaoParanoide\n",
    "TransCol = df_excel_Screening.pop('FatorIdeacaoParanoide')\n",
    "df_excel_Screening.insert(101,\"FatorIdeacaoParanoide\",TransCol)\n",
    "\n",
    "##############FatorPsicoticismo\n",
    "FatorPsicoticismo = []\n",
    "for i in range(0,len(df_excel_Screening['subject_nr'])):\n",
    "    temp_FatorPsicoticismo = (df_excel_Screening.loc[i,'BSI:3'] + df_excel_Screening.loc[i,'BSI:14'] + df_excel_Screening.loc[i,'BSI:34'] + df_excel_Screening.loc[i,'BSI:44'] + df_excel_Screening.loc[i,'BSI:53'])/5\n",
    "    FatorPsicoticismo.append(temp_FatorPsicoticismo)\n",
    "\n",
    "df_excel_Screening['FatorPsicoticismo'] = FatorPsicoticismo\n",
    "TransCol = df_excel_Screening.pop('FatorPsicoticismo')\n",
    "df_excel_Screening.insert(102,\"FatorPsicoticismo\",TransCol)\n",
    "\n",
    "\n",
    "##############IGS\n",
    "IGS = []\n",
    "for i in range(0,len(df_excel_Screening['subject_nr'])):\n",
    "    temp_IGS = (df_excel_Screening.loc[i,'BSI:1'] +\tdf_excel_Screening.loc[i,'BSI:2'] +\tdf_excel_Screening.loc[i,'BSI:3'] +\tdf_excel_Screening.loc[i,'BSI:4'] +\tdf_excel_Screening.loc[i,'BSI:5'] +\tdf_excel_Screening.loc[i,'BSI:6'] +\tdf_excel_Screening.loc[i,'BSI:7'] +\tdf_excel_Screening.loc[i,'BSI:8'] +\tdf_excel_Screening.loc[i,'BSI:9'] +\tdf_excel_Screening.loc[i,'BSI:10'] + df_excel_Screening.loc[i,'BSI:11'] + df_excel_Screening.loc[i,'BSI:12'] + df_excel_Screening.loc[i,'BSI:13'] +\tdf_excel_Screening.loc[i,'BSI:14'] +\tdf_excel_Screening.loc[i,'BSI:15'] +\tdf_excel_Screening.loc[i,'BSI:16'] +\tdf_excel_Screening.loc[i,'BSI:17'] +\tdf_excel_Screening.loc[i,'BSI:18'] +\tdf_excel_Screening.loc[i,'BSI:19'] +\tdf_excel_Screening.loc[i,'BSI:20'] +\tdf_excel_Screening.loc[i,'BSI:21'] +\tdf_excel_Screening.loc[i,'BSI:22'] +\tdf_excel_Screening.loc[i,'BSI:23'] +\tdf_excel_Screening.loc[i,'BSI:24'] +\tdf_excel_Screening.loc[i,'BSI:25'] +\tdf_excel_Screening.loc[i,'BSI:26'] +\tdf_excel_Screening.loc[i,'BSI:27'] +\tdf_excel_Screening.loc[i,'BSI:28'] +\tdf_excel_Screening.loc[i,'BSI:29'] +\tdf_excel_Screening.loc[i,'BSI:30'] +\tdf_excel_Screening.loc[i,'BSI:31'] +\tdf_excel_Screening.loc[i,'BSI:32'] +\tdf_excel_Screening.loc[i,'BSI:33'] +\tdf_excel_Screening.loc[i,'BSI:34'] +\tdf_excel_Screening.loc[i,'BSI:35'] +\tdf_excel_Screening.loc[i,'BSI:36'] +\tdf_excel_Screening.loc[i,'BSI:37'] +\tdf_excel_Screening.loc[i,'BSI:38'] +\tdf_excel_Screening.loc[i,'BSI:39'] +\tdf_excel_Screening.loc[i,'BSI:40'] +\tdf_excel_Screening.loc[i,'BSI:41'] +\tdf_excel_Screening.loc[i,'BSI:42'] +\tdf_excel_Screening.loc[i,'BSI:43'] +\tdf_excel_Screening.loc[i,'BSI:44'] +\tdf_excel_Screening.loc[i,'BSI:45'] +\tdf_excel_Screening.loc[i,'BSI:46'] +\tdf_excel_Screening.loc[i,'BSI:47'] +\tdf_excel_Screening.loc[i,'BSI:48'] +\tdf_excel_Screening.loc[i,'BSI:49'] +\tdf_excel_Screening.loc[i,'BSI:50'] + df_excel_Screening.loc[i,'BSI:51'] + df_excel_Screening.loc[i,'BSI:52'] + df_excel_Screening.loc[i,'BSI:53'])/53\n",
    "    IGS.append(temp_IGS)\n",
    "\n",
    "df_excel_Screening['IGS'] = IGS\n",
    "TransCol = df_excel_Screening.pop('IGS')\n",
    "df_excel_Screening.insert(103,\"IGS\",TransCol)\n",
    "\n",
    "##############TSP\n",
    "TSP = []\n",
    "for i in range(0,len(df_excel_Screening['subject_nr'])):\n",
    "    temp_TSP = 0\n",
    "    for j in range(41,94):\n",
    "        if df_excel_Screening.iloc[i,j] != 0:\n",
    "            temp_TSP += 1\n",
    "    TSP.append(temp_TSP)\n",
    "\n",
    "df_excel_Screening['TSP'] = TSP\n",
    "TransCol = df_excel_Screening.pop('TSP')\n",
    "df_excel_Screening.insert(104,\"TSP\",TransCol)\n",
    "\n",
    "##############ISP\n",
    "ISP = []\n",
    "for i in range(0,len(df_excel_Screening['subject_nr'])):\n",
    "    temp_ISP = 0\n",
    "    temp_TSP = 0\n",
    "    for j in range(41,94):\n",
    "        if df_excel_Screening.iloc[i,j] != 0:\n",
    "            temp_ISP += df_excel_Screening.iloc[i,j]\n",
    "            temp_TSP += 1\n",
    "    if temp_TSP != 0:\n",
    "        temp_ISP = temp_ISP/temp_TSP\n",
    "    else:\n",
    "        temp_ISP = 0\n",
    "    ISP.append(temp_ISP)\n",
    "\n",
    "df_excel_Screening['ISP'] = ISP\n",
    "TransCol = df_excel_Screening.pop('ISP')\n",
    "df_excel_Screening.insert(105,\"ISP\",TransCol)\n",
    "\n",
    "cols_to_round = [\n",
    "    \"Somatizacao\",\n",
    "    \"FatorObsessoesCompulsoes\",\n",
    "    \"FatorSensibilidadeInterpessoal\",\n",
    "    \"FatorDepressao\",\n",
    "    \"FatorAnsiedade\",\n",
    "    \"FatorHostilidade\",\n",
    "    \"FatorAnsiedadeFobica\",\n",
    "    \"FatorIdeacaoParanoide\",\n",
    "    \"FatorPsicoticismo\",\n",
    "    \"IGS\",\n",
    "    \"ISP\"\n",
    "]\n",
    "df_excel_Screening[cols_to_round] = df_excel_Screening[cols_to_round].round(2)\n",
    "\n",
    "df_excel_Screening[['Somatizacao','FatorObsessoesCompulsoes','FatorSensibilidadeInterpessoal','FatorDepressao',\n",
    "                    'FatorAnsiedade','FatorHostilidade','FatorAnsiedadeFobica','FatorIdeacaoParanoide','FatorPsicoticismo',\n",
    "                    'IGS','TSP','ISP']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b4ef61",
   "metadata": {},
   "source": [
    "## 1.5. View final df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b15547e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)  \n",
    "df_excel_Screening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684b4e7d",
   "metadata": {},
   "source": [
    "# 2. Activity and sleep diaries databases.\n",
    "Generates DB with data collected in the activity and sleep diaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f630c7a",
   "metadata": {},
   "source": [
    "## 2.1. Sleep Diary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1501b8",
   "metadata": {},
   "source": [
    "### 2.1.1. Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b34b7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Opens the excel file where data from participants are stored.\n",
    "#Opens the excel file where data from participants are stored.\n",
    "# Go up one folder (from /notebook to project root)\n",
    "PROJ_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "# Build the path safely\n",
    "SD_excel_part_data_path = PROJ_ROOT / \"DiariosSonoAtividade\" / \"dataSono.xlsx\"\n",
    "\n",
    "SD_df_excel_data_part = pd.read_excel(SD_excel_part_data_path)\n",
    "\n",
    "##Drops redundant columns (empty columns regarding the column with the session number) in the dataframe df_excel_data_part.\n",
    "SD_df_excel_data_part.drop(SD_df_excel_data_part.columns[3:11],axis=1,inplace=True)\n",
    "\n",
    "##Substitui os nomes das colunas pelos labels corretos\n",
    "SD_df_excel_data_part.columns = ['participant', 'Subject_Nr', 'Session_Nr', 'Data', 'SD_Q1', 'SD_Q2', 'SD_Q3', 'SD_Q4', 'SD_Q5', 'SD_Q6a',\n",
    "                               'SD_Q6b', 'SD_Q6c', 'SD_Q6d', 'SD_Q7', 'SD_Q8', 'SD_Q9', 'SD_Q10', 'SD_Q11', 'TIME_start', 'TIME_end','TIME_total']\n",
    "\n",
    "##Organiza os registos pelo número de participante e número de sessão (por ordem ascendente).\n",
    "SD_df_excel_data_part.sort_values(by=['Subject_Nr','Session_Nr'], kind='mergesort', inplace=True,ascending=True)\n",
    "SD_df_excel_data_part.reset_index(drop=True,inplace=True)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)  \n",
    "pd.set_option(\"display.max_rows\", 10)  \n",
    "SD_df_excel_data_part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bc78c3",
   "metadata": {},
   "source": [
    "### 2.1.2. Replacing values in multiple columns by values that make more sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SD_df_excel_data_part[['SD_Q6c', 'SD_Q9','SD_Q10']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdc917e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Subsitui valores númericos que codificam um certo label, pelo label correto.\n",
    "for i in range(0,len(SD_df_excel_data_part['SD_Q6c'])):\n",
    "        if SD_df_excel_data_part.loc[i,'SD_Q6c'] == 1:\n",
    "            SD_df_excel_data_part.loc[i,'SD_Q6c'] = \"Sim\"\n",
    "        else :\n",
    "            SD_df_excel_data_part.loc[i,'SD_Q6c'] = \"Não\"\n",
    "\n",
    "for i in range(0,len(SD_df_excel_data_part['SD_Q9'])):\n",
    "        if SD_df_excel_data_part.loc[i,'SD_Q9'] == 1:\n",
    "            SD_df_excel_data_part.loc[i,'SD_Q9'] = \"Muito Pobre\"\n",
    "        elif SD_df_excel_data_part.loc[i,'SD_Q9'] == 2:\n",
    "            SD_df_excel_data_part.loc[i,'SD_Q9'] = \"Pobre\"\n",
    "        elif SD_df_excel_data_part.loc[i,'SD_Q9'] == 3:\n",
    "            SD_df_excel_data_part.loc[i,'SD_Q9'] = \"Aceitável\"\n",
    "        elif SD_df_excel_data_part.loc[i,'SD_Q9'] == 4:\n",
    "            SD_df_excel_data_part.loc[i,'SD_Q9'] = \"Boa\"\n",
    "        else :\n",
    "            SD_df_excel_data_part.loc[i,'SD_Q9'] = \"Muito Boa\"\n",
    "\n",
    "for i in range(0,len(SD_df_excel_data_part['SD_Q10'])):\n",
    "        if SD_df_excel_data_part.loc[i,'SD_Q10'] == 1:\n",
    "            SD_df_excel_data_part.loc[i,'SD_Q10'] = \"Nada descansado(a)/restabelecido(a)\"\n",
    "        elif SD_df_excel_data_part.loc[i,'SD_Q10'] == 2:\n",
    "            SD_df_excel_data_part.loc[i,'SD_Q10'] = \"Ligeiramente descansado(a)/restabelecido(a)\"\n",
    "        elif SD_df_excel_data_part.loc[i,'SD_Q10'] == 3:\n",
    "            SD_df_excel_data_part.loc[i,'SD_Q10'] = \"Aceitavelmente descansado(a)/restabelecido(a)\"\n",
    "        elif SD_df_excel_data_part.loc[i,'SD_Q10'] == 4:\n",
    "            SD_df_excel_data_part.loc[i,'SD_Q10'] = \"Bem descansado(a)/restabelecido(a)\"\n",
    "        else :\n",
    "            SD_df_excel_data_part.loc[i,'SD_Q10'] = \"Muito bem descansado(a)/restabelecido(a)\"\n",
    "\n",
    "SD_df_excel_data_part[['SD_Q6c', 'SD_Q9','SD_Q10']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff09779",
   "metadata": {},
   "source": [
    "### 2.1.3. Calculates and appends the columns sleep onset latency (SOL), sleep after final awakening (TASAFA), time awake after initial sleep onset but before the final awakening (WASO), Total Sleep Time (TST), duration of sleep episode (DSE), and sleep efficiency (SE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9990f9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, datetime, time\n",
    "\n",
    "#Creates column with sleep onset latency (SOL) values\n",
    "SD_df_excel_data_part['SOL'] = SD_df_excel_data_part['SD_Q3']\n",
    "\n",
    "#Creates column with time attempting to sleep after final awakening (TASAFA) values\n",
    "SD_df_excel_data_part['TASAFA'] = SD_df_excel_data_part['SD_Q6b']\n",
    "\n",
    "#Creates column with time awake after initial sleep onset but before the final awakening (WASO) values\n",
    "SD_df_excel_data_part['WASO'] = SD_df_excel_data_part['SD_Q5']\n",
    "#Substitui valores vazios (correspondente a participantes que não responderam à questão) por 0.\n",
    "for i in range(0,len(SD_df_excel_data_part['WASO'])):\n",
    "    if pd.isnull(SD_df_excel_data_part.loc[i,'WASO']):\n",
    "        SD_df_excel_data_part.loc[i,'WASO'] = 0\n",
    "\n",
    "#Creates column with time Total Sleep Time (TST) values\n",
    "temp_sleep_time = SD_df_excel_data_part['SD_Q2'].copy(deep=True)\n",
    "##Cálcula o número de horas que passaram desde o momento em que o participante começou a tentar dormir até ao momento em que se levantou\n",
    "##e iníciou a sua rotna.\n",
    "for i in range(0,len(temp_sleep_time)):\n",
    "    temp_sleep_time[i] = pd.to_datetime(str(temp_sleep_time[i]))\n",
    "temp_rising_time = SD_df_excel_data_part['SD_Q6a'].copy(deep=True)\n",
    "for i in range(0,len(temp_rising_time)):\n",
    "    temp_rising_time[i] = pd.to_datetime(str(temp_rising_time[i]))\n",
    "temp_diff_ris_sleep = temp_rising_time - temp_sleep_time\n",
    "##Exclui a informação referente à data e deixa apenas a informação referente à hora e minutos.\n",
    "for i in range(0,len(temp_diff_ris_sleep)):\n",
    "    temp_diff_ris_sleep[i] = str(temp_diff_ris_sleep[i])\n",
    "    aaa = (str(temp_diff_ris_sleep[i]))\n",
    "    aaa = aaa[-8:-3]\n",
    "    temp_diff_ris_sleep[i] = aaa\n",
    "\n",
    "temp_TST = []\n",
    "TST_for_DSE = []\n",
    "for i in range(0,len(temp_diff_ris_sleep)):\n",
    "##Converte o formato hh:mm em minutos e subtrai o valor do WASo e do SOL para calcular o TST.\n",
    "##Volta a converter o TST num forato HHhMM\n",
    "    aaa = float(temp_diff_ris_sleep[i][0:2])\n",
    "    aaa = aaa*60\n",
    "    bbb = float(temp_diff_ris_sleep[i][3:6])\n",
    "    aaa = aaa + bbb\n",
    "    aaa = aaa - SD_df_excel_data_part.loc[i,'WASO'] - SD_df_excel_data_part.loc[i,'SOL']\n",
    "    TST_for_DSE.append(aaa)\n",
    "    aaa = aaa/60\n",
    "    aaa = '{0:02.0f}:{1:02.0f}'.format(*divmod(aaa * 60, 60))\n",
    "    aaa = str(aaa)\n",
    "    aaa = aaa.replace(\":\",\"h\")\n",
    "    temp_TST.append(aaa)\n",
    "SD_df_excel_data_part['TST'] = temp_TST\n",
    "\n",
    "#Creates column with time duration of the duration of sleep episode (DSE) values.\n",
    "# The DSE is calculating by suming the SOL, WASO, TST, and the TASAFA.\n",
    "temp_DSE = []\n",
    "DSE_for_SE = []\n",
    "for i in range(0,len(SD_df_excel_data_part['participant'])):\n",
    "    aaa = TST_for_DSE[i] + SD_df_excel_data_part.loc[i,'WASO'] + SD_df_excel_data_part.loc[i,'SOL'] + SD_df_excel_data_part.loc[i,'TASAFA']\n",
    "    DSE_for_SE.append(aaa)\n",
    "    aaa = aaa/60\n",
    "    aaa = '{0:02.0f}:{1:02.0f}'.format(*divmod(aaa * 60, 60))\n",
    "    aaa = str(aaa)\n",
    "    aaa = aaa.replace(\":\",\"h\")\n",
    "    temp_DSE.append(aaa)\n",
    "SD_df_excel_data_part['DSE'] = temp_DSE\n",
    "\n",
    "\n",
    "#Creates column with time duration of the sleep efficiency (SE) values.\n",
    "# The SE is the ratio of total sleep time (TST) to duration of sleep episode (SDE).\n",
    "temp_SE = []\n",
    "for i in range(0,len(SD_df_excel_data_part['participant'])):\n",
    "    aaa = round((TST_for_DSE[i]/DSE_for_SE[i])*100,2)\n",
    "    temp_SE.append(aaa)\n",
    "SD_df_excel_data_part['SE'] = temp_SE\n",
    "\n",
    "twentythree = 82800\n",
    "twentythree = datetime.time(23,0,0)\n",
    "one = 3600\n",
    "one = datetime.time(1,0,0)\n",
    "seven = 25200\n",
    "seven = datetime.time(7,0,0)\n",
    "nine = datetime.time(9,0,0)\n",
    "TSTsix = 360\n",
    "TSTnine = 540\n",
    "\n",
    "SD_df_excel_data_part[['SOL', 'TASAFA', 'WASO', 'TST', 'DSE', 'SE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d37eb89",
   "metadata": {},
   "source": [
    "### 2.1.4. View final sleep diaries data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9912ed2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SD_df_excel_data_part = SD_df_excel_data_part[['Subject_Nr', 'Session_Nr', 'Data', 'SD_Q1', 'SD_Q2',\n",
    "       'SD_Q3', 'SD_Q4', 'SD_Q5', 'SD_Q6a', 'SD_Q6b', 'SD_Q6c', 'SD_Q6d',\n",
    "       'SD_Q7', 'SD_Q8', 'SD_Q9', 'SD_Q10', 'SD_Q11', 'SOL', 'TASAFA', 'WASO', 'TST', 'DSE', 'SE', 'TIME_start', 'TIME_end',\n",
    "       'TIME_total']]\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)  \n",
    "SD_df_excel_data_part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caa806b",
   "metadata": {},
   "source": [
    "## 2.2. Activity Diary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95adbce",
   "metadata": {},
   "source": [
    "### 2.2.1. Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd2efd2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Opens the excel file where data from participants are stored.\n",
    "#Opens the excel file where data from participants are stored.\n",
    "# Go up one folder (from /notebook to project root)\n",
    "PROJ_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "# Build the path safely\n",
    "AD_excel_part_data_path = PROJ_ROOT / \"DiariosSonoAtividade\" / \"dataAtividade.xlsx\"\n",
    "\n",
    "AD_df_excel_data_part = pd.read_excel(AD_excel_part_data_path)\n",
    "\n",
    "##Drops redundant columns (empty columns regarding the column with the session number) in the dataframe df_excel_data_part.\n",
    "AD_df_excel_data_part.drop(AD_df_excel_data_part.columns[3:11],axis=1,inplace=True)\n",
    "\n",
    "##Substitui os nomes das colunas pelos labels corretos\n",
    "AD_df_excel_data_part.columns = [\"participant\",\"Subject_Nr\",\"Session_Nr\",\"Data\",\"AD_Q1\",\"AD_Q2\",\"AD_Q3\",\"AD_Q4:1\",\"AD_Q4:2\",\"AD_Q4:3\",\n",
    "                                 \"AD_Q4:4\",\"AD_Q4:5\",\"AD_Q4:6\",\"AD_Q4:7\",\"AD_Q4:8\",\"AD_Q4:9\",\"AD_Q4:10\",\"AD_Q4:11\",\"AD_Q4:12\",\"AD_Q4:13\",\n",
    "                                 \"AD_Q4:14\",\"AD_Q4:15\",\"AD_Q4:16\",\"AD_Q4:17\",\"AD_Q4:18\",\"AD_Q4:19\",\"AD_Q4:20\",\"AD_Q4:21\",\"AD_Q4:22\",\n",
    "                                 \"AD_Q4:23\",\"AD_Q4:24\",\"AD_Q5\",\"AD_Q6:1\",\"AD_Q6:2\",\"AD_Q6:3\",\"AD_Q6:4\",\"AD_Q6:5\",\"AD_Q6:6\",\"AD_Q6:7\",\n",
    "                                 \"AD_Q6:8\",\"AD_Q6:9\",\"AD_Q6:10\",\"AD_Q6:11\",\"AD_Q6:12\",\"AD_Q6:13\",\"AD_Q6:14\",\"AD_Q6:15\",\"AD_Q6:16\",\n",
    "                                 \"AD_Q6:17\",\"AD_Q6:18\",\"AD_Q6:19\",\"AD_Q6:20\",\"AD_Q6:21\",\"AD_Q6:22\",\"AD_Q6:23\",\"AD_Q6:24\",\"AD_Q7\",\n",
    "                                 \"AD_Q8\",\"AD_Q9:1\",\"AD_Q9:2\",\"AD_Q9:3\",\"AD_Q9:4\",\"AD_Q9:5\",\"AD_Q9:6\",\"AD_Q9:7\",\"AD_Q9:8\",\"AD_Q9:9\",\n",
    "                                 \"AD_Q9:10\",\"AD_Q9:11\",\"AD_Q9:12\",\"AD_Q9:13\",\"AD_Q9:14\",\"AD_Q9:15\",\"AD_Q9:16\",\"AD_Q9:17\",\"AD_Q9:18\",\n",
    "                                 \"AD_Q9:19\",\"AD_Q9:20\",\"AD_Q9:21\",\"AD_Q9:22\",\"AD_Q9:23\",\"AD_Q9:24\",\"AD_Q10\",\"AD_Q11:1\",\"AD_Q11:2\",\n",
    "                                 \"AD_Q11:3\",\"AD_Q11:4\",\"AD_Q11:5\",\"AD_Q11:6\",\"AD_Q11:7\",\"AD_Q11:8\",\"AD_Q11:9\",\"AD_Q11:10\",\"AD_Q11:11\",\n",
    "                                 \"AD_Q11:12\",\"AD_Q11:13\",\"AD_Q11:14\",\"AD_Q11:15\",\"AD_Q11:16\",\"AD_Q11:17\",\"AD_Q11:18\",\"AD_Q11:19\",\n",
    "                                 \"AD_Q11:20\",\"AD_Q11:21\",\"AD_Q11:22\",\"AD_Q11:23\",\"AD_Q11:24\",\"AD_Q12\",\"TIME_start\",\"TIME_end\",\n",
    "                                 \"TIME_total\"]\n",
    "\n",
    "\n",
    "##Organiza os registos pelo número de participante e número de sessão (por ordem ascendente).\n",
    "AD_df_excel_data_part.sort_values(by=[\"Subject_Nr\",'Session_Nr'], kind='mergesort', inplace=True,ascending=True)\n",
    "AD_df_excel_data_part.reset_index(drop=True,inplace=True)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)  \n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "AD_df_excel_data_part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af1e6d7",
   "metadata": {},
   "source": [
    "### 2.2.2. Replacing values in multiple columns by values that make more sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca65972",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Substitui os valores númericos que codificam horas nas colunas referentes às questões 4,6,9 11 pelos labels corretos (horas\n",
    "#correspondenes, p. ex., 04h00)\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:1'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:1'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:1'] = '00h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:2'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:2'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:2'] = '01h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:3'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:3'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:3'] = '02h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:4'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:4'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:4'] = '03h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:5'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:5'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:5'] = '04h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:6'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:6'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:6'] = '05h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:7'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:7'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:7'] = '06h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:8'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:8'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:8'] = '07h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:9'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:9'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:9'] = '08h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:10'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:10'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:10'] = '09h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:11'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:11'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:11'] = '10h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:12'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:12'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:12'] = '11h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:13'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:13'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:13'] = '12h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:14'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:14'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:14'] = '13h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:15'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:15'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:15'] = '14h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:16'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:16'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:16'] = '15h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:17'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:17'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:17'] = '16h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:18'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:18'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:18'] = '17h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:19'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:19'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:19'] = '18h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:20'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:20'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:20'] = '19h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:21'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:21'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:21'] = '20h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:22'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:22'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:22'] = '21h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:23'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:23'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:23'] = '22h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q4:24'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q4:24'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q4:24'] = '23h00'\n",
    "\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:1'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:1'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:1'] = '00h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:2'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:2'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:2'] = '01h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:3'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:3'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:3'] = '02h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:4'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:4'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:4'] = '03h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:5'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:5'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:5'] = '04h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:6'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:6'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:6'] = '05h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:7'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:7'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:7'] = '06h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:8'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:8'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:8'] = '07h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:9'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:9'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:9'] = '08h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:10'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:10'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:10'] = '09h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:11'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:11'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:11'] = '10h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:12'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:12'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:12'] = '11h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:13'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:13'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:13'] = '12h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:14'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:14'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:14'] = '13h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:15'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:15'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:15'] = '14h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:16'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:16'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:16'] = '15h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:17'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:17'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:17'] = '16h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:18'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:18'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:18'] = '17h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:19'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:19'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:19'] = '18h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:20'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:20'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:20'] = '19h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:21'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:21'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:21'] = '20h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:22'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:22'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:22'] = '21h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:23'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:23'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:23'] = '22h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q6:24'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q6:24'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q6:24'] = '23h00'\n",
    "\n",
    "\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:1'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:1'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:1'] = '00h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:2'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:2'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:2'] = '01h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:3'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:3'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:3'] = '02h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:4'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:4'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:4'] = '03h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:5'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:5'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:5'] = '04h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:6'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:6'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:6'] = '05h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:7'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:7'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:7'] = '06h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:8'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:8'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:8'] = '07h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:9'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:9'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:9'] = '08h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:10'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:10'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:10'] = '09h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:11'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:11'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:11'] = '10h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:12'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:12'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:12'] = '11h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:13'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:13'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:13'] = '12h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:14'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:14'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:14'] = '13h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:15'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:15'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:15'] = '14h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:16'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:16'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:16'] = '15h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:17'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:17'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:17'] = '16h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:18'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:18'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:18'] = '17h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:19'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:19'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:19'] = '18h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:20'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:20'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:20'] = '19h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:21'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:21'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:21'] = '20h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:22'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:22'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:22'] = '21h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:23'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:23'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:23'] = '22h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q9:24'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q9:24'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q9:24'] = '23h00'\n",
    "\n",
    "\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:1'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:1'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:1'] = '00h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:2'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:2'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:2'] = '01h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:3'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:3'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:3'] = '02h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:4'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:4'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:4'] = '03h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:5'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:5'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:5'] = '04h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:6'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:6'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:6'] = '05h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:7'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:7'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:7'] = '06h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:8'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:8'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:8'] = '07h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:9'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:9'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:9'] = '08h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:10'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:10'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:10'] = '09h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:11'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:11'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:11'] = '10h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:12'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:12'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:12'] = '11h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:13'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:13'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:13'] = '12h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:14'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:14'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:14'] = '13h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:15'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:15'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:15'] = '14h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:16'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:16'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:16'] = '15h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:17'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:17'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:17'] = '16h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:18'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:18'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:18'] = '17h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:19'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:19'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:19'] = '18h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:20'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:20'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:20'] = '19h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:21'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:21'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:21'] = '20h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:22'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:22'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:22'] = '21h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:23'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:23'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:23'] = '22h00'\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q11:24'])):\n",
    "    if AD_df_excel_data_part.loc[i,'AD_Q11:24'] == 1:\n",
    "        AD_df_excel_data_part.loc[i, 'AD_Q11:24'] = '23h00'\n",
    "\n",
    "\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q7'])):\n",
    "        if AD_df_excel_data_part.loc[i,'AD_Q7'] == 1:\n",
    "            AD_df_excel_data_part.loc[i,'AD_Q7'] = \"Sim\"\n",
    "        else:\n",
    "            AD_df_excel_data_part.loc[i, 'AD_Q7'] = \"Não\"\n",
    "\n",
    "for i in range(0,len(AD_df_excel_data_part['AD_Q10'])):\n",
    "        if AD_df_excel_data_part.loc[i,'AD_Q10'] == 1:\n",
    "            AD_df_excel_data_part.loc[i,'AD_Q10'] = \"Sim\"\n",
    "        else:\n",
    "            AD_df_excel_data_part.loc[i, 'AD_Q10'] = \"Não\"\n",
    "\n",
    "##Cria listas com os horários em que os participantes consumiram bebidas alcoólicas (Q4), bebidas cafeinadas (Q6), tomaram medicação\n",
    "##para dormir (Q9), ou fizeram exercício (Q11) e guarda essas listas em colunas na dataframe 'AD_df_excel_data_part'.\n",
    "major_list = []\n",
    "for j in range(0,len(AD_df_excel_data_part['participant'])):\n",
    "    temp_list = []\n",
    "    for i in range(7,31):\n",
    "        if AD_df_excel_data_part.iloc[j,i] != 0:\n",
    "            temp_list.append(AD_df_excel_data_part.iloc[j,i])\n",
    "    major_list.append(temp_list)\n",
    "for i in range(0,len(major_list)):\n",
    "    if major_list[i] == []:\n",
    "        major_list[i] = None\n",
    "AD_df_excel_data_part[\"AD_Q4\"] = major_list\n",
    "\n",
    "major_list = []\n",
    "for j in range(0,len(AD_df_excel_data_part['participant'])):\n",
    "    temp_list = []\n",
    "    for i in range(32,56):\n",
    "        if AD_df_excel_data_part.iloc[j,i] != 0:\n",
    "            temp_list.append(AD_df_excel_data_part.iloc[j,i])\n",
    "    major_list.append(temp_list)\n",
    "for i in range(0,len(major_list)):\n",
    "    if major_list[i] == []:\n",
    "        major_list[i] = None\n",
    "AD_df_excel_data_part[\"AD_Q6\"] = major_list\n",
    "\n",
    "major_list = []\n",
    "for j in range(0,len(AD_df_excel_data_part['participant'])):\n",
    "    temp_list = []\n",
    "    for i in range(58,82):\n",
    "        if AD_df_excel_data_part.iloc[j,i] != 0:\n",
    "            temp_list.append(AD_df_excel_data_part.iloc[j,i])\n",
    "    major_list.append(temp_list)\n",
    "for i in range(0,len(major_list)):\n",
    "    if major_list[i] == []:\n",
    "        major_list[i] = None\n",
    "AD_df_excel_data_part[\"AD_Q9\"] = major_list\n",
    "\n",
    "major_list = []\n",
    "for j in range(0,len(AD_df_excel_data_part['participant'])):\n",
    "    temp_list = []\n",
    "    for i in range(83,107):\n",
    "        if AD_df_excel_data_part.iloc[j,i] != 0:\n",
    "            temp_list.append(AD_df_excel_data_part.iloc[j,i])\n",
    "    major_list.append(temp_list)\n",
    "for i in range(0,len(major_list)):\n",
    "    if major_list[i] == []:\n",
    "        major_list[i] = None\n",
    "AD_df_excel_data_part[\"AD_Q11\"] = major_list\n",
    "\n",
    "##Elimina colunas que já não são úteis relacionadas com as questões 4, 6, 9 e 11.\n",
    "AD_df_excel_data_part.drop(AD_df_excel_data_part.columns[83:107],axis=1,inplace=True)\n",
    "AD_df_excel_data_part.drop(AD_df_excel_data_part.columns[58:82],axis=1,inplace=True)\n",
    "AD_df_excel_data_part.drop(AD_df_excel_data_part.columns[32:56],axis=1,inplace=True)\n",
    "AD_df_excel_data_part.drop(AD_df_excel_data_part.columns[7:31],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "cols_to_clean = [\"AD_Q4\",\"AD_Q6\", \"AD_Q11\"]  # columns where [''] appears\n",
    "for col in cols_to_clean:\n",
    "    AD_df_excel_data_part[col] = (\n",
    "        AD_df_excel_data_part[col]\n",
    "        .astype(str)\n",
    "        .str.replace(r\"[\\[\\]']\", \"\", regex=True)  # remove [, ], '\n",
    "        .str.strip()\n",
    "    )\n",
    "    \n",
    "AD_df_excel_data_part = AD_df_excel_data_part[\n",
    "    [\"Subject_Nr\", \"Session_Nr\",\"Data\", \"AD_Q1\",\"AD_Q2\",\"AD_Q3\",\"AD_Q4\", \"AD_Q5\",\"AD_Q6\", \"AD_Q7\",\"AD_Q8\",\"AD_Q9\",\"AD_Q10\", \n",
    "     \"AD_Q11\",\"AD_Q12\",\"TIME_start\", \"TIME_end\",\"TIME_total\"]\n",
    "]\n",
    "    \n",
    "pd.set_option(\"display.max_columns\", None)  \n",
    "AD_df_excel_data_part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af583587",
   "metadata": {},
   "source": [
    "### 2.2.3. View final activity diaries data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c904ae39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Reorganiza a ordem das colunas da DataFrame AD_df_excel_data_part.\n",
    "AD_df_excel_data_part = AD_df_excel_data_part[['Subject_Nr', 'Session_Nr', 'Data', 'AD_Q1', 'AD_Q2', 'AD_Q3', 'AD_Q4',\n",
    "                                               'AD_Q5', 'AD_Q6', 'AD_Q7', 'AD_Q8', 'AD_Q9', 'AD_Q10', 'AD_Q11', 'AD_Q12', 'TIME_start',\n",
    "                                               'TIME_end', 'TIME_total']]\n",
    "pd.set_option(\"display.max_columns\", None)  \n",
    "AD_df_excel_data_part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b460e5",
   "metadata": {},
   "source": [
    "# 3. Actigraphy database\n",
    "Generates DB with the actigraphy data collected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9f4701",
   "metadata": {},
   "source": [
    "## 3.1. Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de305a90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Opens the excel file where data from participants are stored.\n",
    "# Go up one folder (from /notebook to project root)\n",
    "PROJ_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "# Build the path safely\n",
    "csv_part_data_path = PROJ_ROOT / \"Actigraphy\" / \"part5_daysummary_WW_L30M100V400_T5A5.csv\"\n",
    "\n",
    "df_Actigraphy = pd.read_csv(csv_part_data_path, engine = 'python',sep = ',')\n",
    "df_Actigraphy.sort_values(\"ID\")\n",
    "\n",
    "#Select relevant columns from the csv produced by GeneActive.\n",
    "df_Actigraphy = df_Actigraphy[[\"ID\",\"filename\",\"sleeplog_used\",\"guider\",\"cleaningcode\",\"daysleeper\",\"night_number\",\"calendar_date\",\"weekday\",\n",
    "                                     \"nonwear_perc_day_spt\",\"sleeponset_ts\",\"wakeup_ts\",\"dur_day_spt_min\",\"dur_day_min\",\"dur_spt_min\",\n",
    "                                     \"dur_spt_wake_IN_min\",\"dur_spt_wake_LIG_min\",\"dur_spt_wake_MOD_min\",\"dur_spt_wake_VIG_min\",\"dur_day_IN_unbt_min\",\n",
    "                                     \"dur_day_LIG_unbt_min\",\"dur_day_MOD_unbt_min\",\"dur_day_VIG_unbt_min\",\"dur_spt_sleep_min\",\"sleep_efficiency\"]]\n",
    "\n",
    "\n",
    "######################################\n",
    "#Opens the excel file where data from participants are stored.\n",
    "# Go up one folder (from /notebook to project root)\n",
    "PROJ_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "# Build the path safely\n",
    "csv_part_data_path2 = PROJ_ROOT / \"Actigraphy\" / \"part4_nightsummary_sleep_cleaned.csv\"\n",
    "df_Actigraphy2 = pd.read_csv(csv_part_data_path2, engine = 'python',sep = ',')\n",
    "df_Actigraphy2.sort_values(\"ID\")\n",
    "df_Actigraphy2 = df_Actigraphy2[df_Actigraphy2['night'] == 1]\n",
    "df_Actigraphy3 = df_Actigraphy2.copy(deep=True)\n",
    "\n",
    "df_Actigraphy2 = df_Actigraphy2[[\"ID\",\"filename\",\"sleeplog_used\",\"guider\",\"cleaningcode\",\"daysleeper\",\"night\",\"calendar_date\",\"weekday\",\n",
    "                                     \"nonwear_perc_spt\",\"sleeponset_ts\",\"wakeup_ts\"]]\n",
    "df_Actigraphy2 = df_Actigraphy2.assign(dur_day_spt_min=\"\",dur_day_min=\"\",dur_spt_min=\"\",dur_spt_wake_IN_min=\"\",\n",
    "                                             dur_spt_wake_LIG_min=\"\",dur_spt_wake_MOD_min=\"\",dur_spt_wake_VIG_min=\"\",\n",
    "                                             dur_day_IN_unbt_min=\"\",dur_day_LIG_unbt_min=\"\",dur_day_MOD_unbt_min=\"\",\n",
    "                                             dur_day_VIG_unbt_min=\"\",dur_spt_sleep_min=\"\",sleep_efficiency=\"\")\n",
    "df_Actigraphy2.rename(columns={'night':'night_number','nonwear_perc_spt':'nonwear_perc_day_spt'},inplace=True)\n",
    "df_Actigraphy2 = df_Actigraphy2[[\"ID\",\"filename\",\"sleeplog_used\",\"guider\",\"cleaningcode\",\"daysleeper\",\"night_number\",\"calendar_date\",\"weekday\",\n",
    "                                     \"nonwear_perc_day_spt\",\"sleeponset_ts\",\"wakeup_ts\",\"dur_day_spt_min\",\"dur_day_min\",\"dur_spt_min\",\n",
    "                                     \"dur_spt_wake_IN_min\",\"dur_spt_wake_LIG_min\",\"dur_spt_wake_MOD_min\",\"dur_spt_wake_VIG_min\",\"dur_day_IN_unbt_min\",\n",
    "                                     \"dur_day_LIG_unbt_min\",\"dur_day_MOD_unbt_min\",\"dur_day_VIG_unbt_min\",\"dur_spt_sleep_min\",\"sleep_efficiency\"]]\n",
    "frames = [df_Actigraphy,df_Actigraphy2]\n",
    "df_Actigraphy = pd.concat(frames)\n",
    "df_Actigraphy = df_Actigraphy.sort_values(by=['ID','night_number'],ascending=[True,True])\n",
    "df_Actigraphy.reset_index(drop=True,inplace=True)\n",
    "\n",
    "pattern2 = \"_(.*?)_\"\n",
    "List_actigraph_location = []\n",
    "for i in range(len(df_Actigraphy[\"filename\"])):\n",
    "    substring = re.search(pattern2, df_Actigraphy[\"filename\"][i]).group(1)\n",
    "    List_actigraph_location.append(substring)\n",
    "LocationAcel = pd.Series(List_actigraph_location)\n",
    "df_Actigraphy.insert(2,\"LocationAcel\",LocationAcel)\n",
    "\n",
    "df_Actigraphy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bf9a25",
   "metadata": {},
   "source": [
    "## 3.2. Replacing values in multiple columns by values that make more sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9be1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Actigraphy[[\"daysleeper\",\"sleeplog_used\",\"cleaningcode\",\"calendar_date\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4940ec52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(df_Actigraphy[\"daysleeper\"])):\n",
    "    if df_Actigraphy.loc[i,\"daysleeper\"] == 0:\n",
    "        df_Actigraphy.loc[i,\"daysleeper\"] = \"day sleeper\"\n",
    "    elif df_Actigraphy.loc[i,\"daysleeper\"] == 1:\n",
    "        df_Actigraphy.loc[i,\"daysleeper\"] = \"night sleeper\"\n",
    "\n",
    "for i in range(0,len(df_Actigraphy[\"sleeplog_used\"])):\n",
    "    if df_Actigraphy.loc[i,\"sleeplog_used\"] == 0:\n",
    "        df_Actigraphy.loc[i,\"sleeplog_used\"] = \"No\"\n",
    "    elif df_Actigraphy.loc[i,\"sleeplog_used\"] == 1:\n",
    "        df_Actigraphy.loc[i,\"sleeplog_used\"] = \"Yes\"\n",
    "\n",
    "for i in range(0,len(df_Actigraphy[\"cleaningcode\"])):\n",
    "    if df_Actigraphy.loc[i,\"cleaningcode\"] == 1:\n",
    "        df_Actigraphy.loc[i,\"cleaningcode\"] = \"1: GGIR sleep log was not used. Thus, HDCZA guider was used. Only Sleep Period Time (SPT) was identified \" \\\n",
    "                                                  \"(it was not possible to indentify Time in Bed (TIB)).\"\n",
    "\n",
    "for i in range(0,len(df_Actigraphy[\"calendar_date\"])):\n",
    "    if df_Actigraphy.loc[i,\"night_number\"] == 1:\n",
    "        x = df_Actigraphy.loc[i,\"calendar_date\"].split(\"/\")\n",
    "        y = []\n",
    "        for j in x:\n",
    "            y.insert(0,j)\n",
    "        for j in range(0,len(y)):\n",
    "            if int(y[j]) < 10:\n",
    "                y[j] = '0' + y[j]\n",
    "        y = str(y)\n",
    "        y = y.replace(\"[\",\"\")\n",
    "        y = y.replace(\"]\",\"\")\n",
    "        y = y.replace(\"'\",\"\")\n",
    "        y = y.replace(\" \",\"\")\n",
    "        y = y.replace(\",\",\"-\")\n",
    "        df_Actigraphy.loc[i,\"calendar_date\"] = y\n",
    "\n",
    "List_WASO = []\n",
    "for i in range(0,len(df_Actigraphy)):\n",
    "    if df_Actigraphy.loc[i,\"night_number\"] == 1:\n",
    "        List_WASO.append(round(df_Actigraphy3.loc[i,\"WASO\"]*60,3))\n",
    "    else:\n",
    "        ind = df_Actigraphy.loc[i,\"dur_spt_wake_IN_min\"] + df_Actigraphy.loc[i,\"dur_spt_wake_LIG_min\"] + df_Actigraphy.loc[i,\"dur_spt_wake_MOD_min\"] + df_Actigraphy.loc[i,\"dur_spt_wake_VIG_min\"]\n",
    "        List_WASO.append(ind)\n",
    "row,col = df_Actigraphy.shape\n",
    "List_WASO = pd.Series(List_WASO)\n",
    "df_Actigraphy.insert(col-1,\"WASO\",List_WASO)\n",
    "\n",
    "df_Actigraphy[[\"daysleeper\",\"sleeplog_used\",\"cleaningcode\",\"calendar_date\",\"WASO\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34add51d",
   "metadata": {},
   "source": [
    "## 3.3. Replacing the number values of the columns that should be in minutes to minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bd8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Actigraphy[[\"dur_day_spt_min\",\"dur_day_min\",\"dur_spt_min\",\"dur_spt_sleep_min\",\"dur_spt_wake_IN_min\",\n",
    "                    \"dur_spt_wake_LIG_min\",\"dur_spt_wake_MOD_min\",\"dur_spt_wake_VIG_min\",\"dur_day_IN_unbt_min\",\"dur_day_LIG_unbt_min\",\n",
    "                    \"dur_day_MOD_unbt_min\",\"dur_day_VIG_unbt_min\",\"WASO\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553c32af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import timedelta, datetime\n",
    "List_target_col = [\"dur_day_spt_min\",\"dur_day_min\",\"dur_spt_min\",\"dur_spt_sleep_min\",\"dur_spt_wake_IN_min\",\n",
    "                    \"dur_spt_wake_LIG_min\",\"dur_spt_wake_MOD_min\",\"dur_spt_wake_VIG_min\",\"dur_day_IN_unbt_min\",\"dur_day_LIG_unbt_min\",\n",
    "                    \"dur_day_MOD_unbt_min\",\"dur_day_VIG_unbt_min\",\"WASO\"]\n",
    "\n",
    "for i in List_target_col:\n",
    "    for l in range(0,len(df_Actigraphy)):\n",
    "        if df_Actigraphy.loc[l,\"night_number\"] != 1:\n",
    "            if df_Actigraphy.loc[l,i] == 0:\n",
    "                df_Actigraphy.loc[l,i] = timedelta(hours=00, minutes=00, seconds=00)\n",
    "            else:\n",
    "                df_Actigraphy.loc[l,i] = timedelta(minutes=df_Actigraphy.loc[l,i])\n",
    "\n",
    "wakeupminusbedtime = []\n",
    "for i in range(0,len(df_Actigraphy)):\n",
    "    if df_Actigraphy.loc[i,\"night_number\"] == 1:\n",
    "        aaa = datetime.strptime(df_Actigraphy.loc[i,\"sleeponset_ts\"], \"%H:%M:%S\")\n",
    "        aaa = timedelta(hours=aaa.hour, minutes=aaa.minute, seconds=aaa.second)\n",
    "        if timedelta(hours=9,minutes=0,seconds=0) <= aaa <= timedelta(hours=23,minutes=59,seconds=59):\n",
    "            bbb = timedelta(hours=23,minutes=59,seconds=59) - aaa + timedelta(hours=0,minutes=0,seconds=1)\n",
    "        else:\n",
    "            bbb = timedelta(hours=00,minutes=0,seconds=0)\n",
    "        ccc = datetime.strptime(df_Actigraphy.loc[i,\"wakeup_ts\"], \"%H:%M:%S\")\n",
    "        ccc = timedelta(hours=ccc.hour, minutes=ccc.minute, seconds=ccc.second)\n",
    "        ddd = df_Actigraphy.loc[i,\"WASO\"]*60\n",
    "        ddd = timedelta(seconds=ddd)\n",
    "        if timedelta(hours=9,minutes=0,seconds=0) <= aaa <= timedelta(hours=23,minutes=59,seconds=59):\n",
    "            df_Actigraphy.loc[i,\"dur_spt_sleep_min\"] = ccc + bbb - ddd\n",
    "            wakeupminusbedtime.append(ccc + bbb)\n",
    "        else:\n",
    "            df_Actigraphy.loc[i,\"dur_spt_sleep_min\"] = ccc - aaa - ddd\n",
    "            wakeupminusbedtime.append(ccc - aaa)\n",
    "        df_Actigraphy.loc[i,\"WASO\"] = ddd\n",
    "\n",
    "#Opens the csv. file where data from participants are stored.\n",
    "Daily_Logs_df_excel_data_part = SD_df_excel_data_part.copy(deep=True)\n",
    "Daily_Logs_df_excel_data_part2 = SD_df_excel_data_part.copy(deep=True)\n",
    "\n",
    "Daily_Logs_df_excel_data_part = Daily_Logs_df_excel_data_part[[\"SD_Q2\",\"SD_Q7\"]]\n",
    "List_columns_Daily_Logs = [\"SD_Q2\",\"SD_Q7\"]\n",
    "for i in List_columns_Daily_Logs:\n",
    "    for l in range(0,len(Daily_Logs_df_excel_data_part)):\n",
    "        t = Daily_Logs_df_excel_data_part.loc[l,i]\n",
    "        Daily_Logs_df_excel_data_part.loc[l,i] = timedelta(hours=t.hour, minutes=t.minute, seconds=t.second)\n",
    "df_Actigraphy.insert(11,\"Bedtime\",Daily_Logs_df_excel_data_part[\"SD_Q2\"])\n",
    "df_Actigraphy.insert(14,\"Risetime\",Daily_Logs_df_excel_data_part[\"SD_Q7\"])\n",
    "\n",
    "List_columns_sleeponset_wakeup = [\"sleeponset_ts\",\"wakeup_ts\"]\n",
    "for i in List_columns_sleeponset_wakeup:\n",
    "    for l in range(0,len(df_Actigraphy)):\n",
    "        t = datetime.strptime(df_Actigraphy.loc[l,i], \"%H:%M:%S\")\n",
    "        df_Actigraphy.loc[l,i] = timedelta(hours=t.hour, minutes=t.minute, seconds=t.second)\n",
    "\n",
    "aaa = timedelta(hours=00, minutes=00, seconds=00)\n",
    "bbb = timedelta(hours=7, minutes=00, seconds=00)\n",
    "ccc = timedelta(hours=24, minutes=00, seconds=00)\n",
    "\n",
    "temp_sleep_onset = aaa\n",
    "temp_Bedtime = aaa\n",
    "List_SOL = []\n",
    "df_Actigraphy[\"Bedtime\"] = pd.to_timedelta(df_Actigraphy[\"Bedtime\"], errors=\"coerce\")\n",
    "df_Actigraphy[\"Risetime\"] = pd.to_timedelta(df_Actigraphy[\"Risetime\"], errors=\"coerce\")\n",
    "for i in range(0,len(df_Actigraphy)):\n",
    "    if df_Actigraphy.loc[i,\"sleeponset_ts\"] < bbb:\n",
    "        temp_sleep_onset = df_Actigraphy.loc[i,\"sleeponset_ts\"] + ccc\n",
    "    else:\n",
    "        temp_sleep_onset = df_Actigraphy.loc[i,\"sleeponset_ts\"]\n",
    "    if df_Actigraphy.loc[i,\"Bedtime\"] < bbb:\n",
    "        temp_Bedtime = df_Actigraphy.loc[i, \"Bedtime\"] + ccc\n",
    "    else:\n",
    "        temp_Bedtime = df_Actigraphy.loc[i, \"Bedtime\"]\n",
    "    if temp_sleep_onset < temp_Bedtime:\n",
    "        df_Actigraphy.loc[i, \"sleeponset_ts\"] = df_Actigraphy.loc[i, \"Bedtime\"]\n",
    "    temp_SOL = temp_sleep_onset - temp_Bedtime\n",
    "    if temp_SOL < aaa:\n",
    "        temp_SOL = aaa\n",
    "    List_SOL.append(temp_SOL)\n",
    "df_Actigraphy.insert(col,\"SOL\",List_SOL)\n",
    "\n",
    "for i in range(0,len(df_Actigraphy)):\n",
    "    if df_Actigraphy.loc[i,\"wakeup_ts\"] > df_Actigraphy.loc[i,\"Risetime\"]:\n",
    "        df_Actigraphy.loc[i,\"wakeup_ts\"] = df_Actigraphy.loc[i,\"Risetime\"]\n",
    "\n",
    "List_TASAFA = []\n",
    "for i in range(0,len(df_Actigraphy)):\n",
    "    temp_TASAFA = df_Actigraphy.loc[i, \"Risetime\"] - df_Actigraphy.loc[i, \"wakeup_ts\"]\n",
    "    if temp_TASAFA < aaa:\n",
    "        temp_TASAFA = aaa\n",
    "    List_TASAFA.append(temp_TASAFA)\n",
    "df_Actigraphy.insert(col+3,\"TASAFA\",List_TASAFA)\n",
    "\n",
    "List_DSE = []\n",
    "for i in range(0,len(df_Actigraphy)):\n",
    "    temp_DSE = df_Actigraphy.loc[i,\"SOL\"] + df_Actigraphy.loc[i,\"dur_spt_sleep_min\"] + df_Actigraphy.loc[i,\"WASO\"] + df_Actigraphy.loc[i,\"TASAFA\"]\n",
    "    List_DSE.append(temp_DSE)\n",
    "df_Actigraphy[\"DSE\"] = List_DSE\n",
    "\n",
    "List_SEF = []\n",
    "for i in range(0,len(df_Actigraphy)):\n",
    "    temp_SEF = round(df_Actigraphy.loc[i,\"dur_spt_sleep_min\"] / df_Actigraphy.loc[i,\"DSE\"],3)\n",
    "    List_SEF.append(temp_SEF)\n",
    "df_Actigraphy[\"Sleep Efficiency TST(Act)/DSE(Act)\"] = List_SEF\n",
    "\n",
    "columns_re = [\"ID\",\"filename\",\"LocationAcel\",\"sleeplog_used\",\"guider\",\"cleaningcode\",\"daysleeper\",\"night_number\",\"calendar_date\",\n",
    "              \"weekday\",\"nonwear_perc_day_spt\",\"Bedtime\",\"sleeponset_ts\",\"wakeup_ts\",\"Risetime\",\"SOL\",\"dur_spt_sleep_min\",\"WASO\",\n",
    "              \"TASAFA\",\"DSE\",\"sleep_efficiency\",\"Sleep Efficiency TST(Act)/DSE(Act)\",\"dur_day_spt_min\",\"dur_day_min\",\"dur_spt_min\",\n",
    "              \"dur_spt_wake_IN_min\",\"dur_spt_wake_LIG_min\",\"dur_spt_wake_MOD_min\",\"dur_spt_wake_VIG_min\",\"dur_day_IN_unbt_min\",\n",
    "              \"dur_day_LIG_unbt_min\",\"dur_day_MOD_unbt_min\",\"dur_day_VIG_unbt_min\"]\n",
    "\n",
    "\n",
    "df_Actigraphy = df_Actigraphy.reindex(columns=columns_re)\n",
    "col_names = [\"ID\",\"filename\",\"LocationAcel\",\"sleeplog_used\",\"guider\",\"cleaningcode\",\"daysleeper\",\"night_number\",\"calendar_date\",\n",
    "              \"weekday\",\"nonwear_perc\",\"Bedtime\",\"Sleep Onset\",\"Wakeup Time\",\"Rise Time\",\"SOL\",\"TST\",\"WASO\",\n",
    "              \"TASAFA\",\"DSE\",\"Sleep Efficiency GGIR (TST/(Wakeup-Sleep Onset))\",\"Sleep Efficiency TST(Act)/DSE(Act)\",\n",
    "             \"Duration Day+Sleep episodes\",\"Duration Day Episode\",\"Duration Sleep Episode (Wakeup-Sleep Onset)\",\n",
    "             \"Duration Inactive in Sleep Episode\",\"Duration Light Activity in Sleep Episode\",\n",
    "             \"Duration Moderate Activity in Sleep Episode\",\"Duration Vigorous Activity in Sleep Episode\",\n",
    "             \"Duration Inactive in Day Episode\",\"Duration Light Activity in Day Episode\",\n",
    "             \"Duration Moderate Activity in Day Episode\",\"Duration Vigorous Activity in Day Episode\"]\n",
    "\n",
    "df_Actigraphy.columns = col_names\n",
    "\n",
    "indexx = 0\n",
    "for i in range(0,len(df_Actigraphy)):\n",
    "    if df_Actigraphy.loc[i,\"night_number\"] == 1:\n",
    "        df_Actigraphy.loc[i,\"Sleep Efficiency GGIR (TST/(Wakeup-Sleep Onset))\"] = round(df_Actigraphy.loc[i,\"TST\"]/wakeupminusbedtime[indexx],3)\n",
    "        df_Actigraphy.loc[i,\"Duration Sleep Episode (Wakeup-Sleep Onset)\"] = wakeupminusbedtime[indexx]\n",
    "        indexx += 1\n",
    "    else:\n",
    "        if df_Actigraphy.loc[i,\"Sleep Onset\"] > bbb:\n",
    "            temp_sleep_onset = ccc - df_Actigraphy.loc[i,\"Sleep Onset\"]\n",
    "            df_Actigraphy.loc[i,\"Sleep Efficiency GGIR (TST/(Wakeup-Sleep Onset))\"] = round(df_Actigraphy.loc[i,\"TST\"]/(df_Actigraphy.loc[i,\"Wakeup Time\"] + temp_sleep_onset),3)\n",
    "        else:\n",
    "            df_Actigraphy.loc[i, \"Sleep Efficiency GGIR (TST/(Wakeup-Sleep Onset))\"] = round(df_Actigraphy.loc[i, \"TST\"]/(df_Actigraphy.loc[i, \"Wakeup Time\"] - df_Actigraphy.loc[i,\"Sleep Onset\"]), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121f45d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Actigraphy[[\"Duration Day+Sleep episodes\",\"Duration Day Episode\",\"Duration Sleep Episode (Wakeup-Sleep Onset)\",\n",
    "             \"Duration Inactive in Sleep Episode\",\"Duration Light Activity in Sleep Episode\",\n",
    "             \"Duration Moderate Activity in Sleep Episode\",\"Duration Vigorous Activity in Sleep Episode\",\n",
    "             \"Duration Inactive in Day Episode\",\"Duration Light Activity in Day Episode\",\n",
    "             \"Duration Moderate Activity in Day Episode\",\"Duration Vigorous Activity in Day Episode\",\"WASO\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a3cc8b",
   "metadata": {},
   "source": [
    "## 3.4. Rounding values to make reading the df more friendly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b0e915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of time-like columns\n",
    "time_cols = [\n",
    "    \"Bedtime\",\n",
    "    \"Sleep Onset\",\n",
    "    \"Wakeup Time\",\n",
    "    \"Rise Time\",\n",
    "    \"SOL\",\n",
    "    \"TST\",\n",
    "    \"WASO\",\n",
    "    \"TASAFA\",\n",
    "    \"DSE\",\n",
    "    \"Duration Day+Sleep episodes\",\n",
    "    \"Duration Day Episode\",\n",
    "    \"Duration Sleep Episode (Wakeup-Sleep Onset)\",\n",
    "    \"Duration Inactive in Sleep Episode\",\n",
    "    \"Duration Light Activity in Sleep Episode\",\n",
    "    \"Duration Moderate Activity in Sleep Episode\",\n",
    "    \"Duration Vigorous Activity in Sleep Episode\",\n",
    "    \"Duration Inactive in Day Episode\",\n",
    "    \"Duration Light Activity in Day Episode\",\n",
    "    \"Duration Moderate Activity in Day Episode\",\n",
    "    \"Duration Vigorous Activity in Day Episode\"\n",
    "]\n",
    "\n",
    "# ensure they're timedelta first\n",
    "df_Actigraphy[time_cols] = df_Actigraphy[time_cols].apply(pd.to_timedelta, errors=\"coerce\")\n",
    "\n",
    "# convert timedelta → string \"HH:MM:SS\"\n",
    "for col in time_cols:\n",
    "    df_Actigraphy[col] = df_Actigraphy[col].apply(\n",
    "        lambda x: (\n",
    "            f\"{int(x.total_seconds() // 3600):02d}:\"\n",
    "            f\"{int((x.total_seconds() % 3600) // 60):02d}:\"\n",
    "            f\"{int(x.total_seconds() % 60):02d}\"\n",
    "        ) if pd.notna(x) else \"\"\n",
    "    )\n",
    "\n",
    "\n",
    "cols_to_round = [\n",
    "    \"nonwear_perc\",\n",
    "    \"Sleep Efficiency GGIR (TST/(Wakeup-Sleep Onset))\",\n",
    "    \"Sleep Efficiency TST(Act)/DSE(Act)\"\n",
    "]\n",
    "df_Actigraphy[cols_to_round] = df_Actigraphy[cols_to_round].round(2)\n",
    "df_Actigraphy[[\"Duration Day+Sleep episodes\",\"Duration Day Episode\",\"Duration Sleep Episode (Wakeup-Sleep Onset)\",\n",
    "             \"Duration Inactive in Sleep Episode\",\"Duration Light Activity in Sleep Episode\",\n",
    "             \"Duration Moderate Activity in Sleep Episode\",\"Duration Vigorous Activity in Sleep Episode\",\n",
    "             \"Duration Inactive in Day Episode\",\"Duration Light Activity in Day Episode\",\n",
    "             \"Duration Moderate Activity in Day Episode\",\"Duration Vigorous Activity in Day Episode\",\"WASO\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bbbcc5",
   "metadata": {},
   "source": [
    "## 3.5. View final DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef65880",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)  \n",
    "df_Actigraphy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af83fc7d",
   "metadata": {},
   "source": [
    "# 4. WM tasks Practice Session database\n",
    "Generates DB with the performance data in the WM tasks collected in the practice sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aaaa6f",
   "metadata": {},
   "source": [
    "## 4.1. Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b423216",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-24b771d40f9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\fabio\\OneDrive\\Área de Trabalho\\RPubs\\Article 3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m\"data_participants_practice\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcsv_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"*.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "base = Path(r\"C:\\Users\\fabio\\OneDrive\\Área de Trabalho\\RPubs\\Article 3\")\n",
    "data_dir = base / \"data_participants_practice\"\n",
    "\n",
    "csv_files = sorted(data_dir.glob(\"*.csv\"))\n",
    "\n",
    "def try_read(p):\n",
    "    # Try common CSV variants in Europe/Windows/Excel contexts\n",
    "    tries = [\n",
    "        dict(sep=None, engine=\"python\", encoding=\"utf-8-sig\"),  # auto-detect sep, UTF-8 BOM\n",
    "        dict(sep=\";\",  engine=\"python\", encoding=\"utf-8-sig\"),\n",
    "        dict(sep=\",\",  engine=\"python\", encoding=\"utf-8-sig\"),\n",
    "\n",
    "        dict(sep=None, engine=\"python\", encoding=\"latin-1\"),\n",
    "        dict(sep=\";\",  engine=\"python\", encoding=\"latin-1\"),\n",
    "        dict(sep=\",\",  engine=\"python\", encoding=\"latin-1\"),\n",
    "\n",
    "        # If the file is actually UTF-16 (common from Excel “Unicode Text” export)\n",
    "        dict(sep=\"\\t\", engine=\"python\", encoding=\"utf-16\"),   # TSV-like\n",
    "        dict(sep=\",\",  engine=\"python\", encoding=\"utf-16\"),\n",
    "        dict(sep=\";\",  engine=\"python\", encoding=\"utf-16\"),\n",
    "    ]\n",
    "\n",
    "    last_err = None\n",
    "    for kw in tries:\n",
    "        try:\n",
    "            # older pandas: use error_bad_lines/warn_bad_lines\n",
    "            return pd.read_csv(str(p), error_bad_lines=False, warn_bad_lines=False, **kw)\n",
    "        except TypeError:\n",
    "            # if your pandas is *very* old and doesn’t accept some kwargs, try minimal\n",
    "            try:\n",
    "                return pd.read_csv(str(p), **{k:v for k,v in kw.items() if k in (\"sep\",\"engine\",\"encoding\")})\n",
    "            except Exception as e:\n",
    "                last_err = e\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    raise last_err\n",
    "\n",
    "dfs = []\n",
    "for p in csv_files:\n",
    "    df = try_read(p)\n",
    "    dfs.append(df)\n",
    "\n",
    "df_total_part = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "df_total_part.reset_index(inplace=True)\n",
    "\n",
    "#Substitui dados que deviam estar listados como missing values ('undefined'), por missing values ('Nan')\n",
    "df_total_part = df_total_part.replace('undefined','Nan')\n",
    "\n",
    "#Puxa a coluna com o nome da tarefa que foi realizado neste ensaio e número do participante para a primeira e\n",
    "#segunda coluna respetivamente.\n",
    "first_column = df_total_part.pop('Task_Name')\n",
    "second_column = df_total_part.pop('subject_nr')\n",
    "df_total_part.insert(0, 'Task_Name', first_column)\n",
    "df_total_part.insert(1, 'subject_nr', second_column)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "df_total_part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674e28ea",
   "metadata": {},
   "source": [
    "## 4.2. Generates DB with data regarding each WM task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c497321b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_Reading_Span_Practice = df_total_part[df_total_part['Task_Name'] == 'Reading Span']\n",
    "df_Reading_Span_Practice = df_Reading_Span_Practice.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "\n",
    "df_WMU_Task_Practice = df_total_part[df_total_part['Task_Name'] == 'Working Memory Updating Task']\n",
    "df_WMU_Task_Practice = df_WMU_Task_Practice.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "\n",
    "df_Symmetry_Span_Practice = df_total_part[df_total_part['Task_Name'] == 'Symmetry Span']\n",
    "df_Symmetry_Span_Practice = df_Symmetry_Span_Practice.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "\n",
    "df_Binding_Task_Practice = df_total_part[df_total_part['Task_Name'] == 'Binding Task']\n",
    "df_Binding_Task_Practice = df_Binding_Task_Practice.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "\n",
    "df_Operation_Span_Practice = df_total_part[df_total_part['Task_Name'] == 'Operation Span']\n",
    "df_Operation_Span_Practice = df_Operation_Span_Practice.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "\n",
    "########################################################################################################\n",
    "#Os próximos 5 blocos de código selecionam as colunas com informação relevante de cada WM task e guardam estas colunas em DataFrames\n",
    "#que só contêm informação relacionada com a mesma tarefa. Para além disso, estes nestes 5 blocos de código, são realizadas algumas\n",
    "#conversões no formato dos dados (e.g., string to float) e são alterados os nomes de algumas colunas de forma a ficarem mais percétiveis.\n",
    "#'selSNr',\n",
    "df_Reading_Span_Practice = df_Reading_Span_Practice[\n",
    "    ['subject_nr',  'CB_ref', 'practice', 'TrialNumber', 'Sub_bloco', 'SubTaskName', 'acc', 'avg_rt',\n",
    "     'BlockChoice', 'correct', 'correct_response', 'Frase', 'height', 'letter', 'List_Prev_Letter',\n",
    "     'List_responses_memory', 'live_row', 'logfile', 'response_average_time_memory', 'response_memory',\n",
    "     'response_processing', 'response_time_memory', 'response_time_processing', 'response_total_time_memory',\n",
    "     'RP_part_process_time', 'score_practice', 'score_reading_span', 'score_subblock_2', 'score_subblock_3', 'score_subblock_4',\n",
    "     'score_subblock_5', 'score_subblock_6', 'Tipo', 'total_correct',\n",
    "     'total_response_time', 'total_responses', 'width']]\n",
    "df_Reading_Span_Practice[['acc', 'avg_rt']] = df_Reading_Span_Practice[['acc', 'avg_rt']].replace(',', '.')\n",
    "df_Reading_Span_Practice = df_Reading_Span_Practice.astype(\n",
    "    {'acc': 'float64', 'avg_rt': 'float64', 'correct_response': 'str', 'response_processing': 'str'})\n",
    "example_b = df_Reading_Span_Practice[\"response_processing\"].iloc[2]\n",
    "df_Reading_Span_Practice = df_Reading_Span_Practice.replace(example_b, '')\n",
    "#df_Reading_Span_Practice_1 = df_Reading_Span_Practice_1.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_Reading_Span_Practice_1 = df_Reading_Span_Practice_1.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Reading_Span_Practice.columns = ['subject_nr','CB_ref','practice','TrialNumber','Sub_bloco',\n",
    "                             'SubTaskName','acc_Practice_Sess','avg_rt_Practice_Sess','BlockChoice_Practice_Sess','correct_Practice_Sess','correct_response_Practice_Sess',\n",
    "                             'Frase_Practice_Sess','height_Practice_Sess','letter_Practice_Sess','List_Prev_Letter_Practice_Sess','List_responses_memory_Practice_Sess',\n",
    "                             'live_row_Practice_Sess','logfile_Practice_Sess','response_average_time_memory_Practice_Sess','response_memory_Practice_Sess',\n",
    "                             'response_processing_Practice_Sess','response_time_memory_Practice_Sess','response_time_processing_Practice_Sess',\n",
    "                             'response_total_time_memory_Practice_Sess','RP_part_process_time_Practice_Sess','score_practice_Practice_Sess',\n",
    "                             'score_reading_span_Practice_Sess','score_subblock_2_Practice_Sess','score_subblock_3_Practice_Sess','score_subblock_4_Practice_Sess',\n",
    "                             'score_subblock_5_Practice_Sess','score_subblock_6_Practice_Sess','Tipo_Practice_Sess','total_correct_Practice_Sess',\n",
    "                             'total_response_time_Practice_Sess','total_responses_Practice_Sess','width_Practice_Sess']\n",
    "\n",
    "############################################################################################\n",
    "############################################################################################\n",
    "#'toUpdate1_1', 'toUpdate1_2', 'toUpdate1_3', 'toUpdate2_1', 'toUpdate2_2','toUpdate2_3','correct_response1', 'correct_response2', 'correct_response3',\n",
    "#'selSNr',\n",
    "df_WMU_Task_Practice = df_WMU_Task_Practice[\n",
    "    ['subject_nr',  'CB_ref', 'practice', 'TrialNumber', 'correct1', 'correct2', 'correct3', 'digit1', 'digit2', 'digit3', 'height',\n",
    "     'Index_List', 'live_row', 'logfile', 'response1', 'response2', 'response3', 'response_time1', 'responseavgRT',\n",
    "     'total_correct_trial', 'TotalRtBlock',  'WMUExperimentalScore', 'WMUPracticeScore', 'width']]\n",
    "df_WMU_Task_Practice = df_WMU_Task_Practice.rename(columns={'response_time1': 'response_time'})\n",
    "\n",
    "for i in range(0, len(df_WMU_Task_Practice['responseavgRT'])):\n",
    "    if df_WMU_Task_Practice['responseavgRT'].iloc[i] == 0:\n",
    "        df_WMU_Task_Practice['responseavgRT'].iloc[i] = ''\n",
    "df_WMU_Task_Practice.columns = ['subject_nr','CB_ref','practice','TrialNumber','correct1_Practice_Sess',\n",
    "                         'correct2_Practice_Sess','correct3_Practice_Sess','digit1_Practice_Sess','digit2_Practice_Sess','digit3_Practice_Sess','height_Practice_Sess',\n",
    "                         'Index_List_Practice_Sess','live_row_Practice_Sess','logfile_Practice_Sess','response1_Practice_Sess','response2_Practice_Sess','response3_Practice_Sess',\n",
    "                         'response_time1_Practice_Sess','responseavgRT_Practice_Sess','total_correct_trial_Practice_Sess','TotalRtBlock_Practice_Sess',\n",
    "                         'WMUExperimentalScore_Practice_Sess','WMUPracticeScore_Practice_Sess','width_Practice_Sess']\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "#'selSNr',\n",
    "df_Symmetry_Span_Practice = df_Symmetry_Span_Practice[\n",
    "    ['subject_nr', 'CB_ref', 'practice', 'TrialNumber', 'Sub_bloco', 'SubTaskName',\n",
    "     'aggregated_score_memory', 'average_response_time_processing', 'average_total_time_memory', 'correct',\n",
    "     'correct_response', 'countDys', 'countSym', 'height', 'LeftHalfPos', 'List_SS_button', 'List_SS_Pos', 'live_row',\n",
    "     'logfile', 'maxDys', 'maxSym', 'pressed_buttons', 'response_memory', 'response_processing', 'response_time_memory',\n",
    "     'response_time_processing', 'response_total_time_memory', 'response_total_time_memory_full_task', 'RightHalfPos',\n",
    "     'SP_part_process_time', 'SS_practice_score', 'score_symmetry_span', 'score_subblock_2', 'score_subblock_3',\n",
    "     'score_subblock_4', 'score_subblock_5', 'score_subblock_6', 'SymType',\n",
    "     'total_correct_processing', 'total_response_time_processing', 'width']]\n",
    "df_Symmetry_Span_Practice = df_Symmetry_Span_Practice.astype({'correct_response': 'str', 'response_processing': 'str'})\n",
    "example_d = df_Symmetry_Span_Practice[\"response_processing\"].iloc[2]\n",
    "df_Symmetry_Span_Practice = df_Symmetry_Span_Practice.replace(example_d, '')\n",
    "#df_Symmetry_Span_Practice_1 = df_Symmetry_Span_Practice_1.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_Symmetry_Span_Practice_1 = df_Symmetry_Span_Practice_1.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Symmetry_Span_Practice.columns = ['subject_nr','CB_ref','practice','TrialNumber','Sub_bloco',\n",
    "                              'SubTaskName','aggregated_score_memory_Practice_Sess','average_response_time_processing_Practice_Sess',\n",
    "                              'average_total_time_memory_Practice_Sess','correct_Practice_Sess','correct_response_Practice_Sess','countDys_Practice_Sess',\n",
    "                              'countSym_Practice_Sess','height_Practice_Sess','LeftHalfPos_Practice_Sess','List_SS_button_Practice_Sess','List_SS_Pos_Practice_Sess',\n",
    "                              'live_row_Practice_Sess','logfile_Practice_Sess','maxDys_Practice_Sess','maxSym_Practice_Sess','pressed_buttons_Practice_Sess',\n",
    "                              'response_memory_Practice_Sess','response_processing_Practice_Sess','response_time_memory_Practice_Sess',\n",
    "                              'response_time_processing_Practice_Sess','response_total_time_memory_Practice_Sess',\n",
    "                              'response_total_time_memory_full_task_Practice_Sess','RightHalfPos_Practice_Sess','SP_part_process_time_Practice_Sess',\n",
    "                              'SS_practice_score_Practice_Sess','score_symmetry_span_Practice_Sess','score_subblock_2_Practice_Sess','score_subblock_3_Practice_Sess',\n",
    "                              'score_subblock_4_Practice_Sess','score_subblock_5_Practice_Sess','score_subblock_6_Practice_Sess','SymType_Practice_Sess',\n",
    "                              'total_correct_processing_Practice_Sess','total_response_time_processing_Practice_Sess','width_Practice_Sess']\n",
    "\n",
    "############################################################################################\n",
    "############################################################################################\n",
    "#'Probe', 'Target',\n",
    "#'selSNr',\n",
    "df_Binding_Task_Practice = df_Binding_Task_Practice[\n",
    "    ['subject_nr', 'CB_ref', 'practice', 'TrialNumber', 'acc', 'average_response_time',\n",
    "     'BindingRawScore', 'correct', 'correct_response', 'counter', 'Delay', 'eightsec_accuracy', 'FalseAlarms', 'height',\n",
    "     'Hits', 'live_row', 'logfile', 'match_1s_accuracy', 'match_1s_avg_rt', 'match_8s_accuracy', 'match_8s_avg_rt',\n",
    "     'mismatch_1s_accuracy', 'mismatch_1s_avg_rt', 'mismatch_8s_accuracy', 'mismatch_8s_avg_rt', 'NNonResponses',\n",
    "     'Omissions', 'onesec_accuracy', 'QuinetteAccuracyScore', 'QuinetteProcessingScore', 'response',\n",
    "     'response_time', 'ResponsesGiven', 'total_correct', 'total_match_1s_rt', 'total_match_8s_rt',\n",
    "     'total_mismatch_1s_rt', 'total_mismatch_8s_rt', 'total_response_time', 'total_responses', 'width']]\n",
    "df_Binding_Task_Practice[['acc', 'average_response_time']] = df_Binding_Task_Practice[['acc', 'average_response_time']].replace(',', '.')\n",
    "df_Binding_Task_Practice = df_Binding_Task_Practice.astype(\n",
    "    {'acc': 'float64', 'average_response_time': 'float64', 'correct_response': 'str', 'response': 'str'})\n",
    "#df_Binding_Task_Practice_1 = df_Binding_Task_Practice_1.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_Binding_Task_Practice_1 = df_Binding_Task_Practice_1.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Binding_Task_Practice.columns = ['subject_nr','CB_ref','practice','TrialNumber','acc_Practice_Sess',\n",
    "                             'average_response_time_Practice_Sess','BindingRawScore_Practice_Sess','correct_Practice_Sess','correct_response_Practice_Sess',\n",
    "                             'counter_Practice_Sess','Delay_Practice_Sess','eightsec_accuracy_Practice_Sess','FalseAlarms_Practice_Sess','height_Practice_Sess','Hits_Practice_Sess',\n",
    "                             'live_row_Practice_Sess','logfile_Practice_Sess','match_1s_accuracy_Practice_Sess','match_1s_avg_rt_Practice_Sess','match_8s_accuracy_Practice_Sess',\n",
    "                             'match_8s_avg_rt_Practice_Sess','mismatch_1s_accuracy_Practice_Sess','mismatch_1s_avg_rt_Practice_Sess','mismatch_8s_accuracy_Practice_Sess',\n",
    "                             'mismatch_8s_avg_rt_Practice_Sess','NNonResponses_Practice_Sess','Omissions_Practice_Sess','onesec_accuracy_Practice_Sess',\n",
    "                             'QuinetteAccuracyScore_Practice_Sess','QuinetteProcessingScore_Practice_Sess','response_Practice_Sess','response_time_Practice_Sess',\n",
    "                             'ResponsesGiven_Practice_Sess','total_correct_Practice_Sess','total_match_1s_rt_Practice_Sess','total_match_8s_rt_Practice_Sess',\n",
    "                             'total_mismatch_1s_rt_Practice_Sess','total_mismatch_8s_rt_Practice_Sess','total_response_time_Practice_Sess','total_responses_Practice_Sess',\n",
    "                             'width_Practice_Sess']\n",
    "\n",
    "############################################################################################\n",
    "############################################################################################\n",
    "#'selSNr',\n",
    "df_Operation_Span_Practice = df_Operation_Span_Practice[\n",
    "    ['subject_nr', 'CB_ref', 'practice', 'TrialNumber', 'Sub_bloco', 'SubTaskName', 'acc', 'avg_rt',\n",
    "     'BlockChoice', 'correct', 'correct_response', 'height', 'letter', 'List_Prev_Letter', 'List_responses_memory',\n",
    "     'live_row', 'logfile', 'response_average_time_memory', 'response_memory', 'response_processing',\n",
    "     'response_time_memory', 'response_time_processing', 'response_total_time_memory', 'OP_part_process_time',\n",
    "     'score_practice', 'score_operation_span', 'score_subblock_2', 'score_subblock_3', 'score_subblock_4', 'score_subblock_5',\n",
    "     'score_subblock_6', 'Tipo', 'total_correct', 'total_response_time',\n",
    "     'total_responses', 'width']]\n",
    "df_Operation_Span_Practice[['acc', 'avg_rt']] = df_Operation_Span_Practice[['acc', 'avg_rt']].replace(',', '.')\n",
    "df_Operation_Span_Practice = df_Operation_Span_Practice.astype(\n",
    "    {'acc': 'float64', 'avg_rt': 'float64', 'correct_response': 'str', 'response_processing': 'str'})\n",
    "example_c = df_Operation_Span_Practice[\"response_processing\"].iloc[2]\n",
    "df_Operation_Span_Practice = df_Operation_Span_Practice.replace(example_c, '')\n",
    "#df_Operation_Span_Practice_1 = df_Operation_Span_Practice_1.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_Operation_Span_Practice_1 = df_Operation_Span_Practice_1.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Operation_Span_Practice.columns = ['subject_nr','CB_ref','practice','TrialNumber','Sub_bloco',\n",
    "                               'SubTaskName','acc_Practice_Sess','avg_rt_Practice_Sess','BlockChoice_Practice_Sess','correct_Practice_Sess',\n",
    "                               'correct_response_Practice_Sess','height_Practice_Sess','letter_Practice_Sess','List_Prev_Letter_Practice_Sess',\n",
    "                               'List_responses_memory_Practice_Sess','live_row_Practice_Sess','logfile_Practice_Sess','response_average_time_memory_Practice_Sess',\n",
    "                               'response_memory_Practice_Sess','response_processing_Practice_Sess','response_time_memory_Practice_Sess',\n",
    "                               'response_time_processing_Practice_Sess','response_total_time_memory_Practice_Sess','OP_part_process_time_Practice_Sess',\n",
    "                               'score_practice_Practice_Sess','score_operation_span_Practice_Sess','score_subblock_2_Practice_Sess','score_subblock_3_Practice_Sess',\n",
    "                               'score_subblock_4_Practice_Sess','score_subblock_5_Practice_Sess','score_subblock_6_Practice_Sess','Tipo_Practice_Sess',\n",
    "                               'total_correct_Practice_Sess','total_response_time_Practice_Sess','total_responses_Practice_Sess','width_Practice_Sess']\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "df_Reading_Span_Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503b7ea8",
   "metadata": {},
   "source": [
    "## 4.3. Generates DB with the raw scores in the 5 WM tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985f9e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_scores = pd.DataFrame()\n",
    "\n",
    "##Inserts column with subject number in the the df that will contain the raw scores of each task\n",
    "subj_nr = df_total_part[\"subject_nr\"].unique()\n",
    "df_raw_scores.insert(0,'subject_nr',subj_nr)\n",
    "\n",
    "##############################################################################################################\n",
    "##Inserts column with temperature in the the df that will contain the raw scores of each task\n",
    "Temperature = pd.read_excel(r'C:\\Users\\fabio\\OneDrive\\Área de Trabalho\\RPubs\\Article 3\\Temperature\\Body_Temperature_Collection.xlsx',sheet_name='TempPractice')\n",
    "\n",
    "aa = df_raw_scores[\"subject_nr\"].astype(\"int\")\n",
    "\n",
    "ii = 0\n",
    "k = 0\n",
    "\n",
    "for i in Temperature[\"Subject ID\"]:\n",
    "    if int(i) in aa.values:\n",
    "        df_raw_scores[\"Temperature (°C) Practice Sess\"] = Temperature[\"Temperature (°C) Practice Sess\"][ii]\n",
    "    ii += 1\n",
    "    k =+ 1\n",
    "\n",
    "########################################################################################################\n",
    "#Calculates and inserts the raw score of each participant in each WM task\n",
    "RawRS = list(df_Reading_Span_Practice.groupby(['subject_nr'], sort=True)['score_reading_span_Practice_Sess'].max() * 20)\n",
    "df_raw_scores[\"Reading Span Practice Session\"] = RawRS\n",
    "\n",
    "RawUT = list(df_WMU_Task_Practice.groupby(['subject_nr'], sort=True)['WMUExperimentalScore_Practice_Sess'].max())\n",
    "df_raw_scores[\"Updating Task Practice Session\"] = RawUT\n",
    "\n",
    "RawSS = list(df_Symmetry_Span_Practice.groupby(['subject_nr'], sort=True)['score_symmetry_span_Practice_Sess'].max() * 20)\n",
    "df_raw_scores[\"Symmetry Span Practice Session\"] = RawSS\n",
    "\n",
    "RawBT = list(df_Binding_Task_Practice.groupby(['subject_nr'], sort=True)['BindingRawScore_Practice_Sess'].max())\n",
    "df_raw_scores[\"Binding Task Practice Session\"] = RawBT\n",
    "\n",
    "RawOS = list(df_Operation_Span_Practice.groupby(['subject_nr'], sort=True)['score_operation_span_Practice_Sess'].max() * 20)\n",
    "df_raw_scores[\"Operation Span Practice Session\"] = RawOS\n",
    "\n",
    "df_raw_scores[\"subject_nr\"] = pd.to_numeric(df_raw_scores[\"subject_nr\"], errors=\"coerce\")\n",
    "df_raw_scores = df_raw_scores.sort_values(by=\"subject_nr\").reset_index(drop=True)\n",
    "df_raw_scores = df_raw_scores.astype({\n",
    "    col: 'int' \n",
    "    for col in df_raw_scores.columns \n",
    "    if col not in ['subject_nr', 'Temperature (°C) Practice Sess']\n",
    "})\n",
    "\n",
    "df_raw_scores_pract = df_raw_scores.sort_values(by=\"subject_nr\")\n",
    "df_raw_scores_pract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f371a39",
   "metadata": {},
   "source": [
    "## 4.4. Generates DB with the normalized scores in the 5 WM tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949512d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########################################################################################################################################\n",
    "######Criação da DataFrame com os valores normalizados obtidos por cada participante em cada uma das provas em que realizaram (e com os\n",
    "#####dados socio-demografcos).\n",
    "df_normalized_scores = df_raw_scores.copy(deep=True)\n",
    "\n",
    "df_normalized_scores[\"Reading Span Practice Session\"] = df_normalized_scores[\"Reading Span Practice Session\"]/20\n",
    "df_normalized_scores[\"Updating Task Practice Session\"] = df_normalized_scores[\"Updating Task Practice Session\"] / 36\n",
    "df_normalized_scores[\"Symmetry Span Practice Session\"] = df_normalized_scores[\"Symmetry Span Practice Session\"] / 20\n",
    "df_normalized_scores[\"Binding Task Practice Session\"] = df_normalized_scores[\"Binding Task Practice Session\"] / 12\n",
    "df_normalized_scores[\"Operation Span Practice Session\"] = df_normalized_scores[\"Operation Span Practice Session\"] / 20\n",
    "\n",
    "cols_to_round = [\n",
    "    \"Reading Span Practice Session\",\n",
    "    \"Updating Task Practice Session\",\n",
    "    \"Symmetry Span Practice Session\",\n",
    "    \"Binding Task Practice Session\",\n",
    "    \"Operation Span Practice Session\",\n",
    "]\n",
    "\n",
    "df_normalized_scores[cols_to_round] = (\n",
    "    df_normalized_scores[cols_to_round]\n",
    "    .apply(pd.to_numeric, errors=\"coerce\")  # converts text to numbers safely\n",
    "    .round(2)  # rounds to 2 decimal places\n",
    ")\n",
    "\n",
    "df_normalized_scores[\"subject_nr\"] = pd.to_numeric(df_normalized_scores[\"subject_nr\"], errors=\"coerce\")\n",
    "df_normalized_scores = df_normalized_scores.sort_values(by=\"subject_nr\").reset_index(drop=True)\n",
    "\n",
    "df_normalized_scores_pract = df_normalized_scores.sort_values(by=\"subject_nr\")\n",
    "df_normalized_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04662ead",
   "metadata": {},
   "source": [
    "# 5. WM tasks Experimental Session database\n",
    "Generates DB with the performance data in the WM tasks collected in the experimental sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848da14f",
   "metadata": {},
   "source": [
    "## 5.1. Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e09b546",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base = Path(r\"C:\\Users\\fabio\\OneDrive\\Área de Trabalho\\RPubs\\Article 3\")\n",
    "data_dir = base / \"data_participants_experimental\"\n",
    "\n",
    "csv_files = sorted(data_dir.glob(\"*.csv\"))\n",
    "\n",
    "def try_read(p):\n",
    "    # Try common CSV variants in Europe/Windows/Excel contexts\n",
    "    tries = [\n",
    "        dict(sep=None, engine=\"python\", encoding=\"utf-8-sig\"),  # auto-detect sep, UTF-8 BOM\n",
    "        dict(sep=\";\",  engine=\"python\", encoding=\"utf-8-sig\"),\n",
    "        dict(sep=\",\",  engine=\"python\", encoding=\"utf-8-sig\"),\n",
    "\n",
    "        dict(sep=None, engine=\"python\", encoding=\"latin-1\"),\n",
    "        dict(sep=\";\",  engine=\"python\", encoding=\"latin-1\"),\n",
    "        dict(sep=\",\",  engine=\"python\", encoding=\"latin-1\"),\n",
    "\n",
    "        # If the file is actually UTF-16 (common from Excel “Unicode Text” export)\n",
    "        dict(sep=\"\\t\", engine=\"python\", encoding=\"utf-16\"),   # TSV-like\n",
    "        dict(sep=\",\",  engine=\"python\", encoding=\"utf-16\"),\n",
    "        dict(sep=\";\",  engine=\"python\", encoding=\"utf-16\"),\n",
    "    ]\n",
    "\n",
    "    last_err = None\n",
    "    for kw in tries:\n",
    "        try:\n",
    "            # older pandas: use error_bad_lines/warn_bad_lines\n",
    "            return pd.read_csv(str(p), error_bad_lines=False, warn_bad_lines=False, **kw)\n",
    "        except TypeError:\n",
    "            # if your pandas is *very* old and doesn’t accept some kwargs, try minimal\n",
    "            try:\n",
    "                return pd.read_csv(str(p), **{k:v for k,v in kw.items() if k in (\"sep\",\"engine\",\"encoding\")})\n",
    "            except Exception as e:\n",
    "                last_err = e\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    raise last_err\n",
    "\n",
    "dfs = []\n",
    "for p in csv_files:\n",
    "    df = try_read(p)\n",
    "    dfs.append(df)\n",
    "\n",
    "df_total_part = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "df_total_part.reset_index(inplace=True)\n",
    "\n",
    "#Substitui dados que deviam estar listados como missing values ('undefined'), por missing values ('Nan')\n",
    "df_total_part = df_total_part.replace('undefined','Nan')\n",
    "\n",
    "#Puxa a coluna com o nome da tarefa que foi realizado neste ensaio e número do participante para a primeira e\n",
    "#segunda coluna respetivamente.\n",
    "first_column = df_total_part.pop('Task_Name')\n",
    "second_column = df_total_part.pop('subject_nr')\n",
    "df_total_part.insert(0, 'Task_Name', first_column)\n",
    "df_total_part.insert(1, 'subject_nr', second_column)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "df_total_part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6772b6",
   "metadata": {},
   "source": [
    "## 5.2. Generates DB with data regarding each WM task experimental sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0484a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Os seguintes 5 blocos de código criam 5 DataFrames distintas.\n",
    "#Cada uma das DataFrames vai conter a informação referente a cada uma das sete tarefas de memória de trabalho (reading span, symmetry\n",
    "# span, operation span, binding task e Updating Task) realizadas por todos os participantes.\n",
    "df_Reading_Span = df_total_part[df_total_part['Task_Name'] == 'Reading Span']\n",
    "df_Reading_Span = df_Reading_Span.sort_values(by=['selSNr'], kind='mergesort')\n",
    "df_Reading_Span = df_Reading_Span.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Reading_Span_1 = df_Reading_Span.query('selSNr == 1 and 1 <= subject_nr <= 5 or selSNr == 4 and 6 <= subject_nr <= 10 or selSNr == 3 and 11 <= subject_nr <= 15 or selSNr == 2 and 16 <= subject_nr <= 20 or selSNr == 1 and subject_nr == 21 or selSNr == 4 and subject_nr == 22 or selSNr == 3 and subject_nr == 23 or selSNr == 2 and subject_nr == 24 or selSNr == 1 and subject_nr == 25 or selSNr == 4 and subject_nr == 26 or selSNr == 3 and subject_nr == 27  or selSNr == 2 and subject_nr == 28')\n",
    "df_Reading_Span_1 = df_Reading_Span_1.reset_index(drop=True)\n",
    "df_Reading_Span_2 = df_Reading_Span.query('selSNr == 2 and 1 <= subject_nr <= 5 or selSNr == 1 and 6 <= subject_nr <= 10 or selSNr == 4 and 11 <= subject_nr <= 15 or selSNr == 3 and 16 <= subject_nr <= 20 or selSNr == 2 and subject_nr == 21 or selSNr == 1 and subject_nr == 22 or selSNr == 4 and subject_nr == 23 or selSNr == 3 and subject_nr == 24 or selSNr == 2 and subject_nr == 25 or selSNr == 1 and subject_nr == 26  or selSNr == 4 and subject_nr == 27  or selSNr == 3 and subject_nr == 28')\n",
    "df_Reading_Span_2 = df_Reading_Span_2.reset_index(drop=True)\n",
    "df_Reading_Span_3 = df_Reading_Span.query('selSNr == 3 and 1 <= subject_nr <= 5 or selSNr == 2 and 6 <= subject_nr <= 10 or selSNr == 1 and 11 <= subject_nr <= 15 or selSNr == 4 and 16 <= subject_nr <= 20 or selSNr == 3 and subject_nr == 21 or selSNr == 2 and subject_nr == 22 or selSNr == 1 and subject_nr == 23 or selSNr == 4 and subject_nr == 24 or selSNr == 3 and subject_nr == 25 or selSNr == 2 and subject_nr == 26  or selSNr == 1 and subject_nr == 27  or selSNr == 4 and subject_nr == 28')\n",
    "df_Reading_Span_3 = df_Reading_Span_3.reset_index(drop=True)\n",
    "df_Reading_Span_4 = df_Reading_Span.query('selSNr == 4 and 1 <= subject_nr <= 5 or selSNr == 3 and 6 <= subject_nr <= 10 or selSNr == 2 and 11 <= subject_nr <= 15 or selSNr == 1 and 16 <= subject_nr <= 20 or selSNr == 4 and subject_nr == 21 or selSNr == 3 and subject_nr == 22 or selSNr == 2 and subject_nr == 23 or selSNr == 1 and subject_nr == 24 or selSNr == 4 and subject_nr == 25 or selSNr == 3 and subject_nr == 26  or selSNr == 2 and subject_nr == 27  or selSNr == 1 and subject_nr == 28')\n",
    "df_Reading_Span_4 = df_Reading_Span_4.reset_index(drop=True)\n",
    "\n",
    "df_WMU_Task = df_total_part[df_total_part['Task_Name'] == 'Working Memory Updating Task']\n",
    "df_WMU_Task = df_WMU_Task.sort_values(by=['selSNr'], kind='mergesort')\n",
    "df_WMU_Task = df_WMU_Task.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_WMU_Task_1 = df_WMU_Task.query('selSNr == 1 and 1 <= subject_nr <= 5 or selSNr == 4 and 6 <= subject_nr <= 10 or selSNr == 3 and 11 <= subject_nr <= 15 or selSNr == 2 and 16 <= subject_nr <= 20 or selSNr == 1 and subject_nr == 21 or selSNr == 4 and subject_nr == 22 or selSNr == 3 and subject_nr == 23 or selSNr == 2 and subject_nr == 24 or selSNr == 1 and subject_nr == 25 or selSNr == 4 and subject_nr == 26  or selSNr == 3 and subject_nr == 27  or selSNr == 2 and subject_nr == 28')\n",
    "df_WMU_Task_1 = df_WMU_Task_1.reset_index(drop=True)\n",
    "df_WMU_Task_2 = df_WMU_Task.query('selSNr == 2 and 1 <= subject_nr <= 5 or selSNr == 1 and 6 <= subject_nr <= 10 or selSNr == 4 and 11 <= subject_nr <= 15 or selSNr == 3 and 16 <= subject_nr <= 20 or selSNr == 2 and subject_nr == 21 or selSNr == 1 and subject_nr == 22 or selSNr == 4 and subject_nr == 23 or selSNr == 3 and subject_nr == 24 or selSNr == 2 and subject_nr == 25 or selSNr == 1 and subject_nr == 26  or selSNr == 4 and subject_nr == 27  or selSNr == 3 and subject_nr == 28')\n",
    "df_WMU_Task_2 = df_WMU_Task_2.reset_index(drop=True)\n",
    "df_WMU_Task_3 = df_WMU_Task.query('selSNr == 3 and 1 <= subject_nr <= 5 or selSNr == 2 and 6 <= subject_nr <= 10 or selSNr == 1 and 11 <= subject_nr <= 15 or selSNr == 4 and 16 <= subject_nr <= 20 or selSNr == 3 and subject_nr == 21 or selSNr == 2 and subject_nr == 22 or selSNr == 1 and subject_nr == 23 or selSNr == 4 and subject_nr == 24 or selSNr == 3 and subject_nr == 25 or selSNr == 2 and subject_nr == 26  or selSNr == 1 and subject_nr == 27  or selSNr == 4 and subject_nr == 28')\n",
    "df_WMU_Task_3 = df_WMU_Task_3.reset_index(drop=True)\n",
    "df_WMU_Task_4 = df_WMU_Task.query('selSNr == 4 and 1 <= subject_nr <= 5 or selSNr == 3 and 6 <= subject_nr <= 10 or selSNr == 2 and 11 <= subject_nr <= 15 or selSNr == 1 and 16 <= subject_nr <= 20 or selSNr == 4 and subject_nr == 21 or selSNr == 3 and subject_nr == 22 or selSNr == 2 and subject_nr == 23 or selSNr == 1 and subject_nr == 24 or selSNr == 4 and subject_nr == 25 or selSNr == 3 and subject_nr == 26  or selSNr == 2 and subject_nr == 27  or selSNr == 1 and subject_nr == 28')\n",
    "df_WMU_Task_4 = df_WMU_Task_4.reset_index(drop=True)\n",
    "\n",
    "df_Symmetry_Span = df_total_part[df_total_part['Task_Name'] == 'Symmetry Span']\n",
    "df_Symmetry_Span = df_Symmetry_Span.sort_values(by=['selSNr'], kind='mergesort')\n",
    "df_Symmetry_Span = df_Symmetry_Span.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Symmetry_Span_1 = df_Symmetry_Span.query('selSNr == 1 and 1 <= subject_nr <= 5 or selSNr == 4 and 6 <= subject_nr <= 10 or selSNr == 3 and 11 <= subject_nr <= 15 or selSNr == 2 and 16 <= subject_nr <= 20 or selSNr == 1 and subject_nr == 21 or selSNr == 4 and subject_nr == 22 or selSNr == 3 and subject_nr == 23 or selSNr == 2 and subject_nr == 24 or selSNr == 1 and subject_nr == 25 or selSNr == 4 and subject_nr == 26 or selSNr == 3 and subject_nr == 27  or selSNr == 2 and subject_nr == 28')\n",
    "df_Symmetry_Span_1 = df_Symmetry_Span_1.reset_index(drop=True)\n",
    "df_Symmetry_Span_2 = df_Symmetry_Span.query('selSNr == 2 and 1 <= subject_nr <= 5 or selSNr == 1 and 6 <= subject_nr <= 10 or selSNr == 4 and 11 <= subject_nr <= 15 or selSNr == 3 and 16 <= subject_nr <= 20 or selSNr == 2 and subject_nr == 21 or selSNr == 1 and subject_nr == 22 or selSNr == 4 and subject_nr == 23 or selSNr == 3 and subject_nr == 24 or selSNr == 2 and subject_nr == 25 or selSNr == 1 and subject_nr == 26 or selSNr == 4 and subject_nr == 27  or selSNr == 3 and subject_nr == 28')\n",
    "df_Symmetry_Span_2 = df_Symmetry_Span_2.reset_index(drop=True)\n",
    "df_Symmetry_Span_3 = df_Symmetry_Span.query('selSNr == 3 and 1 <= subject_nr <= 5 or selSNr == 2 and 6 <= subject_nr <= 10 or selSNr == 1 and 11 <= subject_nr <= 15 or selSNr == 4 and 16 <= subject_nr <= 20 or selSNr == 3 and subject_nr == 21 or selSNr == 2 and subject_nr == 22 or selSNr == 1 and subject_nr == 23 or selSNr == 4 and subject_nr == 24 or selSNr == 3 and subject_nr == 25 or selSNr == 2 and subject_nr == 26 or selSNr == 1 and subject_nr == 27  or selSNr == 4 and subject_nr == 28')\n",
    "df_Symmetry_Span_3 = df_Symmetry_Span_3.reset_index(drop=True)\n",
    "df_Symmetry_Span_4 = df_Symmetry_Span.query('selSNr == 4 and 1 <= subject_nr <= 5 or selSNr == 3 and 6 <= subject_nr <= 10 or selSNr == 2 and 11 <= subject_nr <= 15 or selSNr == 1 and 16 <= subject_nr <= 20 or selSNr == 4 and subject_nr == 21 or selSNr == 3 and subject_nr == 22 or selSNr == 2 and subject_nr == 23 or selSNr == 1 and subject_nr == 24 or selSNr == 4 and subject_nr == 25 or selSNr == 3 and subject_nr == 26 or selSNr == 2 and subject_nr == 27  or selSNr == 1 and subject_nr == 28')\n",
    "df_Symmetry_Span_4 = df_Symmetry_Span_4.reset_index(drop=True)\n",
    "\n",
    "df_Binding_Task = df_total_part[df_total_part['Task_Name'] == 'Binding Task']\n",
    "df_Binding_Task = df_Binding_Task.sort_values(by=['selSNr'], kind='mergesort')\n",
    "df_Binding_Task = df_Binding_Task.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Binding_Task_1 = df_Binding_Task.query('selSNr == 1 and 1 <= subject_nr <= 5 or selSNr == 4 and 6 <= subject_nr <= 10 or selSNr == 3 and 11 <= subject_nr <= 15 or selSNr == 2 and 16 <= subject_nr <= 20 or selSNr == 1 and subject_nr == 21 or selSNr == 4 and subject_nr == 22 or selSNr == 3 and subject_nr == 23 or selSNr == 2 and subject_nr == 24 or selSNr == 1 and subject_nr == 25 or selSNr == 4 and subject_nr == 26 or selSNr == 3 and subject_nr == 27  or selSNr == 2 and subject_nr == 28')\n",
    "df_Binding_Task_1 = df_Binding_Task_1.reset_index(drop=True)\n",
    "df_Binding_Task_2 = df_Binding_Task.query('selSNr == 2 and 1 <= subject_nr <= 5 or selSNr == 1 and 6 <= subject_nr <= 10 or selSNr == 4 and 11 <= subject_nr <= 15 or selSNr == 3 and 16 <= subject_nr <= 20 or selSNr == 2 and subject_nr == 21 or selSNr == 1 and subject_nr == 22 or selSNr == 4 and subject_nr == 23 or selSNr == 3 and subject_nr == 24 or selSNr == 2 and subject_nr == 25 or selSNr == 1 and subject_nr == 26 or selSNr == 4 and subject_nr == 27  or selSNr == 3 and subject_nr == 28')\n",
    "df_Binding_Task_2 = df_Binding_Task_2.reset_index(drop=True)\n",
    "df_Binding_Task_3 = df_Binding_Task.query('selSNr == 3 and 1 <= subject_nr <= 5 or selSNr == 2 and 6 <= subject_nr <= 10 or selSNr == 1 and 11 <= subject_nr <= 15 or selSNr == 4 and 16 <= subject_nr <= 20 or selSNr == 3 and subject_nr == 21 or selSNr == 2 and subject_nr == 22 or selSNr == 1 and subject_nr == 23 or selSNr == 4 and subject_nr == 24 or selSNr == 3 and subject_nr == 25 or selSNr == 2 and subject_nr == 26 or selSNr == 1 and subject_nr == 27  or selSNr == 4 and subject_nr == 28')\n",
    "df_Binding_Task_3 = df_Binding_Task_3.reset_index(drop=True)\n",
    "df_Binding_Task_4 = df_Binding_Task.query('selSNr == 4 and 1 <= subject_nr <= 5 or selSNr == 3 and 6 <= subject_nr <= 10 or selSNr == 2 and 11 <= subject_nr <= 15 or selSNr == 1 and 16 <= subject_nr <= 20 or selSNr == 4 and subject_nr == 21 or selSNr == 3 and subject_nr == 22 or selSNr == 2 and subject_nr == 23 or selSNr == 1 and subject_nr == 24 or selSNr == 4 and subject_nr == 25 or selSNr == 3 and subject_nr == 26 or selSNr == 2 and subject_nr == 27  or selSNr == 1 and subject_nr == 28')\n",
    "df_Binding_Task_4 = df_Binding_Task_4.reset_index(drop=True)\n",
    "\n",
    "df_Operation_Span = df_total_part[df_total_part['Task_Name'] == 'Operation Span']\n",
    "df_Operation_Span = df_Operation_Span.sort_values(by=['selSNr'], kind='mergesort')\n",
    "df_Operation_Span = df_Operation_Span.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Operation_Span_1 = df_Operation_Span.query('selSNr == 1 and 1 <= subject_nr <= 5 or selSNr == 4 and 6 <= subject_nr <= 10 or selSNr == 3 and 11 <= subject_nr <= 15 or selSNr == 2 and 16 <= subject_nr <= 20 or selSNr == 1 and subject_nr == 21 or selSNr == 4 and subject_nr == 22 or selSNr == 3 and subject_nr == 23 or selSNr == 2 and subject_nr == 24 or selSNr == 1 and subject_nr == 25 or selSNr == 4 and subject_nr == 26 or selSNr == 3 and subject_nr == 27  or selSNr == 2 and subject_nr == 28')\n",
    "df_Operation_Span_1 = df_Operation_Span_1.reset_index(drop=True)\n",
    "df_Operation_Span_2 = df_Operation_Span.query('selSNr == 2 and 1 <= subject_nr <= 5 or selSNr == 1 and 6 <= subject_nr <= 10 or selSNr == 4 and 11 <= subject_nr <= 15 or selSNr == 3 and 16 <= subject_nr <= 20 or selSNr == 2 and subject_nr == 21 or selSNr == 1 and subject_nr == 22 or selSNr == 4 and subject_nr == 23 or selSNr == 3 and subject_nr == 24 or selSNr == 2 and subject_nr == 25 or selSNr == 1 and subject_nr == 26 or selSNr == 4 and subject_nr == 27  or selSNr == 3 and subject_nr == 28')\n",
    "df_Operation_Span_2 = df_Operation_Span_2.reset_index(drop=True)\n",
    "df_Operation_Span_3 = df_Operation_Span.query('selSNr == 3 and 1 <= subject_nr <= 5 or selSNr == 2 and 6 <= subject_nr <= 10 or selSNr == 1 and 11 <= subject_nr <= 15 or selSNr == 4 and 16 <= subject_nr <= 20 or selSNr == 3 and subject_nr == 21 or selSNr == 2 and subject_nr == 22 or selSNr == 1 and subject_nr == 23 or selSNr == 4 and subject_nr == 24 or selSNr == 3 and subject_nr == 25 or selSNr == 2 and subject_nr == 26 or selSNr == 1 and subject_nr == 27  or selSNr == 4 and subject_nr == 28')\n",
    "df_Operation_Span_3 = df_Operation_Span_3.reset_index(drop=True)\n",
    "df_Operation_Span_4 = df_Operation_Span.query('selSNr == 4 and 1 <= subject_nr <= 5 or selSNr == 3 and 6 <= subject_nr <= 10 or selSNr == 2 and 11 <= subject_nr <= 15 or selSNr == 1 and 16 <= subject_nr <= 20 or selSNr == 4 and subject_nr == 21 or selSNr == 3 and subject_nr == 22 or selSNr == 2 and subject_nr == 23 or selSNr == 1 and subject_nr == 24 or selSNr == 4 and subject_nr == 25 or selSNr == 3 and subject_nr == 26 or selSNr == 2 and subject_nr == 27  or selSNr == 1 and subject_nr == 28')\n",
    "df_Operation_Span_4 = df_Operation_Span_4.reset_index(drop=True)\n",
    "\n",
    "#Os próximos 5 blocos de código selecionam as colunas com informação relevante de cada WM task e guardam estas colunas em DataFrames\n",
    "#que só contêm informação relacionada com a mesma tarefa. Para além disso, estes nestes 5 blocos de código, são realizadas algumas\n",
    "#conversões no formato dos dados (e.g., string to float) e são alterados os nomes de algumas colunas de forma a ficarem mais percétiveis.\n",
    "#'selSNr',\n",
    "df_Reading_Span_1 = df_Reading_Span_1[\n",
    "    ['subject_nr',  'CB_ref', 'practice', 'TrialNumber', 'Sub_bloco', 'SubTaskName', 'acc', 'avg_rt',\n",
    "     'BlockChoice', 'correct', 'correct_response', 'Frase', 'height', 'letter', 'List_Prev_Letter',\n",
    "     'List_responses_memory', 'live_row', 'logfile', 'response_average_time_memory', 'response_memory',\n",
    "     'response_processing', 'response_time_memory', 'response_time_processing', 'response_total_time_memory',\n",
    "     'RP_part_process_time', 'score_practice', 'score_reading_span', 'score_subblock_2', 'score_subblock_3', 'score_subblock_4',\n",
    "     'score_subblock_5', 'score_subblock_6', 'Tipo', 'total_correct',\n",
    "     'total_response_time', 'total_responses', 'width']]\n",
    "df_Reading_Span_1[['acc', 'avg_rt']] = df_Reading_Span_1[['acc', 'avg_rt']].replace(',', '.')\n",
    "df_Reading_Span_1 = df_Reading_Span_1.astype(\n",
    "    {'acc': 'float64', 'avg_rt': 'float64', 'correct_response': 'str', 'response_processing': 'str'})\n",
    "example_b = df_Reading_Span_1[\"response_processing\"].iloc[2]\n",
    "df_Reading_Span_1 = df_Reading_Span_1.replace(example_b, '')\n",
    "#df_Reading_Span_1 = df_Reading_Span_1.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_Reading_Span_1 = df_Reading_Span_1.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Reading_Span_1.columns = ['subject_nr','CB_ref','practice','TrialNumber','Sub_bloco',\n",
    "                             'SubTaskName','acc_Sess09h00','avg_rt_Sess09h00','BlockChoice_Sess09h00','correct_Sess09h00','correct_response_Sess09h00',\n",
    "                             'Frase_Sess09h00','height_Sess09h00','letter_Sess09h00','List_Prev_Letter_Sess09h00','List_responses_memory_Sess09h00',\n",
    "                             'live_row_Sess09h00','logfile_Sess09h00','response_average_time_memory_Sess09h00','response_memory_Sess09h00',\n",
    "                             'response_processing_Sess09h00','response_time_memory_Sess09h00','response_time_processing_Sess09h00',\n",
    "                             'response_total_time_memory_Sess09h00','RP_part_process_time_Sess09h00','score_practice_Sess09h00',\n",
    "                             'score_reading_span_Sess09h00','score_subblock_2_Sess09h00','score_subblock_3_Sess09h00','score_subblock_4_Sess09h00',\n",
    "                             'score_subblock_5_Sess09h00','score_subblock_6_Sess09h00','Tipo_Sess09h00','total_correct_Sess09h00',\n",
    "                             'total_response_time_Sess09h00','total_responses_Sess09h00','width_Sess09h00']\n",
    "#'selSNr',\n",
    "df_Reading_Span_2 = df_Reading_Span_2[\n",
    "    ['subject_nr',  'CB_ref', 'practice', 'TrialNumber', 'Sub_bloco', 'SubTaskName', 'acc', 'avg_rt',\n",
    "     'BlockChoice', 'correct', 'correct_response', 'Frase', 'height', 'letter', 'List_Prev_Letter',\n",
    "     'List_responses_memory', 'live_row', 'logfile', 'response_average_time_memory', 'response_memory',\n",
    "     'response_processing', 'response_time_memory', 'response_time_processing', 'response_total_time_memory',\n",
    "     'RP_part_process_time', 'score_practice', 'score_reading_span', 'score_subblock_2', 'score_subblock_3', 'score_subblock_4',\n",
    "     'score_subblock_5', 'score_subblock_6', 'Tipo', 'total_correct',\n",
    "     'total_response_time', 'total_responses', 'width']]\n",
    "df_Reading_Span_2[['acc', 'avg_rt']] = df_Reading_Span_2[['acc', 'avg_rt']].replace(',', '.')\n",
    "df_Reading_Span_2 = df_Reading_Span_2.astype(\n",
    "    {'acc': 'float64', 'avg_rt': 'float64', 'correct_response': 'str', 'response_processing': 'str'})\n",
    "example_b = df_Reading_Span_2[\"response_processing\"].iloc[2]\n",
    "df_Reading_Span_2 = df_Reading_Span_2.replace(example_b, '')\n",
    "df_Reading_Span_2.drop(['subject_nr','CB_ref','practice','TrialNumber','Sub_bloco','SubTaskName'],axis=1,inplace=True)\n",
    "#df_Reading_Span_2 = df_Reading_Span_2.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_Reading_Span_2 = df_Reading_Span_2.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Reading_Span_2.columns = ['acc_Sess13h00','avg_rt_Sess13h00','BlockChoice_Sess13h00','correct_Sess13h00','correct_response_Sess13h00',\n",
    "                             'Frase_Sess13h00','height_Sess13h00','letter_Sess13h00','List_Prev_Letter_Sess13h00','List_responses_memory_Sess13h00',\n",
    "                             'live_row_Sess13h00','logfile_Sess13h00','response_average_time_memory_Sess13h00','response_memory_Sess13h00',\n",
    "                             'response_processing_Sess13h00','response_time_memory_Sess13h00','response_time_processing_Sess13h00',\n",
    "                             'response_total_time_memory_Sess13h00','RP_part_process_time_Sess13h00','score_practice_Sess13h00',\n",
    "                             'score_reading_span_Sess13h00','score_subblock_2_Sess13h00','score_subblock_3_Sess13h00','score_subblock_4_Sess13h00',\n",
    "                             'score_subblock_5_Sess13h00','score_subblock_6_Sess13h00','Tipo_Sess13h00','total_correct_Sess13h00',\n",
    "                             'total_response_time_Sess13h00','total_responses_Sess13h00','width_Sess13h00']\n",
    "\n",
    "#'selSNr',\n",
    "df_Reading_Span_3 = df_Reading_Span_3[\n",
    "    ['subject_nr',  'CB_ref', 'practice', 'TrialNumber', 'Sub_bloco', 'SubTaskName', 'acc', 'avg_rt',\n",
    "     'BlockChoice', 'correct', 'correct_response', 'Frase', 'height', 'letter', 'List_Prev_Letter',\n",
    "     'List_responses_memory', 'live_row', 'logfile', 'response_average_time_memory', 'response_memory',\n",
    "     'response_processing', 'response_time_memory', 'response_time_processing', 'response_total_time_memory',\n",
    "     'RP_part_process_time', 'score_practice', 'score_reading_span', 'score_subblock_2', 'score_subblock_3', 'score_subblock_4',\n",
    "     'score_subblock_5', 'score_subblock_6', 'Tipo', 'total_correct',\n",
    "     'total_response_time', 'total_responses', 'width']]\n",
    "df_Reading_Span_3[['acc', 'avg_rt']] = df_Reading_Span_3[['acc', 'avg_rt']].replace(',', '.')\n",
    "df_Reading_Span_3 = df_Reading_Span_3.astype(\n",
    "    {'acc': 'float64', 'avg_rt': 'float64', 'correct_response': 'str', 'response_processing': 'str'})\n",
    "example_b = df_Reading_Span_3[\"response_processing\"].iloc[2]\n",
    "df_Reading_Span_3 = df_Reading_Span_3.replace(example_b, '')\n",
    "#df_Reading_Span_3 = df_Reading_Span_3.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_Reading_Span_3 = df_Reading_Span_3.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Reading_Span_3.drop(['subject_nr','CB_ref','practice','TrialNumber','Sub_bloco','SubTaskName'],axis=1,inplace=True)\n",
    "df_Reading_Span_3.columns = ['acc_Sess17h00','avg_rt_Sess17h00','BlockChoice_Sess17h00','correct_Sess17h00','correct_response_Sess17h00',\n",
    "                             'Frase_Sess17h00','height_Sess17h00','letter_Sess17h00','List_Prev_Letter_Sess17h00','List_responses_memory_Sess17h00',\n",
    "                             'live_row_Sess17h00','logfile_Sess17h00','response_average_time_memory_Sess17h00','response_memory_Sess17h00',\n",
    "                             'response_processing_Sess17h00','response_time_memory_Sess17h00','response_time_processing_Sess17h00',\n",
    "                             'response_total_time_memory_Sess17h00','RP_part_process_time_Sess17h00','score_practice_Sess17h00',\n",
    "                             'score_reading_span_Sess17h00','score_subblock_2_Sess17h00','score_subblock_3_Sess17h00','score_subblock_4_Sess17h00',\n",
    "                             'score_subblock_5_Sess17h00','score_subblock_6_Sess17h00','Tipo_Sess17h00','total_correct_Sess17h00',\n",
    "                             'total_response_time_Sess17h00','total_responses_Sess17h00','width_Sess17h00']\n",
    "#'selSNr',\n",
    "df_Reading_Span_4 = df_Reading_Span_4[\n",
    "    ['subject_nr',  'CB_ref', 'practice', 'TrialNumber', 'Sub_bloco', 'SubTaskName', 'acc', 'avg_rt',\n",
    "     'BlockChoice', 'correct', 'correct_response', 'Frase', 'height', 'letter', 'List_Prev_Letter',\n",
    "     'List_responses_memory', 'live_row', 'logfile', 'response_average_time_memory', 'response_memory',\n",
    "     'response_processing', 'response_time_memory', 'response_time_processing', 'response_total_time_memory',\n",
    "     'RP_part_process_time', 'score_practice', 'score_reading_span', 'score_subblock_2', 'score_subblock_3', 'score_subblock_4',\n",
    "     'score_subblock_5', 'score_subblock_6', 'Tipo', 'total_correct',\n",
    "     'total_response_time', 'total_responses', 'width']]\n",
    "df_Reading_Span_4[['acc', 'avg_rt']] = df_Reading_Span_4[['acc', 'avg_rt']].replace(',', '.')\n",
    "df_Reading_Span_4 = df_Reading_Span_4.astype(\n",
    "    {'acc': 'float64', 'avg_rt': 'float64', 'correct_response': 'str', 'response_processing': 'str'})\n",
    "example_b = df_Reading_Span_4[\"response_processing\"].iloc[2]\n",
    "df_Reading_Span_4 = df_Reading_Span_4.replace(example_b, '')\n",
    "#df_Reading_Span_4 = df_Reading_Span_4.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_Reading_Span_4 = df_Reading_Span_4.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Reading_Span_4.drop(['subject_nr','CB_ref','practice','TrialNumber','Sub_bloco','SubTaskName'],axis=1,inplace=True)\n",
    "df_Reading_Span_4.columns = ['acc_Sess21h00','avg_rt_Sess21h00','BlockChoice_Sess21h00','correct_Sess21h00','correct_response_Sess21h00',\n",
    "                             'Frase_Sess21h00','height_Sess21h00','letter_Sess21h00','List_Prev_Letter_Sess21h00','List_responses_memory_Sess21h00',\n",
    "                             'live_row_Sess21h00','logfile_Sess21h00','response_average_time_memory_Sess21h00','response_memory_Sess21h00',\n",
    "                             'response_processing_Sess21h00','response_time_memory_Sess21h00','response_time_processing_Sess21h00',\n",
    "                             'response_total_time_memory_Sess21h00','RP_part_process_time_Sess21h00','score_practice_Sess21h00',\n",
    "                             'score_reading_span_Sess21h00','score_subblock_2_Sess21h00','score_subblock_3_Sess21h00','score_subblock_4_Sess21h00',\n",
    "                             'score_subblock_5_Sess21h00','score_subblock_6_Sess21h00','Tipo_Sess21h00','total_correct_Sess21h00',\n",
    "                             'total_response_time_Sess21h00','total_responses_Sess21h00','width_Sess21h00']\n",
    "\n",
    "#'selSNr',\n",
    "\n",
    "#print(df_Reading_Span_2.to_string())\n",
    "df_Reading_Span_Experimental = pd.concat([df_Reading_Span_1,df_Reading_Span_2,df_Reading_Span_3,df_Reading_Span_4],axis=1)\n",
    "\n",
    "df_Reading_Span_Experimental = df_Reading_Span_Experimental[['subject_nr','CB_ref','practice','TrialNumber','Sub_bloco','SubTaskName','acc_Sess09h00',\n",
    "                                                   'acc_Sess13h00','acc_Sess17h00','acc_Sess21h00','avg_rt_Sess09h00','avg_rt_Sess13h00','avg_rt_Sess17h00','avg_rt_Sess21h00',\n",
    "                                                   'BlockChoice_Sess09h00','BlockChoice_Sess13h00','BlockChoice_Sess17h00','BlockChoice_Sess21h00','correct_Sess09h00',\n",
    "                                                   'correct_Sess13h00','correct_Sess17h00','correct_Sess21h00','correct_response_Sess09h00','correct_response_Sess13h00',\n",
    "                                                   'correct_response_Sess17h00','correct_response_Sess21h00','Frase_Sess09h00','Frase_Sess13h00','Frase_Sess17h00','Frase_Sess21h00',\n",
    "                                                   'height_Sess09h00','height_Sess13h00','height_Sess17h00','height_Sess21h00','letter_Sess09h00','letter_Sess13h00','letter_Sess17h00',\n",
    "                                                   'letter_Sess21h00','List_Prev_Letter_Sess09h00','List_Prev_Letter_Sess13h00','List_Prev_Letter_Sess17h00',\n",
    "                                                   'List_Prev_Letter_Sess21h00','List_responses_memory_Sess09h00','List_responses_memory_Sess13h00',\n",
    "                                                   'List_responses_memory_Sess17h00','List_responses_memory_Sess21h00','live_row_Sess09h00','live_row_Sess13h00',\n",
    "                                                   'live_row_Sess17h00','live_row_Sess21h00','logfile_Sess09h00','logfile_Sess13h00','logfile_Sess17h00','logfile_Sess21h00',\n",
    "                                                   'response_average_time_memory_Sess09h00','response_average_time_memory_Sess13h00','response_average_time_memory_Sess17h00',\n",
    "                                                   'response_average_time_memory_Sess21h00','response_memory_Sess09h00','response_memory_Sess13h00','response_memory_Sess17h00',\n",
    "                                                   'response_memory_Sess21h00','response_processing_Sess09h00','response_processing_Sess13h00','response_processing_Sess17h00',\n",
    "                                                   'response_processing_Sess21h00','response_time_memory_Sess09h00','response_time_memory_Sess13h00',\n",
    "                                                   'response_time_memory_Sess17h00','response_time_memory_Sess21h00','response_time_processing_Sess09h00',\n",
    "                                                   'response_time_processing_Sess13h00','response_time_processing_Sess17h00','response_time_processing_Sess21h00',\n",
    "                                                   'response_total_time_memory_Sess09h00','response_total_time_memory_Sess13h00','response_total_time_memory_Sess17h00',\n",
    "                                                   'response_total_time_memory_Sess21h00','RP_part_process_time_Sess09h00','RP_part_process_time_Sess13h00',\n",
    "                                                   'RP_part_process_time_Sess17h00','RP_part_process_time_Sess21h00','score_practice_Sess09h00',\n",
    "                                                   'score_practice_Sess13h00','score_practice_Sess17h00','score_practice_Sess21h00','score_reading_span_Sess09h00',\n",
    "                                                   'score_reading_span_Sess13h00','score_reading_span_Sess17h00','score_reading_span_Sess21h00','score_subblock_2_Sess09h00',\n",
    "                                                   'score_subblock_2_Sess13h00','score_subblock_2_Sess17h00','score_subblock_2_Sess21h00','score_subblock_3_Sess09h00',\n",
    "                                                   'score_subblock_3_Sess13h00','score_subblock_3_Sess17h00','score_subblock_3_Sess21h00','score_subblock_4_Sess09h00',\n",
    "                                                   'score_subblock_4_Sess13h00','score_subblock_4_Sess17h00','score_subblock_4_Sess21h00','score_subblock_5_Sess09h00',\n",
    "                                                   'score_subblock_5_Sess13h00','score_subblock_5_Sess17h00','score_subblock_5_Sess21h00','score_subblock_6_Sess09h00',\n",
    "                                                   'score_subblock_6_Sess13h00','score_subblock_6_Sess17h00','score_subblock_6_Sess21h00','Tipo_Sess09h00','Tipo_Sess13h00',\n",
    "                                                   'Tipo_Sess17h00','Tipo_Sess21h00','total_correct_Sess09h00','total_correct_Sess13h00','total_correct_Sess17h00',\n",
    "                                                   'total_correct_Sess21h00','total_response_time_Sess09h00','total_response_time_Sess13h00','total_response_time_Sess17h00',\n",
    "                                                   'total_response_time_Sess21h00','total_responses_Sess09h00','total_responses_Sess13h00','total_responses_Sess17h00',\n",
    "                                                   'total_responses_Sess21h00','width_Sess09h00','width_Sess13h00','width_Sess17h00','width_Sess21h00']]\n",
    "\n",
    "############################################################################################\n",
    "############################################################################################\n",
    "#'toUpdate1_1', 'toUpdate1_2', 'toUpdate1_3', 'toUpdate2_1', 'toUpdate2_2','toUpdate2_3','correct_response1', 'correct_response2', 'correct_response3',\n",
    "#'selSNr',\n",
    "df_WMU_Task_1 = df_WMU_Task_1[\n",
    "    ['subject_nr',  'CB_ref', 'practice', 'TrialNumber', 'correct1', 'correct2', 'correct3', 'digit1', 'digit2', 'digit3', 'height',\n",
    "     'Index_List', 'live_row', 'logfile', 'response1', 'response2', 'response3', 'response_time1', 'responseavgRT',\n",
    "     'total_correct_trial', 'TotalRtBlock',  'WMUExperimentalScore', 'WMUPracticeScore', 'width']]\n",
    "df_WMU_Task_1 = df_WMU_Task_1.rename(columns={'response_time1': 'response_time'})\n",
    "#df_WMU_Task_1 = df_WMU_Task_1.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_WMU_Task_1 = df_WMU_Task_1.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "for i in range(0, len(df_WMU_Task_1['responseavgRT'])):\n",
    "    if df_WMU_Task_1['responseavgRT'].iloc[i] == 0:\n",
    "        df_WMU_Task_1['responseavgRT'].iloc[i] = ''\n",
    "df_WMU_Task_1.columns = ['subject_nr','CB_ref','practice','TrialNumber','correct1_Sess09h00',\n",
    "                         'correct2_Sess09h00','correct3_Sess09h00','digit1_Sess09h00','digit2_Sess09h00','digit3_Sess09h00','height_Sess09h00',\n",
    "                         'Index_List_Sess09h00','live_row_Sess09h00','logfile_Sess09h00','response1_Sess09h00','response2_Sess09h00','response3_Sess09h00',\n",
    "                         'response_time1_Sess09h00','responseavgRT_Sess09h00','total_correct_trial_Sess09h00','TotalRtBlock_Sess09h00',\n",
    "                         'WMUExperimentalScore_Sess09h00','WMUPracticeScore_Sess09h00','width_Sess09h00']\n",
    "\n",
    "#WMU_cast_lis = ['toUpdate1_1', 'toUpdate1_2', 'toUpdate1_3', 'toUpdate2_1', 'toUpdate2_2', 'toUpdate2_3']\n",
    "#for i in WMU_cast_lis:\n",
    "#    for j in range(0, len(df_WMU_Task[i])):\n",
    "#        if df_WMU_Task[i].iloc[j] > 0:\n",
    "#            df_WMU_Task[i].iloc[j] = '+' + str(int(df_WMU_Task[i].iloc[j]))\n",
    "#        else:\n",
    "#            df_WMU_Task[i].iloc[j] = str(int(df_WMU_Task[i].iloc[j]))\n",
    "\n",
    "#'selSNr',\n",
    "df_WMU_Task_2 = df_WMU_Task_2[\n",
    "    ['subject_nr', 'CB_ref', 'practice', 'TrialNumber', 'correct1', 'correct2', 'correct3', 'digit1', 'digit2', 'digit3', 'height',\n",
    "     'Index_List', 'live_row', 'logfile', 'response1', 'response2', 'response3', 'response_time1', 'responseavgRT',\n",
    "     'total_correct_trial', 'TotalRtBlock',  'WMUExperimentalScore', 'WMUPracticeScore', 'width']]\n",
    "df_WMU_Task_2 = df_WMU_Task_2.rename(columns={'response_time1': 'response_time'})\n",
    "#df_WMU_Task_2 = df_WMU_Task_2.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_WMU_Task_2 = df_WMU_Task_2.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "for i in range(0, len(df_WMU_Task_2['responseavgRT'])):\n",
    "    if df_WMU_Task_2['responseavgRT'].iloc[i] == 0:\n",
    "        df_WMU_Task_2['responseavgRT'].iloc[i] = ''\n",
    "df_WMU_Task_2.drop(['subject_nr','CB_ref','practice','TrialNumber'],axis=1,inplace=True)\n",
    "df_WMU_Task_2.columns = ['correct1_Sess13h00','correct2_Sess13h00','correct3_Sess13h00','digit1_Sess13h00','digit2_Sess13h00','digit3_Sess13h00','height_Sess13h00',\n",
    "                         'Index_List_Sess13h00','live_row_Sess13h00','logfile_Sess13h00','response1_Sess13h00','response2_Sess13h00','response3_Sess13h00',\n",
    "                         'response_time1_Sess13h00','responseavgRT_Sess13h00','total_correct_trial_Sess13h00','TotalRtBlock_Sess13h00',\n",
    "                         'WMUExperimentalScore_Sess13h00','WMUPracticeScore_Sess13h00','width_Sess13h00']\n",
    "#WMU_cast_lis = ['toUpdate1_1', 'toUpdate1_2', 'toUpdate1_3', 'toUpdate2_1', 'toUpdate2_2', 'toUpdate2_3']\n",
    "#for i in WMU_cast_lis:\n",
    "#    for j in range(0, len(df_WMU_Task[i])):\n",
    "#        if df_WMU_Task[i].iloc[j] > 0:\n",
    "#            df_WMU_Task[i].iloc[j] = '+' + str(int(df_WMU_Task[i].iloc[j]))\n",
    "#        else:\n",
    "#            df_WMU_Task[i].iloc[j] = str(int(df_WMU_Task[i].iloc[j]))\n",
    "\n",
    "#'selSNr',\n",
    "df_WMU_Task_3 = df_WMU_Task_3[\n",
    "    ['subject_nr', 'CB_ref', 'practice', 'TrialNumber', 'correct1', 'correct2', 'correct3', 'digit1', 'digit2', 'digit3', 'height',\n",
    "     'Index_List', 'live_row', 'logfile', 'response1', 'response2', 'response3', 'response_time1', 'responseavgRT',\n",
    "     'total_correct_trial', 'TotalRtBlock',  'WMUExperimentalScore', 'WMUPracticeScore', 'width']]\n",
    "df_WMU_Task_3 = df_WMU_Task_3.rename(columns={'response_time1': 'response_time'})\n",
    "#df_WMU_Task_3 = df_WMU_Task_3.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_WMU_Task_3 = df_WMU_Task_3.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "for i in range(0, len(df_WMU_Task_3['responseavgRT'])):\n",
    "    if df_WMU_Task_3['responseavgRT'].iloc[i] == 0:\n",
    "        df_WMU_Task_3['responseavgRT'].iloc[i] = ''\n",
    "df_WMU_Task_3.drop(['subject_nr','CB_ref','practice','TrialNumber'],axis=1,inplace=True)\n",
    "df_WMU_Task_3.columns = ['correct1_Sess17h00','correct2_Sess17h00','correct3_Sess17h00','digit1_Sess17h00','digit2_Sess17h00','digit3_Sess17h00','height_Sess17h00',\n",
    "                         'Index_List_Sess17h00','live_row_Sess17h00','logfile_Sess17h00','response1_Sess17h00','response2_Sess17h00','response3_Sess17h00',\n",
    "                         'response_time1_Sess17h00','responseavgRT_Sess17h00','total_correct_trial_Sess17h00','TotalRtBlock_Sess17h00',\n",
    "                         'WMUExperimentalScore_Sess17h00','WMUPracticeScore_Sess17h00','width_Sess17h00']\n",
    "#WMU_cast_lis = ['toUpdate1_1', 'toUpdate1_2', 'toUpdate1_3', 'toUpdate2_1', 'toUpdate2_2', 'toUpdate2_3']\n",
    "#for i in WMU_cast_lis:\n",
    "#    for j in range(0, len(df_WMU_Task[i])):\n",
    "#        if df_WMU_Task[i].iloc[j] > 0:\n",
    "#            df_WMU_Task[i].iloc[j] = '+' + str(int(df_WMU_Task[i].iloc[j]))\n",
    "#        else:\n",
    "#            df_WMU_Task[i].iloc[j] = str(int(df_WMU_Task[i].iloc[j]))\n",
    "\n",
    "#'selSNr',\n",
    "df_WMU_Task_4 = df_WMU_Task_4[\n",
    "    ['subject_nr', 'CB_ref', 'practice', 'TrialNumber', 'correct1', 'correct2', 'correct3', 'digit1', 'digit2', 'digit3', 'height',\n",
    "     'Index_List', 'live_row', 'logfile', 'response1', 'response2', 'response3', 'response_time1', 'responseavgRT',\n",
    "     'total_correct_trial', 'TotalRtBlock',  'WMUExperimentalScore', 'WMUPracticeScore', 'width']]\n",
    "df_WMU_Task_4 = df_WMU_Task_4.rename(columns={'response_time1': 'response_time'})\n",
    "#df_WMU_Task_4 = df_WMU_Task_4.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_WMU_Task_4 = df_WMU_Task_4.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "for i in range(0, len(df_WMU_Task_4['responseavgRT'])):\n",
    "    if df_WMU_Task_4['responseavgRT'].iloc[i] == 0:\n",
    "        df_WMU_Task_4['responseavgRT'].iloc[i] = ''\n",
    "df_WMU_Task_4.drop(['subject_nr','CB_ref','practice','TrialNumber'],axis=1,inplace=True)\n",
    "df_WMU_Task_4.columns = ['correct1_Sess21h00','correct2_Sess21h00','correct3_Sess21h00','digit1_Sess21h00','digit2_Sess21h00','digit3_Sess21h00','height_Sess21h00',\n",
    "                         'Index_List_Sess21h00','live_row_Sess21h00','logfile_Sess21h00','response1_Sess21h00','response2_Sess21h00','response3_Sess21h00',\n",
    "                         'response_time1_Sess21h00','responseavgRT_Sess21h00','total_correct_trial_Sess21h00','TotalRtBlock_Sess21h00',\n",
    "                         'WMUExperimentalScore_Sess21h00','WMUPracticeScore_Sess21h00','width_Sess21h00']\n",
    "#WMU_cast_lis = ['toUpdate1_1', 'toUpdate1_2', 'toUpdate1_3', 'toUpdate2_1', 'toUpdate2_2', 'toUpdate2_3']\n",
    "#for i in WMU_cast_lis:\n",
    "#    for j in range(0, len(df_WMU_Task[i])):\n",
    "#        if df_WMU_Task[i].iloc[j] > 0:\n",
    "#            df_WMU_Task[i].iloc[j] = '+' + str(int(df_WMU_Task[i].iloc[j]))\n",
    "#        else:\n",
    "#            df_WMU_Task[i].iloc[j] = str(int(df_WMU_Task[i].iloc[j]))\n",
    "\n",
    "df_WMU_Task_Experimental = pd.concat([df_WMU_Task_1,df_WMU_Task_2,df_WMU_Task_3,df_WMU_Task_4],axis=1)\n",
    "\n",
    "df_WMU_Task_Experimental = df_WMU_Task_Experimental[['subject_nr','CB_ref','practice','TrialNumber','correct1_Sess09h00','correct1_Sess13h00',\n",
    "                                       'correct1_Sess17h00','correct1_Sess21h00','correct2_Sess09h00','correct2_Sess13h00','correct2_Sess17h00',\n",
    "                                       'correct2_Sess21h00','correct3_Sess09h00','correct3_Sess13h00','correct3_Sess17h00','correct3_Sess21h00',\n",
    "                                       'digit1_Sess09h00','digit1_Sess13h00','digit1_Sess17h00','digit1_Sess21h00','digit2_Sess09h00','digit2_Sess13h00',\n",
    "                                       'digit2_Sess17h00','digit2_Sess21h00','digit3_Sess09h00','digit3_Sess13h00','digit3_Sess17h00','digit3_Sess21h00',\n",
    "                                       'height_Sess09h00','height_Sess13h00','height_Sess17h00','height_Sess21h00','Index_List_Sess09h00',\n",
    "                                       'Index_List_Sess13h00','Index_List_Sess17h00','Index_List_Sess21h00','live_row_Sess09h00','live_row_Sess13h00',\n",
    "                                       'live_row_Sess17h00','live_row_Sess21h00','logfile_Sess09h00','logfile_Sess13h00','logfile_Sess17h00','logfile_Sess21h00',\n",
    "                                       'response1_Sess09h00','response1_Sess13h00','response1_Sess17h00','response1_Sess21h00','response2_Sess09h00','response2_Sess13h00',\n",
    "                                       'response2_Sess17h00','response2_Sess21h00','response3_Sess09h00','response3_Sess13h00','response3_Sess17h00','response3_Sess21h00',\n",
    "                                       'response_time1_Sess09h00','response_time1_Sess13h00','response_time1_Sess17h00','response_time1_Sess21h00',\n",
    "                                       'responseavgRT_Sess09h00','responseavgRT_Sess13h00','responseavgRT_Sess17h00','responseavgRT_Sess21h00',\n",
    "                                       'total_correct_trial_Sess09h00','total_correct_trial_Sess13h00','total_correct_trial_Sess17h00','total_correct_trial_Sess21h00',\n",
    "                                       'TotalRtBlock_Sess09h00','TotalRtBlock_Sess13h00','TotalRtBlock_Sess17h00','TotalRtBlock_Sess21h00',\n",
    "                                       'WMUExperimentalScore_Sess09h00', 'WMUExperimentalScore_Sess13h00','WMUExperimentalScore_Sess17h00', 'WMUExperimentalScore_Sess21h00',\n",
    "                                       'WMUPracticeScore_Sess09h00','WMUPracticeScore_Sess13h00','WMUPracticeScore_Sess17h00','WMUPracticeScore_Sess21h00',\n",
    "                                       'width_Sess09h00','width_Sess13h00','width_Sess17h00','width_Sess21h00']]\n",
    "############################################################################################\n",
    "############################################################################################\n",
    "#'selSNr',\n",
    "df_Symmetry_Span_1 = df_Symmetry_Span_1[\n",
    "    ['subject_nr', 'CB_ref', 'practice', 'TrialNumber', 'Sub_bloco', 'SubTaskName',\n",
    "     'aggregated_score_memory', 'average_response_time_processing', 'average_total_time_memory', 'correct',\n",
    "     'correct_response', 'countDys', 'countSym', 'height', 'LeftHalfPos', 'List_SS_button', 'List_SS_Pos', 'live_row',\n",
    "     'logfile', 'maxDys', 'maxSym', 'pressed_buttons', 'response_memory', 'response_processing', 'response_time_memory',\n",
    "     'response_time_processing', 'response_total_time_memory', 'response_total_time_memory_full_task', 'RightHalfPos',\n",
    "     'SP_part_process_time', 'SS_practice_score', 'score_symmetry_span', 'score_subblock_2', 'score_subblock_3',\n",
    "     'score_subblock_4', 'score_subblock_5', 'score_subblock_6', 'SymType',\n",
    "     'total_correct_processing', 'total_response_time_processing', 'width']]\n",
    "df_Symmetry_Span_1 = df_Symmetry_Span_1.astype({'correct_response': 'str', 'response_processing': 'str'})\n",
    "example_d = df_Symmetry_Span_1[\"response_processing\"].iloc[2]\n",
    "df_Symmetry_Span_1 = df_Symmetry_Span_1.replace(example_d, '')\n",
    "#df_Symmetry_Span_1 = df_Symmetry_Span_1.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_Symmetry_Span_1 = df_Symmetry_Span_1.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Symmetry_Span_1.columns = ['subject_nr','CB_ref','practice','TrialNumber','Sub_bloco',\n",
    "                              'SubTaskName','aggregated_score_memory_Sess09h00','average_response_time_processing_Sess09h00',\n",
    "                              'average_total_time_memory_Sess09h00','correct_Sess09h00','correct_response_Sess09h00','countDys_Sess09h00',\n",
    "                              'countSym_Sess09h00','height_Sess09h00','LeftHalfPos_Sess09h00','List_SS_button_Sess09h00','List_SS_Pos_Sess09h00',\n",
    "                              'live_row_Sess09h00','logfile_Sess09h00','maxDys_Sess09h00','maxSym_Sess09h00','pressed_buttons_Sess09h00',\n",
    "                              'response_memory_Sess09h00','response_processing_Sess09h00','response_time_memory_Sess09h00',\n",
    "                              'response_time_processing_Sess09h00','response_total_time_memory_Sess09h00',\n",
    "                              'response_total_time_memory_full_task_Sess09h00','RightHalfPos_Sess09h00','SP_part_process_time_Sess09h00',\n",
    "                              'SS_practice_score_Sess09h00','score_symmetry_span_Sess09h00','score_subblock_2_Sess09h00','score_subblock_3_Sess09h00',\n",
    "                              'score_subblock_4_Sess09h00','score_subblock_5_Sess09h00','score_subblock_6_Sess09h00','SymType_Sess09h00',\n",
    "                              'total_correct_processing_Sess09h00','total_response_time_processing_Sess09h00','width_Sess09h00']\n",
    "\n",
    "#'selSNr',\n",
    "df_Symmetry_Span_2 = df_Symmetry_Span_2[\n",
    "    ['subject_nr', 'CB_ref', 'practice', 'TrialNumber', 'Sub_bloco', 'SubTaskName',\n",
    "     'aggregated_score_memory', 'average_response_time_processing', 'average_total_time_memory', 'correct',\n",
    "     'correct_response', 'countDys', 'countSym', 'height', 'LeftHalfPos', 'List_SS_button', 'List_SS_Pos', 'live_row',\n",
    "     'logfile', 'maxDys', 'maxSym', 'pressed_buttons', 'response_memory', 'response_processing', 'response_time_memory',\n",
    "     'response_time_processing', 'response_total_time_memory', 'response_total_time_memory_full_task', 'RightHalfPos',\n",
    "     'SP_part_process_time', 'SS_practice_score', 'score_symmetry_span', 'score_subblock_2', 'score_subblock_3',\n",
    "     'score_subblock_4', 'score_subblock_5', 'score_subblock_6', 'SymType',\n",
    "     'total_correct_processing', 'total_response_time_processing', 'width']]\n",
    "df_Symmetry_Span_2 = df_Symmetry_Span_2.astype({'correct_response': 'str', 'response_processing': 'str'})\n",
    "example_d = df_Symmetry_Span_2[\"response_processing\"].iloc[2]\n",
    "df_Symmetry_Span_2 = df_Symmetry_Span_2.replace(example_d, '')\n",
    "#df_Symmetry_Span_2 = df_Symmetry_Span_2.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_Symmetry_Span_2 = df_Symmetry_Span_2.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Symmetry_Span_2.drop(['subject_nr','CB_ref','practice','TrialNumber','Sub_bloco','SubTaskName'],axis=1,inplace=True)\n",
    "df_Symmetry_Span_2.columns = ['aggregated_score_memory_Sess13h00','average_response_time_processing_Sess13h00',\n",
    "                              'average_total_time_memory_Sess13h00','correct_Sess13h00','correct_response_Sess13h00','countDys_Sess13h00',\n",
    "                              'countSym_Sess13h00','height_Sess13h00','LeftHalfPos_Sess13h00','List_SS_button_Sess13h00','List_SS_Pos_Sess13h00',\n",
    "                              'live_row_Sess13h00','logfile_Sess13h00','maxDys_Sess13h00','maxSym_Sess13h00','pressed_buttons_Sess13h00',\n",
    "                              'response_memory_Sess13h00','response_processing_Sess13h00','response_time_memory_Sess13h00',\n",
    "                              'response_time_processing_Sess13h00','response_total_time_memory_Sess13h00',\n",
    "                              'response_total_time_memory_full_task_Sess13h00','RightHalfPos_Sess13h00','SP_part_process_time_Sess13h00',\n",
    "                              'SS_practice_score_Sess13h00','score_symmetry_span_Sess13h00','score_subblock_2_Sess13h00','score_subblock_3_Sess13h00',\n",
    "                              'score_subblock_4_Sess13h00','score_subblock_5_Sess13h00','score_subblock_6_Sess13h00','SymType_Sess13h00',\n",
    "                              'total_correct_processing_Sess13h00','total_response_time_processing_Sess13h00','width_Sess13h00']\n",
    "\n",
    "#'selSNr',\n",
    "df_Symmetry_Span_3 = df_Symmetry_Span_3[\n",
    "    ['subject_nr', 'CB_ref', 'practice', 'TrialNumber', 'Sub_bloco', 'SubTaskName',\n",
    "     'aggregated_score_memory', 'average_response_time_processing', 'average_total_time_memory', 'correct',\n",
    "     'correct_response', 'countDys', 'countSym', 'height', 'LeftHalfPos', 'List_SS_button', 'List_SS_Pos', 'live_row',\n",
    "     'logfile', 'maxDys', 'maxSym', 'pressed_buttons', 'response_memory', 'response_processing', 'response_time_memory',\n",
    "     'response_time_processing', 'response_total_time_memory', 'response_total_time_memory_full_task', 'RightHalfPos',\n",
    "     'SP_part_process_time', 'SS_practice_score', 'score_symmetry_span', 'score_subblock_2', 'score_subblock_3',\n",
    "     'score_subblock_4', 'score_subblock_5', 'score_subblock_6', 'SymType',\n",
    "     'total_correct_processing', 'total_response_time_processing', 'width']]\n",
    "df_Symmetry_Span_3 = df_Symmetry_Span_3.astype({'correct_response': 'str', 'response_processing': 'str'})\n",
    "example_d = df_Symmetry_Span_3[\"response_processing\"].iloc[2]\n",
    "df_Symmetry_Span_3 = df_Symmetry_Span_3.replace(example_d, '')\n",
    "#df_Symmetry_Span_3 = df_Symmetry_Span_3.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_Symmetry_Span_3 = df_Symmetry_Span_3.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Symmetry_Span_3.drop(['subject_nr','CB_ref','practice','TrialNumber','Sub_bloco','SubTaskName'],axis=1,inplace=True)\n",
    "df_Symmetry_Span_3.columns = ['aggregated_score_memory_Sess17h00','average_response_time_processing_Sess17h00',\n",
    "                              'average_total_time_memory_Sess17h00','correct_Sess17h00','correct_response_Sess17h00','countDys_Sess17h00',\n",
    "                              'countSym_Sess17h00','height_Sess17h00','LeftHalfPos_Sess17h00','List_SS_button_Sess17h00','List_SS_Pos_Sess17h00',\n",
    "                              'live_row_Sess17h00','logfile_Sess17h00','maxDys_Sess17h00','maxSym_Sess17h00','pressed_buttons_Sess17h00',\n",
    "                              'response_memory_Sess17h00','response_processing_Sess17h00','response_time_memory_Sess17h00',\n",
    "                              'response_time_processing_Sess17h00','response_total_time_memory_Sess17h00',\n",
    "                              'response_total_time_memory_full_task_Sess17h00','RightHalfPos_Sess17h00','SP_part_process_time_Sess17h00',\n",
    "                              'SS_practice_score_Sess17h00','score_symmetry_span_Sess17h00','score_subblock_2_Sess17h00','score_subblock_3_Sess17h00',\n",
    "                              'score_subblock_4_Sess17h00','score_subblock_5_Sess17h00','score_subblock_6_Sess17h00','SymType_Sess17h00',\n",
    "                              'total_correct_processing_Sess17h00','total_response_time_processing_Sess17h00','width_Sess17h00']\n",
    "\n",
    "#'selSNr',\n",
    "df_Symmetry_Span_4 = df_Symmetry_Span_4[\n",
    "    ['subject_nr', 'CB_ref', 'practice', 'TrialNumber', 'Sub_bloco', 'SubTaskName',\n",
    "     'aggregated_score_memory', 'average_response_time_processing', 'average_total_time_memory', 'correct',\n",
    "     'correct_response', 'countDys', 'countSym', 'height', 'LeftHalfPos', 'List_SS_button', 'List_SS_Pos', 'live_row',\n",
    "     'logfile', 'maxDys', 'maxSym', 'pressed_buttons', 'response_memory', 'response_processing', 'response_time_memory',\n",
    "     'response_time_processing', 'response_total_time_memory', 'response_total_time_memory_full_task', 'RightHalfPos',\n",
    "     'SP_part_process_time', 'SS_practice_score', 'score_symmetry_span', 'score_subblock_2', 'score_subblock_3',\n",
    "     'score_subblock_4', 'score_subblock_5', 'score_subblock_6', 'SymType',\n",
    "     'total_correct_processing', 'total_response_time_processing', 'width']]\n",
    "df_Symmetry_Span_4 = df_Symmetry_Span_4.astype({'correct_response': 'str', 'response_processing': 'str'})\n",
    "example_d = df_Symmetry_Span_4[\"response_processing\"].iloc[2]\n",
    "df_Symmetry_Span_4 = df_Symmetry_Span_4.replace(example_d, '')\n",
    "#df_Symmetry_Span_4 = df_Symmetry_Span_4.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_Symmetry_Span_4 = df_Symmetry_Span_4.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Symmetry_Span_4.drop(['subject_nr','CB_ref','practice','TrialNumber','Sub_bloco','SubTaskName'],axis=1,inplace=True)\n",
    "df_Symmetry_Span_4.columns = ['aggregated_score_memory_Sess21h00','average_response_time_processing_Sess21h00',\n",
    "                              'average_total_time_memory_Sess21h00','correct_Sess21h00','correct_response_Sess21h00','countDys_Sess21h00',\n",
    "                              'countSym_Sess21h00','height_Sess21h00','LeftHalfPos_Sess21h00','List_SS_button_Sess21h00','List_SS_Pos_Sess21h00',\n",
    "                              'live_row_Sess21h00','logfile_Sess21h00','maxDys_Sess21h00','maxSym_Sess21h00','pressed_buttons_Sess21h00',\n",
    "                              'response_memory_Sess21h00','response_processing_Sess21h00','response_time_memory_Sess21h00',\n",
    "                              'response_time_processing_Sess21h00','response_total_time_memory_Sess21h00',\n",
    "                              'response_total_time_memory_full_task_Sess21h00','RightHalfPos_Sess21h00','SP_part_process_time_Sess21h00',\n",
    "                              'SS_practice_score_Sess21h00','score_symmetry_span_Sess21h00','score_subblock_2_Sess21h00','score_subblock_3_Sess21h00',\n",
    "                              'score_subblock_4_Sess21h00','score_subblock_5_Sess21h00','score_subblock_6_Sess21h00','SymType_Sess21h00',\n",
    "                              'total_correct_processing_Sess21h00','total_response_time_processing_Sess21h00','width_Sess21h00']\n",
    "\n",
    "df_Symmetry_Span_Experimental = pd.concat([df_Symmetry_Span_1,df_Symmetry_Span_2,df_Symmetry_Span_3,df_Symmetry_Span_4],axis=1)\n",
    "\n",
    "df_Symmetry_Span_Experimental = df_Symmetry_Span_Experimental[['subject_nr','CB_ref','practice','TrialNumber','Sub_bloco','SubTaskName',\n",
    "                                                 'aggregated_score_memory_Sess09h00','aggregated_score_memory_Sess13h00',\n",
    "                                                 'aggregated_score_memory_Sess17h00','aggregated_score_memory_Sess21h00',\n",
    "                                                 'average_response_time_processing_Sess09h00','average_response_time_processing_Sess13h00',\n",
    "                                                 'average_response_time_processing_Sess17h00','average_response_time_processing_Sess21h00',\n",
    "                                                 'average_total_time_memory_Sess09h00','average_total_time_memory_Sess13h00',\n",
    "                                                 'average_total_time_memory_Sess17h00','average_total_time_memory_Sess21h00',\n",
    "                                                 'correct_Sess09h00','correct_Sess13h00','correct_Sess17h00','correct_Sess21h00',\n",
    "                                                 'correct_response_Sess09h00','correct_response_Sess13h00','correct_response_Sess17h00',\n",
    "                                                 'correct_response_Sess21h00','countDys_Sess09h00','countDys_Sess13h00','countDys_Sess17h00','countDys_Sess21h00',\n",
    "                                                 'countSym_Sess09h00','countSym_Sess13h00','countSym_Sess17h00','countSym_Sess21h00','height_Sess09h00','height_Sess13h00','height_Sess17h00','height_Sess21h00',\n",
    "                                                 'LeftHalfPos_Sess09h00','LeftHalfPos_Sess13h00','LeftHalfPos_Sess17h00','LeftHalfPos_Sess21h00',\n",
    "                                                 'List_SS_button_Sess09h00','List_SS_button_Sess13h00','List_SS_button_Sess17h00','List_SS_button_Sess21h00',\n",
    "                                                 'List_SS_Pos_Sess09h00','List_SS_Pos_Sess13h00','List_SS_Pos_Sess17h00','List_SS_Pos_Sess21h00','live_row_Sess09h00',\n",
    "                                                 'live_row_Sess13h00','live_row_Sess17h00','live_row_Sess21h00','logfile_Sess09h00','logfile_Sess13h00','logfile_Sess17h00',\n",
    "                                                 'logfile_Sess21h00','maxDys_Sess09h00','maxDys_Sess13h00','maxDys_Sess17h00','maxDys_Sess21h00','maxSym_Sess09h00',\n",
    "                                                 'maxSym_Sess13h00','maxSym_Sess17h00','maxSym_Sess21h00','pressed_buttons_Sess09h00','pressed_buttons_Sess13h00',\n",
    "                                                 'pressed_buttons_Sess17h00','pressed_buttons_Sess21h00','response_memory_Sess09h00',\n",
    "                                                 'response_memory_Sess13h00','response_memory_Sess17h00','response_memory_Sess21h00',\n",
    "                                                 'response_processing_Sess09h00','response_processing_Sess13h00','response_processing_Sess17h00',\n",
    "                                                 'response_processing_Sess21h00','response_time_memory_Sess09h00','response_time_memory_Sess13h00','response_time_memory_Sess17h00',\n",
    "                                                 'response_time_memory_Sess21h00','response_time_processing_Sess09h00','response_time_processing_Sess13h00',\n",
    "                                                 'response_time_processing_Sess17h00','response_time_processing_Sess21h00','response_total_time_memory_Sess09h00',\n",
    "                                                 'response_total_time_memory_Sess13h00','response_total_time_memory_Sess17h00','response_total_time_memory_Sess21h00',\n",
    "                                                 'response_total_time_memory_full_task_Sess09h00','response_total_time_memory_full_task_Sess13h00',\n",
    "                                                 'response_total_time_memory_full_task_Sess17h00','response_total_time_memory_full_task_Sess21h00',\n",
    "                                                 'RightHalfPos_Sess09h00','RightHalfPos_Sess13h00','RightHalfPos_Sess17h00','RightHalfPos_Sess21h00',\n",
    "                                                 'SP_part_process_time_Sess09h00','SP_part_process_time_Sess13h00','SP_part_process_time_Sess17h00',\n",
    "                                                 'SP_part_process_time_Sess21h00','SS_practice_score_Sess09h00','SS_practice_score_Sess13h00','SS_practice_score_Sess17h00',\n",
    "                                                 'SS_practice_score_Sess21h00','score_symmetry_span_Sess09h00','score_symmetry_span_Sess13h00',\n",
    "                                                 'score_symmetry_span_Sess17h00','score_symmetry_span_Sess21h00','score_subblock_2_Sess09h00','score_subblock_2_Sess13h00',\n",
    "                                                 'score_subblock_2_Sess17h00','score_subblock_2_Sess21h00','score_subblock_3_Sess09h00','score_subblock_3_Sess13h00',\n",
    "                                                 'score_subblock_3_Sess17h00','score_subblock_3_Sess21h00','score_subblock_4_Sess09h00','score_subblock_4_Sess13h00',\n",
    "                                                 'score_subblock_4_Sess17h00','score_subblock_4_Sess21h00','score_subblock_5_Sess09h00','score_subblock_5_Sess13h00',\n",
    "                                                 'score_subblock_5_Sess17h00','score_subblock_5_Sess21h00','score_subblock_6_Sess09h00','score_subblock_6_Sess13h00',\n",
    "                                                 'score_subblock_6_Sess17h00','score_subblock_6_Sess21h00','SymType_Sess09h00','SymType_Sess13h00','SymType_Sess17h00',\n",
    "                                                 'SymType_Sess21h00','total_correct_processing_Sess09h00','total_correct_processing_Sess13h00','total_correct_processing_Sess17h00',\n",
    "                                                 'total_correct_processing_Sess21h00','total_response_time_processing_Sess09h00','total_response_time_processing_Sess13h00',\n",
    "                                                 'total_response_time_processing_Sess17h00','total_response_time_processing_Sess21h00','width_Sess09h00','width_Sess13h00',\n",
    "                                                 'width_Sess17h00','width_Sess21h00']]\n",
    "\n",
    "############################################################################################\n",
    "############################################################################################\n",
    "#'Probe', 'Target',\n",
    "#'selSNr',\n",
    "df_Binding_Task_1 = df_Binding_Task_1[\n",
    "    ['subject_nr', 'CB_ref', 'practice', 'TrialNumber', 'acc', 'average_response_time',\n",
    "     'BindingRawScore', 'correct', 'correct_response', 'counter', 'Delay', 'eightsec_accuracy', 'FalseAlarms', 'height',\n",
    "     'Hits', 'live_row', 'logfile', 'match_1s_accuracy', 'match_1s_avg_rt', 'match_8s_accuracy', 'match_8s_avg_rt',\n",
    "     'mismatch_1s_accuracy', 'mismatch_1s_avg_rt', 'mismatch_8s_accuracy', 'mismatch_8s_avg_rt', 'NNonResponses',\n",
    "     'Omissions', 'onesec_accuracy', 'QuinetteAccuracyScore', 'QuinetteProcessingScore', 'response',\n",
    "     'response_time', 'ResponsesGiven', 'total_correct', 'total_match_1s_rt', 'total_match_8s_rt',\n",
    "     'total_mismatch_1s_rt', 'total_mismatch_8s_rt', 'total_response_time', 'total_responses', 'width']]\n",
    "df_Binding_Task_1[['acc', 'average_response_time']] = df_Binding_Task_1[['acc', 'average_response_time']].replace(',', '.')\n",
    "df_Binding_Task_1 = df_Binding_Task_1.astype(\n",
    "    {'acc': 'float64', 'average_response_time': 'float64', 'correct_response': 'str', 'response': 'str'})\n",
    "#df_Binding_Task_1 = df_Binding_Task_1.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_Binding_Task_1 = df_Binding_Task_1.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Binding_Task_1.columns = ['subject_nr','CB_ref','practice','TrialNumber','acc_Sess09h00',\n",
    "                             'average_response_time_Sess09h00','BindingRawScore_Sess09h00','correct_Sess09h00','correct_response_Sess09h00',\n",
    "                             'counter_Sess09h00','Delay_Sess09h00','eightsec_accuracy_Sess09h00','FalseAlarms_Sess09h00','height_Sess09h00','Hits_Sess09h00',\n",
    "                             'live_row_Sess09h00','logfile_Sess09h00','match_1s_accuracy_Sess09h00','match_1s_avg_rt_Sess09h00','match_8s_accuracy_Sess09h00',\n",
    "                             'match_8s_avg_rt_Sess09h00','mismatch_1s_accuracy_Sess09h00','mismatch_1s_avg_rt_Sess09h00','mismatch_8s_accuracy_Sess09h00',\n",
    "                             'mismatch_8s_avg_rt_Sess09h00','NNonResponses_Sess09h00','Omissions_Sess09h00','onesec_accuracy_Sess09h00',\n",
    "                             'QuinetteAccuracyScore_Sess09h00','QuinetteProcessingScore_Sess09h00','response_Sess09h00','response_time_Sess09h00',\n",
    "                             'ResponsesGiven_Sess09h00','total_correct_Sess09h00','total_match_1s_rt_Sess09h00','total_match_8s_rt_Sess09h00',\n",
    "                             'total_mismatch_1s_rt_Sess09h00','total_mismatch_8s_rt_Sess09h00','total_response_time_Sess09h00','total_responses_Sess09h00',\n",
    "                             'width_Sess09h00']\n",
    "\n",
    "#'selSNr',\n",
    "df_Binding_Task_2 = df_Binding_Task_2[\n",
    "    ['subject_nr', 'CB_ref', 'practice', 'TrialNumber', 'acc', 'average_response_time',\n",
    "     'BindingRawScore', 'correct', 'correct_response', 'counter', 'Delay', 'eightsec_accuracy', 'FalseAlarms', 'height',\n",
    "     'Hits', 'live_row', 'logfile', 'match_1s_accuracy', 'match_1s_avg_rt', 'match_8s_accuracy', 'match_8s_avg_rt',\n",
    "     'mismatch_1s_accuracy', 'mismatch_1s_avg_rt', 'mismatch_8s_accuracy', 'mismatch_8s_avg_rt', 'NNonResponses',\n",
    "     'Omissions', 'onesec_accuracy', 'QuinetteAccuracyScore', 'QuinetteProcessingScore', 'response',\n",
    "     'response_time', 'ResponsesGiven', 'total_correct', 'total_match_1s_rt', 'total_match_8s_rt',\n",
    "     'total_mismatch_1s_rt', 'total_mismatch_8s_rt', 'total_response_time', 'total_responses', 'width']]\n",
    "df_Binding_Task_2[['acc', 'average_response_time']] = df_Binding_Task_2[['acc', 'average_response_time']].replace(',', '.')\n",
    "df_Binding_Task_2 = df_Binding_Task_2.astype(\n",
    "    {'acc': 'float64', 'average_response_time': 'float64', 'correct_response': 'str', 'response': 'str'})\n",
    "#df_Binding_Task_2 = df_Binding_Task_2.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_Binding_Task_2 = df_Binding_Task_2.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Binding_Task_2.drop(['subject_nr','CB_ref','practice','TrialNumber'],axis=1,inplace=True)\n",
    "df_Binding_Task_2.columns = ['acc_Sess13h00','average_response_time_Sess13h00','BindingRawScore_Sess13h00','correct_Sess13h00','correct_response_Sess13h00',\n",
    "                             'counter_Sess13h00','Delay_Sess13h00','eightsec_accuracy_Sess13h00','FalseAlarms_Sess13h00','height_Sess13h00','Hits_Sess13h00',\n",
    "                             'live_row_Sess13h00','logfile_Sess13h00','match_1s_accuracy_Sess13h00','match_1s_avg_rt_Sess13h00','match_8s_accuracy_Sess13h00',\n",
    "                             'match_8s_avg_rt_Sess13h00','mismatch_1s_accuracy_Sess13h00','mismatch_1s_avg_rt_Sess13h00','mismatch_8s_accuracy_Sess13h00',\n",
    "                             'mismatch_8s_avg_rt_Sess13h00','NNonResponses_Sess13h00','Omissions_Sess13h00','onesec_accuracy_Sess13h00',\n",
    "                             'QuinetteAccuracyScore_Sess13h00','QuinetteProcessingScore_Sess13h00','response_Sess13h00','response_time_Sess13h00',\n",
    "                             'ResponsesGiven_Sess13h00','total_correct_Sess13h00','total_match_1s_rt_Sess13h00','total_match_8s_rt_Sess13h00',\n",
    "                             'total_mismatch_1s_rt_Sess13h00','total_mismatch_8s_rt_Sess13h00','total_response_time_Sess13h00','total_responses_Sess13h00',\n",
    "                             'width_Sess13h00']\n",
    "\n",
    "#'selSNr',\n",
    "df_Binding_Task_3 = df_Binding_Task_3[\n",
    "    ['subject_nr', 'CB_ref', 'practice', 'TrialNumber', 'acc', 'average_response_time',\n",
    "     'BindingRawScore', 'correct', 'correct_response', 'counter', 'Delay', 'eightsec_accuracy', 'FalseAlarms', 'height',\n",
    "     'Hits', 'live_row', 'logfile', 'match_1s_accuracy', 'match_1s_avg_rt', 'match_8s_accuracy', 'match_8s_avg_rt',\n",
    "     'mismatch_1s_accuracy', 'mismatch_1s_avg_rt', 'mismatch_8s_accuracy', 'mismatch_8s_avg_rt', 'NNonResponses',\n",
    "     'Omissions', 'onesec_accuracy', 'QuinetteAccuracyScore', 'QuinetteProcessingScore', 'response',\n",
    "     'response_time', 'ResponsesGiven', 'total_correct', 'total_match_1s_rt', 'total_match_8s_rt',\n",
    "     'total_mismatch_1s_rt', 'total_mismatch_8s_rt', 'total_response_time', 'total_responses', 'width']]\n",
    "df_Binding_Task_3[['acc', 'average_response_time']] = df_Binding_Task_3[['acc', 'average_response_time']].replace(',', '.')\n",
    "df_Binding_Task_3 = df_Binding_Task_3.astype(\n",
    "    {'acc': 'float64', 'average_response_time': 'float64', 'correct_response': 'str', 'response': 'str'})\n",
    "#df_Binding_Task_3 = df_Binding_Task_3.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_Binding_Task_3 = df_Binding_Task_3.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Binding_Task_3.drop(['subject_nr','CB_ref','practice','TrialNumber'],axis=1,inplace=True)\n",
    "df_Binding_Task_3.columns = ['acc_Sess17h00','average_response_time_Sess17h00','BindingRawScore_Sess17h00','correct_Sess17h00','correct_response_Sess17h00',\n",
    "                             'counter_Sess17h00','Delay_Sess17h00','eightsec_accuracy_Sess17h00','FalseAlarms_Sess17h00','height_Sess17h00','Hits_Sess17h00',\n",
    "                             'live_row_Sess17h00','logfile_Sess17h00','match_1s_accuracy_Sess17h00','match_1s_avg_rt_Sess17h00','match_8s_accuracy_Sess17h00',\n",
    "                             'match_8s_avg_rt_Sess17h00','mismatch_1s_accuracy_Sess17h00','mismatch_1s_avg_rt_Sess17h00','mismatch_8s_accuracy_Sess17h00',\n",
    "                             'mismatch_8s_avg_rt_Sess17h00','NNonResponses_Sess17h00','Omissions_Sess17h00','onesec_accuracy_Sess17h00',\n",
    "                             'QuinetteAccuracyScore_Sess17h00','QuinetteProcessingScore_Sess17h00','response_Sess17h00','response_time_Sess17h00',\n",
    "                             'ResponsesGiven_Sess17h00','total_correct_Sess17h00','total_match_1s_rt_Sess17h00','total_match_8s_rt_Sess17h00',\n",
    "                             'total_mismatch_1s_rt_Sess17h00','total_mismatch_8s_rt_Sess17h00','total_response_time_Sess17h00','total_responses_Sess17h00',\n",
    "                             'width_Sess17h00']\n",
    "\n",
    "#'selSNr',\n",
    "df_Binding_Task_4 = df_Binding_Task_4[\n",
    "    ['subject_nr', 'CB_ref', 'practice', 'TrialNumber', 'acc', 'average_response_time',\n",
    "     'BindingRawScore', 'correct', 'correct_response', 'counter', 'Delay', 'eightsec_accuracy', 'FalseAlarms', 'height',\n",
    "     'Hits', 'live_row', 'logfile', 'match_1s_accuracy', 'match_1s_avg_rt', 'match_8s_accuracy', 'match_8s_avg_rt',\n",
    "     'mismatch_1s_accuracy', 'mismatch_1s_avg_rt', 'mismatch_8s_accuracy', 'mismatch_8s_avg_rt', 'NNonResponses',\n",
    "     'Omissions', 'onesec_accuracy', 'QuinetteAccuracyScore', 'QuinetteProcessingScore', 'response',\n",
    "     'response_time', 'ResponsesGiven', 'total_correct', 'total_match_1s_rt', 'total_match_8s_rt',\n",
    "     'total_mismatch_1s_rt', 'total_mismatch_8s_rt', 'total_response_time', 'total_responses', 'width']]\n",
    "df_Binding_Task_4[['acc', 'average_response_time']] = df_Binding_Task_4[['acc', 'average_response_time']].replace(',', '.')\n",
    "df_Binding_Task_4 = df_Binding_Task_4.astype(\n",
    "    {'acc': 'float64', 'average_response_time': 'float64', 'correct_response': 'str', 'response': 'str'})\n",
    "#df_Binding_Task_4 = df_Binding_Task_4.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_Binding_Task_4 = df_Binding_Task_4.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Binding_Task_4.drop(['subject_nr','CB_ref','practice','TrialNumber'],axis=1,inplace=True)\n",
    "df_Binding_Task_4.columns = ['acc_Sess21h00','average_response_time_Sess21h00','BindingRawScore_Sess21h00','correct_Sess21h00','correct_response_Sess21h00',\n",
    "                             'counter_Sess21h00','Delay_Sess21h00','eightsec_accuracy_Sess21h00','FalseAlarms_Sess21h00','height_Sess21h00','Hits_Sess21h00',\n",
    "                             'live_row_Sess21h00','logfile_Sess21h00','match_1s_accuracy_Sess21h00','match_1s_avg_rt_Sess21h00','match_8s_accuracy_Sess21h00',\n",
    "                             'match_8s_avg_rt_Sess21h00','mismatch_1s_accuracy_Sess21h00','mismatch_1s_avg_rt_Sess21h00','mismatch_8s_accuracy_Sess21h00',\n",
    "                             'mismatch_8s_avg_rt_Sess21h00','NNonResponses_Sess21h00','Omissions_Sess21h00','onesec_accuracy_Sess21h00',\n",
    "                             'QuinetteAccuracyScore_Sess21h00','QuinetteProcessingScore_Sess21h00','response_Sess21h00','response_time_Sess21h00',\n",
    "                             'ResponsesGiven_Sess21h00','total_correct_Sess21h00','total_match_1s_rt_Sess21h00','total_match_8s_rt_Sess21h00',\n",
    "                             'total_mismatch_1s_rt_Sess21h00','total_mismatch_8s_rt_Sess21h00','total_response_time_Sess21h00','total_responses_Sess21h00',\n",
    "                             'width_Sess21h00']\n",
    "\n",
    "df_Binding_Task_Experimental = pd.concat([df_Binding_Task_1,df_Binding_Task_2,df_Binding_Task_3,df_Binding_Task_4],axis=1)\n",
    "\n",
    "df_Binding_Task_Experimental = df_Binding_Task_Experimental[['subject_nr','CB_ref','practice','TrialNumber','acc_Sess09h00','acc_Sess13h00','acc_Sess17h00','acc_Sess21h00',\n",
    "                                         'average_response_time_Sess09h00','average_response_time_Sess13h00','average_response_time_Sess17h00','average_response_time_Sess21h00',\n",
    "                                         'BindingRawScore_Sess09h00','BindingRawScore_Sess13h00','BindingRawScore_Sess17h00','BindingRawScore_Sess21h00','correct_Sess09h00',\n",
    "                                         'correct_Sess13h00','correct_Sess17h00','correct_Sess21h00','correct_response_Sess09h00','correct_response_Sess13h00',\n",
    "                                         'correct_response_Sess17h00','correct_response_Sess21h00','counter_Sess09h00','counter_Sess13h00','counter_Sess17h00','counter_Sess21h00',\n",
    "                                         'Delay_Sess09h00','Delay_Sess13h00','Delay_Sess17h00','Delay_Sess21h00','eightsec_accuracy_Sess09h00','eightsec_accuracy_Sess13h00',\n",
    "                                         'eightsec_accuracy_Sess17h00','eightsec_accuracy_Sess21h00','FalseAlarms_Sess09h00','FalseAlarms_Sess13h00','FalseAlarms_Sess17h00',\n",
    "                                         'FalseAlarms_Sess21h00','height_Sess09h00','height_Sess13h00','height_Sess17h00','height_Sess21h00','Hits_Sess09h00','Hits_Sess13h00',\n",
    "                                         'Hits_Sess17h00','Hits_Sess21h00','live_row_Sess09h00','live_row_Sess13h00','live_row_Sess17h00','live_row_Sess21h00','logfile_Sess09h00',\n",
    "                                         'logfile_Sess13h00','logfile_Sess17h00','logfile_Sess21h00','match_1s_accuracy_Sess09h00','match_1s_accuracy_Sess13h00',\n",
    "                                         'match_1s_accuracy_Sess17h00','match_1s_accuracy_Sess21h00','match_1s_avg_rt_Sess09h00','match_1s_avg_rt_Sess13h00','match_1s_avg_rt_Sess17h00',\n",
    "                                         'match_1s_avg_rt_Sess21h00','match_8s_accuracy_Sess09h00','match_8s_accuracy_Sess13h00','match_8s_accuracy_Sess17h00',\n",
    "                                         'match_8s_accuracy_Sess21h00','match_8s_avg_rt_Sess09h00','match_8s_avg_rt_Sess13h00','match_8s_avg_rt_Sess17h00',\n",
    "                                         'match_8s_avg_rt_Sess21h00','mismatch_1s_accuracy_Sess09h00','mismatch_1s_accuracy_Sess13h00','mismatch_1s_accuracy_Sess17h00',\n",
    "                                         'mismatch_1s_accuracy_Sess21h00','mismatch_1s_avg_rt_Sess09h00','mismatch_1s_avg_rt_Sess13h00','mismatch_1s_avg_rt_Sess17h00',\n",
    "                                         'mismatch_1s_avg_rt_Sess21h00','mismatch_8s_accuracy_Sess09h00','mismatch_8s_accuracy_Sess13h00','mismatch_8s_accuracy_Sess17h00',\n",
    "                                         'mismatch_8s_accuracy_Sess21h00','mismatch_8s_avg_rt_Sess09h00','mismatch_8s_avg_rt_Sess13h00','mismatch_8s_avg_rt_Sess17h00',\n",
    "                                         'mismatch_8s_avg_rt_Sess21h00','NNonResponses_Sess09h00','NNonResponses_Sess13h00','NNonResponses_Sess17h00',\n",
    "                                         'NNonResponses_Sess21h00','Omissions_Sess09h00','Omissions_Sess13h00','Omissions_Sess17h00',\n",
    "                                         'Omissions_Sess21h00','onesec_accuracy_Sess09h00','onesec_accuracy_Sess13h00','onesec_accuracy_Sess17h00',\n",
    "                                         'onesec_accuracy_Sess21h00','QuinetteAccuracyScore_Sess09h00','QuinetteAccuracyScore_Sess13h00','QuinetteAccuracyScore_Sess17h00',\n",
    "                                         'QuinetteAccuracyScore_Sess21h00','QuinetteProcessingScore_Sess09h00','QuinetteProcessingScore_Sess13h00',\n",
    "                                         'QuinetteProcessingScore_Sess17h00','QuinetteProcessingScore_Sess21h00','response_Sess09h00',\n",
    "                                         'response_Sess13h00','response_Sess17h00','response_Sess21h00','response_time_Sess09h00','response_time_Sess13h00',\n",
    "                                         'response_time_Sess17h00','response_time_Sess21h00','ResponsesGiven_Sess09h00','ResponsesGiven_Sess13h00',\n",
    "                                         'ResponsesGiven_Sess17h00','ResponsesGiven_Sess21h00','total_correct_Sess09h00','total_correct_Sess13h00','total_correct_Sess17h00',\n",
    "                                         'total_correct_Sess21h00','total_match_1s_rt_Sess09h00','total_match_1s_rt_Sess13h00','total_match_1s_rt_Sess17h00',\n",
    "                                         'total_match_1s_rt_Sess21h00','total_match_8s_rt_Sess09h00','total_match_8s_rt_Sess13h00','total_match_8s_rt_Sess17h00',\n",
    "                                         'total_match_8s_rt_Sess21h00','total_mismatch_1s_rt_Sess09h00','total_mismatch_1s_rt_Sess13h00','total_mismatch_1s_rt_Sess17h00',\n",
    "                                         'total_mismatch_1s_rt_Sess21h00','total_mismatch_8s_rt_Sess09h00','total_mismatch_8s_rt_Sess13h00','total_mismatch_8s_rt_Sess17h00',\n",
    "                                         'total_mismatch_8s_rt_Sess21h00','total_response_time_Sess09h00','total_response_time_Sess13h00','total_response_time_Sess17h00',\n",
    "                                         'total_response_time_Sess21h00','total_responses_Sess09h00','total_responses_Sess13h00','total_responses_Sess17h00','total_responses_Sess21h00',\n",
    "                                         'width_Sess09h00','width_Sess13h00','width_Sess17h00','width_Sess21h00']]\n",
    "\n",
    "############################################################################################\n",
    "############################################################################################\n",
    "#'selSNr',\n",
    "df_Operation_Span_1 = df_Operation_Span_1[\n",
    "    ['subject_nr', 'CB_ref', 'practice', 'TrialNumber', 'Sub_bloco', 'SubTaskName', 'acc', 'avg_rt',\n",
    "     'BlockChoice', 'correct', 'correct_response', 'height', 'letter', 'List_Prev_Letter', 'List_responses_memory',\n",
    "     'live_row', 'logfile', 'response_average_time_memory', 'response_memory', 'response_processing',\n",
    "     'response_time_memory', 'response_time_processing', 'response_total_time_memory', 'OP_part_process_time',\n",
    "     'score_practice', 'score_operation_span', 'score_subblock_2', 'score_subblock_3', 'score_subblock_4', 'score_subblock_5',\n",
    "     'score_subblock_6', 'Tipo', 'total_correct', 'total_response_time',\n",
    "     'total_responses', 'width']]\n",
    "df_Operation_Span_1[['acc', 'avg_rt']] = df_Operation_Span_1[['acc', 'avg_rt']].replace(',', '.')\n",
    "df_Operation_Span_1 = df_Operation_Span_1.astype(\n",
    "    {'acc': 'float64', 'avg_rt': 'float64', 'correct_response': 'str', 'response_processing': 'str'})\n",
    "example_c = df_Operation_Span_1[\"response_processing\"].iloc[2]\n",
    "df_Operation_Span_1 = df_Operation_Span_1.replace(example_c, '')\n",
    "#df_Operation_Span_1 = df_Operation_Span_1.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_Operation_Span_1 = df_Operation_Span_1.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Operation_Span_1.columns = ['subject_nr','CB_ref','practice','TrialNumber','Sub_bloco',\n",
    "                               'SubTaskName','acc_Sess09h00','avg_rt_Sess09h00','BlockChoice_Sess09h00','correct_Sess09h00',\n",
    "                               'correct_response_Sess09h00','height_Sess09h00','letter_Sess09h00','List_Prev_Letter_Sess09h00',\n",
    "                               'List_responses_memory_Sess09h00','live_row_Sess09h00','logfile_Sess09h00','response_average_time_memory_Sess09h00',\n",
    "                               'response_memory_Sess09h00','response_processing_Sess09h00','response_time_memory_Sess09h00',\n",
    "                               'response_time_processing_Sess09h00','response_total_time_memory_Sess09h00','OP_part_process_time_Sess09h00',\n",
    "                               'score_practice_Sess09h00','score_operation_span_Sess09h00','score_subblock_2_Sess09h00','score_subblock_3_Sess09h00',\n",
    "                               'score_subblock_4_Sess09h00','score_subblock_5_Sess09h00','score_subblock_6_Sess09h00','Tipo_Sess09h00',\n",
    "                               'total_correct_Sess09h00','total_response_time_Sess09h00','total_responses_Sess09h00','width_Sess09h00']\n",
    "\n",
    "#'selSNr',\n",
    "df_Operation_Span_2 = df_Operation_Span_2[\n",
    "    ['subject_nr', 'CB_ref', 'practice', 'TrialNumber', 'Sub_bloco', 'SubTaskName', 'acc', 'avg_rt',\n",
    "     'BlockChoice', 'correct', 'correct_response', 'height', 'letter', 'List_Prev_Letter', 'List_responses_memory',\n",
    "     'live_row', 'logfile', 'response_average_time_memory', 'response_memory', 'response_processing',\n",
    "     'response_time_memory', 'response_time_processing', 'response_total_time_memory', 'OP_part_process_time',\n",
    "     'score_practice', 'score_operation_span', 'score_subblock_2', 'score_subblock_3', 'score_subblock_4', 'score_subblock_5',\n",
    "     'score_subblock_6', 'Tipo', 'total_correct', 'total_response_time',\n",
    "     'total_responses', 'width']]\n",
    "df_Operation_Span_2[['acc', 'avg_rt']] = df_Operation_Span_2[['acc', 'avg_rt']].replace(',', '.')\n",
    "df_Operation_Span_2 = df_Operation_Span_2.astype(\n",
    "    {'acc': 'float64', 'avg_rt': 'float64', 'correct_response': 'str', 'response_processing': 'str'})\n",
    "example_c = df_Operation_Span_2[\"response_processing\"].iloc[2]\n",
    "df_Operation_Span_2 = df_Operation_Span_2.replace(example_c, '')\n",
    "#df_Operation_Span_2 = df_Operation_Span_2.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_Operation_Span_2 = df_Operation_Span_2.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Operation_Span_2.drop(['subject_nr','CB_ref','practice','TrialNumber','Sub_bloco','SubTaskName'],axis=1,inplace=True)\n",
    "df_Operation_Span_2.columns = ['acc_Sess13h00','avg_rt_Sess13h00','BlockChoice_Sess13h00','correct_Sess13h00',\n",
    "                               'correct_response_Sess13h00','height_Sess13h00','letter_Sess13h00','List_Prev_Letter_Sess13h00',\n",
    "                               'List_responses_memory_Sess13h00','live_row_Sess13h00','logfile_Sess13h00','response_average_time_memory_Sess13h00',\n",
    "                               'response_memory_Sess13h00','response_processing_Sess13h00','response_time_memory_Sess13h00',\n",
    "                               'response_time_processing_Sess13h00','response_total_time_memory_Sess13h00','OP_part_process_time_Sess13h00',\n",
    "                               'score_practice_Sess13h00','score_operation_span_Sess13h00','score_subblock_2_Sess13h00','score_subblock_3_Sess13h00',\n",
    "                               'score_subblock_4_Sess13h00','score_subblock_5_Sess13h00','score_subblock_6_Sess13h00','Tipo_Sess13h00',\n",
    "                               'total_correct_Sess13h00','total_response_time_Sess13h00','total_responses_Sess13h00','width_Sess13h00']\n",
    "\n",
    "#'selSNr',\n",
    "df_Operation_Span_3 = df_Operation_Span_3[\n",
    "    ['subject_nr', 'CB_ref', 'practice', 'TrialNumber', 'Sub_bloco', 'SubTaskName', 'acc', 'avg_rt',\n",
    "     'BlockChoice', 'correct', 'correct_response', 'height', 'letter', 'List_Prev_Letter', 'List_responses_memory',\n",
    "     'live_row', 'logfile', 'response_average_time_memory', 'response_memory', 'response_processing',\n",
    "     'response_time_memory', 'response_time_processing', 'response_total_time_memory', 'OP_part_process_time',\n",
    "     'score_practice', 'score_operation_span', 'score_subblock_2', 'score_subblock_3', 'score_subblock_4', 'score_subblock_5',\n",
    "     'score_subblock_6', 'Tipo', 'total_correct', 'total_response_time',\n",
    "     'total_responses', 'width']]\n",
    "df_Operation_Span_3[['acc', 'avg_rt']] = df_Operation_Span_3[['acc', 'avg_rt']].replace(',', '.')\n",
    "df_Operation_Span_3 = df_Operation_Span_3.astype(\n",
    "    {'acc': 'float64', 'avg_rt': 'float64', 'correct_response': 'str', 'response_processing': 'str'})\n",
    "example_c = df_Operation_Span_3[\"response_processing\"].iloc[2]\n",
    "df_Operation_Span_3 = df_Operation_Span_3.replace(example_c, '')\n",
    "#df_Operation_Span_3 = df_Operation_Span_3.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_Operation_Span_3 = df_Operation_Span_3.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Operation_Span_3.drop(['subject_nr','CB_ref','practice','TrialNumber','Sub_bloco','SubTaskName'],axis=1,inplace=True)\n",
    "df_Operation_Span_3.columns = ['acc_Sess17h00','avg_rt_Sess17h00','BlockChoice_Sess17h00','correct_Sess17h00',\n",
    "                               'correct_response_Sess17h00','height_Sess17h00','letter_Sess17h00','List_Prev_Letter_Sess17h00',\n",
    "                               'List_responses_memory_Sess17h00','live_row_Sess17h00','logfile_Sess17h00','response_average_time_memory_Sess17h00',\n",
    "                               'response_memory_Sess17h00','response_processing_Sess17h00','response_time_memory_Sess17h00',\n",
    "                               'response_time_processing_Sess17h00','response_total_time_memory_Sess17h00','OP_part_process_time_Sess17h00',\n",
    "                               'score_practice_Sess17h00','score_operation_span_Sess17h00','score_subblock_2_Sess17h00','score_subblock_3_Sess17h00',\n",
    "                               'score_subblock_4_Sess17h00','score_subblock_5_Sess17h00','score_subblock_6_Sess17h00','Tipo_Sess17h00',\n",
    "                               'total_correct_Sess17h00','total_response_time_Sess17h00','total_responses_Sess17h00','width_Sess17h00']\n",
    "\n",
    "#'selSNr',\n",
    "df_Operation_Span_4 = df_Operation_Span_4[\n",
    "    ['subject_nr', 'CB_ref', 'practice', 'TrialNumber', 'Sub_bloco', 'SubTaskName', 'acc', 'avg_rt',\n",
    "     'BlockChoice', 'correct', 'correct_response', 'height', 'letter', 'List_Prev_Letter', 'List_responses_memory',\n",
    "     'live_row', 'logfile', 'response_average_time_memory', 'response_memory', 'response_processing',\n",
    "     'response_time_memory', 'response_time_processing', 'response_total_time_memory', 'OP_part_process_time',\n",
    "     'score_practice', 'score_operation_span', 'score_subblock_2', 'score_subblock_3', 'score_subblock_4', 'score_subblock_5',\n",
    "     'score_subblock_6', 'Tipo', 'total_correct', 'total_response_time',\n",
    "     'total_responses', 'width']]\n",
    "df_Operation_Span_4[['acc', 'avg_rt']] = df_Operation_Span_4[['acc', 'avg_rt']].replace(',', '.')\n",
    "df_Operation_Span_4 = df_Operation_Span_4.astype(\n",
    "    {'acc': 'float64', 'avg_rt': 'float64', 'correct_response': 'str', 'response_processing': 'str'})\n",
    "example_c = df_Operation_Span_4[\"response_processing\"].iloc[2]\n",
    "df_Operation_Span_4 = df_Operation_Span_4.replace(example_c, '')\n",
    "#df_Operation_Span_4 = df_Operation_Span_4.sort_values(by=['selSNr'], kind='mergesort')\n",
    "#df_Operation_Span_4 = df_Operation_Span_4.sort_values(by=['subject_nr'], kind='mergesort')\n",
    "df_Operation_Span_4.drop(['subject_nr','CB_ref','practice','TrialNumber','Sub_bloco','SubTaskName'],axis=1,inplace=True)\n",
    "df_Operation_Span_4.columns = ['acc_Sess21h00','avg_rt_Sess21h00','BlockChoice_Sess21h00','correct_Sess21h00',\n",
    "                               'correct_response_Sess21h00','height_Sess21h00','letter_Sess21h00','List_Prev_Letter_Sess21h00',\n",
    "                               'List_responses_memory_Sess21h00','live_row_Sess21h00','logfile_Sess21h00','response_average_time_memory_Sess21h00',\n",
    "                               'response_memory_Sess21h00','response_processing_Sess21h00','response_time_memory_Sess21h00',\n",
    "                               'response_time_processing_Sess21h00','response_total_time_memory_Sess21h00','OP_part_process_time_Sess21h00',\n",
    "                               'score_practice_Sess21h00','score_operation_span_Sess21h00','score_subblock_2_Sess21h00','score_subblock_3_Sess21h00',\n",
    "                               'score_subblock_4_Sess21h00','score_subblock_5_Sess21h00','score_subblock_6_Sess21h00','Tipo_Sess21h00',\n",
    "                               'total_correct_Sess21h00','total_response_time_Sess21h00','total_responses_Sess21h00','width_Sess21h00']\n",
    "\n",
    "df_Operation_Span_Experimental = pd.concat([df_Operation_Span_1,df_Operation_Span_2,df_Operation_Span_3,df_Operation_Span_4],axis=1)\n",
    "\n",
    "\n",
    "df_Operation_Span_Experimental = df_Operation_Span_Experimental[['subject_nr','CB_ref','practice','TrialNumber','Sub_bloco','SubTaskName',\n",
    "                                                   'acc_Sess09h00','acc_Sess13h00','acc_Sess17h00','acc_Sess21h00','avg_rt_Sess09h00','avg_rt_Sess13h00','avg_rt_Sess17h00','avg_rt_Sess21h00',\n",
    "                                                   'BlockChoice_Sess09h00','BlockChoice_Sess13h00','BlockChoice_Sess17h00','BlockChoice_Sess21h00','correct_Sess09h00',\n",
    "                                                   'correct_Sess13h00','correct_Sess17h00','correct_Sess21h00','correct_response_Sess09h00','correct_response_Sess13h00',\n",
    "                                                   'correct_response_Sess17h00','correct_response_Sess21h00','height_Sess09h00','height_Sess13h00','height_Sess17h00','height_Sess21h00',\n",
    "                                                   'letter_Sess09h00','letter_Sess13h00','letter_Sess17h00','letter_Sess21h00','List_Prev_Letter_Sess09h00','List_Prev_Letter_Sess13h00',\n",
    "                                                   'List_Prev_Letter_Sess17h00','List_Prev_Letter_Sess21h00','List_responses_memory_Sess09h00','List_responses_memory_Sess13h00',\n",
    "                                                   'List_responses_memory_Sess17h00','List_responses_memory_Sess21h00','live_row_Sess09h00','live_row_Sess13h00','live_row_Sess17h00',\n",
    "                                                   'live_row_Sess21h00','logfile_Sess09h00','logfile_Sess13h00','logfile_Sess17h00','logfile_Sess21h00',\n",
    "                                                   'response_average_time_memory_Sess09h00','response_average_time_memory_Sess13h00','response_average_time_memory_Sess17h00',\n",
    "                                                   'response_average_time_memory_Sess21h00','response_memory_Sess09h00','response_memory_Sess13h00','response_memory_Sess17h00',\n",
    "                                                   'response_memory_Sess21h00','response_processing_Sess09h00','response_processing_Sess13h00','response_processing_Sess17h00',\n",
    "                                                   'response_processing_Sess21h00','response_time_memory_Sess09h00','response_time_memory_Sess13h00','response_time_memory_Sess17h00',\n",
    "                                                   'response_time_memory_Sess21h00','response_time_processing_Sess09h00','response_time_processing_Sess13h00',\n",
    "                                                   'response_time_processing_Sess17h00','response_time_processing_Sess21h00','response_total_time_memory_Sess09h00',\n",
    "                                                   'response_total_time_memory_Sess13h00','response_total_time_memory_Sess17h00','response_total_time_memory_Sess21h00',\n",
    "                                                   'OP_part_process_time_Sess09h00','OP_part_process_time_Sess13h00','OP_part_process_time_Sess17h00',\n",
    "                                                   'OP_part_process_time_Sess21h00','score_practice_Sess09h00','score_practice_Sess13h00','score_practice_Sess17h00',\n",
    "                                                   'score_practice_Sess21h00','score_operation_span_Sess09h00','score_operation_span_Sess13h00','score_operation_span_Sess17h00',\n",
    "                                                   'score_operation_span_Sess21h00','score_subblock_2_Sess09h00','score_subblock_2_Sess13h00','score_subblock_2_Sess17h00',\n",
    "                                                   'score_subblock_2_Sess21h00','score_subblock_3_Sess09h00','score_subblock_3_Sess13h00','score_subblock_3_Sess17h00',\n",
    "                                                   'score_subblock_3_Sess21h00','score_subblock_4_Sess09h00','score_subblock_4_Sess13h00','score_subblock_4_Sess17h00',\n",
    "                                                   'score_subblock_4_Sess21h00','score_subblock_5_Sess09h00','score_subblock_5_Sess13h00','score_subblock_5_Sess17h00',\n",
    "                                                   'score_subblock_5_Sess21h00','score_subblock_6_Sess09h00','score_subblock_6_Sess13h00','score_subblock_6_Sess17h00',\n",
    "                                                   'score_subblock_6_Sess21h00','Tipo_Sess09h00','Tipo_Sess13h00','Tipo_Sess17h00','Tipo_Sess21h00','total_correct_Sess09h00',\n",
    "                                                   'total_correct_Sess13h00','total_correct_Sess17h00','total_correct_Sess21h00','total_response_time_Sess09h00',\n",
    "                                                   'total_response_time_Sess13h00','total_response_time_Sess17h00','total_response_time_Sess21h00','total_responses_Sess09h00',\n",
    "                                                   'total_responses_Sess13h00','total_responses_Sess17h00','total_responses_Sess21h00','width_Sess09h00','width_Sess13h00',\n",
    "                                                   'width_Sess17h00','width_Sess21h00']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14afba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\",10)\n",
    "df_Reading_Span_Experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99e0e7f",
   "metadata": {},
   "source": [
    "## 5.3. Generates DB with the raw scores in the 5 WM tasks Experimental Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb661ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_scores = pd.DataFrame()\n",
    "\n",
    "subj_nr = df_total_part[\"subject_nr\"].unique()\n",
    "df_raw_scores.insert(0,'subject_nr',subj_nr)\n",
    "########################################################################################################\n",
    "\n",
    "Temperature = pd.read_excel(r'C:\\Users\\fabio\\OneDrive\\Área de Trabalho\\RPubs\\Article 3\\Temperature\\Body_Temperature_Collection.xlsx',sheet_name='TempExperimental')\n",
    "Temperature.drop(columns=\"Subject ID\", inplace=True)\n",
    "\n",
    "df_raw_scores[\"Temperature (°C) Sess 09h00\"] = list(Temperature[\"Temperature (°C) Sess 09h00\"])\n",
    "df_raw_scores[\"Temperature (°C) Sess 13h00\"] = list(Temperature[\"Temperature (°C) Sess 13h00\"])\n",
    "df_raw_scores[\"Temperature (°C) Sess 17h00\"] = list(Temperature[\"Temperature (°C) Sess 17h00\"])\n",
    "df_raw_scores[\"Temperature (°C) Sess 21h00\"] = list(Temperature[\"Temperature (°C) Sess 21h00\"])\n",
    "\n",
    "#######################################################################################################\n",
    "\n",
    "RawRS1 = list(df_Reading_Span_1.groupby(['subject_nr'], sort=True)['score_reading_span_Sess09h00'].max() * 20)\n",
    "df_raw_scores[\"Reading Span Session 09h00\"] = RawRS1\n",
    "cols_to_add = [\n",
    "    'subject_nr', 'CB_ref', 'practice', \n",
    "    'TrialNumber', 'Sub_bloco', 'SubTaskName'\n",
    "]\n",
    "for col in cols_to_add:\n",
    "    df_Reading_Span_2.insert(\n",
    "        loc=0,                          # insert at the beginning\n",
    "        column=col, \n",
    "        value=df_Reading_Span_1[col].values\n",
    "    )\n",
    "RawRS2 = list(df_Reading_Span_2.groupby(['subject_nr'], sort=True)['score_reading_span_Sess13h00'].max() * 20)\n",
    "df_raw_scores[\"Reading Span Session 13h00\"] = RawRS2\n",
    "cols_to_add = [\n",
    "    'subject_nr', 'CB_ref', 'practice', \n",
    "    'TrialNumber', 'Sub_bloco', 'SubTaskName'\n",
    "]\n",
    "for col in cols_to_add:\n",
    "    df_Reading_Span_3.insert(\n",
    "        loc=0,                          # insert at the beginning\n",
    "        column=col, \n",
    "        value=df_Reading_Span_1[col].values\n",
    "    )\n",
    "RawRS3 = list(df_Reading_Span_3.groupby(['subject_nr'], sort=True)['score_reading_span_Sess17h00'].max() * 20)\n",
    "df_raw_scores[\"Reading Span Session 17h00\"] = RawRS3\n",
    "cols_to_add = [\n",
    "    'subject_nr', 'CB_ref', 'practice', \n",
    "    'TrialNumber', 'Sub_bloco', 'SubTaskName'\n",
    "]\n",
    "for col in cols_to_add:\n",
    "    df_Reading_Span_4.insert(\n",
    "        loc=0,                          # insert at the beginning\n",
    "        column=col, \n",
    "        value=df_Reading_Span_1[col].values\n",
    "    )\n",
    "RawRS4 = list(df_Reading_Span_4.groupby(['subject_nr'], sort=True)['score_reading_span_Sess21h00'].max() * 20)\n",
    "df_raw_scores[\"Reading Span Session 21h00\"] = RawRS4\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "RawUT1 = list(df_WMU_Task_1.groupby(['subject_nr'], sort=True)['WMUExperimentalScore_Sess09h00'].max())\n",
    "df_raw_scores[\"Updating Task Session 09h00\"] = RawUT1\n",
    "cols_to_add = [\n",
    "    'subject_nr'\n",
    "]\n",
    "for col in cols_to_add:\n",
    "    df_WMU_Task_2.insert(\n",
    "        loc=0,                          # insert at the beginning\n",
    "        column=col, \n",
    "        value=df_WMU_Task_1[col].values\n",
    "    )\n",
    "RawUT2 = list(df_WMU_Task_2.groupby(['subject_nr'], sort=True)['WMUExperimentalScore_Sess13h00'].max())\n",
    "df_raw_scores[\"Updating Task Session 13h00\"] = RawUT2\n",
    "cols_to_add = [\n",
    "    'subject_nr'\n",
    "]\n",
    "for col in cols_to_add:\n",
    "    df_WMU_Task_3.insert(\n",
    "        loc=0,                          # insert at the beginning\n",
    "        column=col, \n",
    "        value=df_WMU_Task_1[col].values\n",
    "    )\n",
    "RawUT3 = list(df_WMU_Task_3.groupby(['subject_nr'], sort=True)['WMUExperimentalScore_Sess17h00'].max())\n",
    "df_raw_scores[\"Updating Task Session 17h00\"] = RawUT3\n",
    "cols_to_add = [\n",
    "    'subject_nr'\n",
    "]\n",
    "for col in cols_to_add:\n",
    "    df_WMU_Task_4.insert(\n",
    "        loc=0,                          # insert at the beginning\n",
    "        column=col, \n",
    "        value=df_WMU_Task_1[col].values\n",
    "    )\n",
    "RawUT4 = list(df_WMU_Task_4.groupby(['subject_nr'], sort=True)['WMUExperimentalScore_Sess21h00'].max())\n",
    "df_raw_scores[\"Updating Task Session 21h00\"] = RawUT4\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "RawSS1 = list(df_Symmetry_Span_1.groupby(['subject_nr'], sort=True)['score_symmetry_span_Sess09h00'].max() * 20)\n",
    "df_raw_scores[\"Symmetry Span Session 09h00\"] = RawSS1\n",
    "cols_to_add = [\n",
    "    'subject_nr'\n",
    "]\n",
    "for col in cols_to_add:\n",
    "    df_Symmetry_Span_2.insert(\n",
    "        loc=0,                          # insert at the beginning\n",
    "        column=col, \n",
    "        value=df_Symmetry_Span_1[col].values\n",
    "    )\n",
    "RawSS2 = list(df_Symmetry_Span_2.groupby(['subject_nr'], sort=True)['score_symmetry_span_Sess13h00'].max() * 20)\n",
    "df_raw_scores[\"Symmetry Span Session 13h00\"] = RawSS2\n",
    "cols_to_add = [\n",
    "    'subject_nr'\n",
    "]\n",
    "for col in cols_to_add:\n",
    "    df_Symmetry_Span_3.insert(\n",
    "        loc=0,                          # insert at the beginning\n",
    "        column=col, \n",
    "        value=df_Symmetry_Span_1[col].values\n",
    "    )\n",
    "RawSS3 = list(df_Symmetry_Span_3.groupby(['subject_nr'], sort=True)['score_symmetry_span_Sess17h00'].max() * 20)\n",
    "df_raw_scores[\"Symmetry Span Session 17h00\"] = RawSS3\n",
    "cols_to_add = [\n",
    "    'subject_nr'\n",
    "]\n",
    "for col in cols_to_add:\n",
    "    df_Symmetry_Span_4.insert(\n",
    "        loc=0,                          # insert at the beginning\n",
    "        column=col, \n",
    "        value=df_Symmetry_Span_1[col].values\n",
    "    )\n",
    "RawSS4 = list(df_Symmetry_Span_4.groupby(['subject_nr'], sort=True)['score_symmetry_span_Sess21h00'].max() * 20)\n",
    "df_raw_scores[\"Symmetry Span Session 21h00\"] = RawSS4\n",
    "\n",
    "########################################################################################################\n",
    "RawBT1 = list(df_Binding_Task_1.groupby(['subject_nr'], sort=True)['BindingRawScore_Sess09h00'].max())\n",
    "df_raw_scores[\"Binding Task Session 09h00\"] = RawBT1\n",
    "cols_to_add = [\n",
    "    'subject_nr'\n",
    "]\n",
    "for col in cols_to_add:\n",
    "    df_Binding_Task_2.insert(\n",
    "        loc=0,                          # insert at the beginning\n",
    "        column=col, \n",
    "        value=df_Binding_Task_1[col].values\n",
    "    )\n",
    "RawBT2 = list(df_Binding_Task_2.groupby(['subject_nr'], sort=True)['BindingRawScore_Sess13h00'].max())\n",
    "df_raw_scores[\"Binding Task Session 13h00\"] = RawBT2\n",
    "cols_to_add = [\n",
    "    'subject_nr'\n",
    "]\n",
    "for col in cols_to_add:\n",
    "    df_Binding_Task_3.insert(\n",
    "        loc=0,                          # insert at the beginning\n",
    "        column=col, \n",
    "        value=df_Binding_Task_1[col].values\n",
    "    )\n",
    "RawBT3 = list(df_Binding_Task_3.groupby(['subject_nr'], sort=True)['BindingRawScore_Sess17h00'].max())\n",
    "df_raw_scores[\"Binding Task Session 17h00\"] = RawBT3\n",
    "cols_to_add = [\n",
    "    'subject_nr'\n",
    "]\n",
    "for col in cols_to_add:\n",
    "    df_Binding_Task_4.insert(\n",
    "        loc=0,                          # insert at the beginning\n",
    "        column=col, \n",
    "        value=df_Binding_Task_1[col].values\n",
    "    )\n",
    "RawBT4 = list(df_Binding_Task_4.groupby(['subject_nr'], sort=True)['BindingRawScore_Sess21h00'].max())\n",
    "df_raw_scores[\"Binding Task Session 21h00\"] = RawBT4\n",
    "\n",
    "########################################################################################################\n",
    "RawOS1 = list(df_Operation_Span_1.groupby(['subject_nr'], sort=True)['score_operation_span_Sess09h00'].max() * 20)\n",
    "df_raw_scores[\"Operation Span Session 09h00\"] = RawOS1\n",
    "cols_to_add = [\n",
    "    'subject_nr'\n",
    "]\n",
    "for col in cols_to_add:\n",
    "    df_Operation_Span_2.insert(\n",
    "        loc=0,                          # insert at the beginning\n",
    "        column=col, \n",
    "        value=df_Operation_Span_1[col].values\n",
    "    )\n",
    "RawOS2 = list(df_Operation_Span_2.groupby(['subject_nr'], sort=True)['score_operation_span_Sess13h00'].max() * 20)\n",
    "df_raw_scores[\"Operation Span Session 13h00\"] = RawOS2\n",
    "cols_to_add = [\n",
    "    'subject_nr'\n",
    "]\n",
    "for col in cols_to_add:\n",
    "    df_Operation_Span_3.insert(\n",
    "        loc=0,                          # insert at the beginning\n",
    "        column=col, \n",
    "        value=df_Operation_Span_1[col].values\n",
    "    )\n",
    "RawOS3 = list(df_Operation_Span_3.groupby(['subject_nr'], sort=True)['score_operation_span_Sess17h00'].max() * 20)\n",
    "df_raw_scores[\"Operation Span Session 17h00\"] = RawOS3\n",
    "cols_to_add = [\n",
    "    'subject_nr'\n",
    "]\n",
    "for col in cols_to_add:\n",
    "    df_Operation_Span_4.insert(\n",
    "        loc=0,                          # insert at the beginning\n",
    "        column=col, \n",
    "        value=df_Operation_Span_1[col].values\n",
    "    )\n",
    "RawOS4 = list(df_Operation_Span_4.groupby(['subject_nr'], sort=True)['score_operation_span_Sess21h00'].max() * 20)\n",
    "df_raw_scores[\"Operation Span Session 21h00\"] = RawOS4\n",
    "\n",
    "list_counterbalancing = []\n",
    "for i in range(0,len(df_raw_scores)):\n",
    "    if 1 <= df_raw_scores.loc[i,'subject_nr'] <= 5 or df_raw_scores.loc[i,'subject_nr'] == 21 or df_raw_scores.loc[i,'subject_nr'] == 25:\n",
    "        aaa = '09h00,13h00,17h00,21h00'\n",
    "        list_counterbalancing.append(aaa)\n",
    "    elif 6 <= df_raw_scores.loc[i,'subject_nr'] <= 10 or df_raw_scores.loc[i,'subject_nr'] == 22 or df_raw_scores.loc[i,'subject_nr'] == 26:\n",
    "        aaa = '13h00,17h00,21h00,09h00'\n",
    "        list_counterbalancing.append(aaa)\n",
    "    elif 11 <= df_raw_scores.loc[i,'subject_nr'] <= 15 or df_raw_scores.loc[i,'subject_nr'] == 23  or df_raw_scores.loc[i,'subject_nr'] == 27:\n",
    "        aaa = '17h00,21h00,09h00,13h00'\n",
    "        list_counterbalancing.append(aaa)\n",
    "    elif 16 <= df_raw_scores.loc[i,'subject_nr'] <= 20 or df_raw_scores.loc[i,'subject_nr'] == 24  or df_raw_scores.loc[i,'subject_nr'] == 28:\n",
    "        aaa = '21h00,09h00,13h00,17h00'\n",
    "        list_counterbalancing.append(aaa)\n",
    "\n",
    "df_raw_scores.insert(1, 'Counterbalancing', list_counterbalancing)\n",
    "df_raw_scores = df_raw_scores.astype({\n",
    "    col: 'int' \n",
    "    for col in df_raw_scores.columns \n",
    "    if col not in ['subject_nr', 'Counterbalancing','Temperature (°C) Sess 09h00','Temperature (°C) Sess 13h00','Temperature (°C) Sess 17h00',\n",
    "                   'Temperature (°C) Sess 21h00']\n",
    "})\n",
    "\n",
    "df_raw_scores_exper = df_raw_scores.sort_values(by=\"subject_nr\")\n",
    "df_raw_scores_exper\n",
    "\n",
    "pd.set_option(\"display.max_columns\",None)\n",
    "df_raw_scores_exper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7207c787",
   "metadata": {},
   "source": [
    "## 5.4. Generates DB with the normalized scores in the 5 WM tasks Experimental Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c51a08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_normalized_scores_exper = df_raw_scores_exper.copy(deep=True)\n",
    "\n",
    "df_normalized_scores_exper[\"Reading Span Session 09h00\"] = df_normalized_scores_exper[\"Reading Span Session 09h00\"]/20\n",
    "df_normalized_scores_exper[\"Reading Span Session 13h00\"] = df_normalized_scores_exper[\"Reading Span Session 13h00\"]/20\n",
    "df_normalized_scores_exper[\"Reading Span Session 17h00\"] = df_normalized_scores_exper[\"Reading Span Session 17h00\"]/20\n",
    "df_normalized_scores_exper[\"Reading Span Session 21h00\"] = df_normalized_scores_exper[\"Reading Span Session 21h00\"]/20\n",
    "df_normalized_scores_exper[\"Updating Task Session 09h00\"] = df_normalized_scores_exper[\"Updating Task Session 09h00\"] / 36\n",
    "df_normalized_scores_exper[\"Updating Task Session 13h00\"] = df_normalized_scores_exper[\"Updating Task Session 13h00\"] / 36\n",
    "df_normalized_scores_exper[\"Updating Task Session 17h00\"] = df_normalized_scores_exper[\"Updating Task Session 17h00\"] / 36\n",
    "df_normalized_scores_exper[\"Updating Task Session 21h00\"] = df_normalized_scores_exper[\"Updating Task Session 21h00\"] / 36\n",
    "df_normalized_scores_exper[\"Symmetry Span Session 09h00\"] = df_normalized_scores_exper[\"Symmetry Span Session 09h00\"] / 20\n",
    "df_normalized_scores_exper[\"Symmetry Span Session 13h00\"] = df_normalized_scores_exper[\"Symmetry Span Session 13h00\"] / 20\n",
    "df_normalized_scores_exper[\"Symmetry Span Session 17h00\"] = df_normalized_scores_exper[\"Symmetry Span Session 17h00\"] / 20\n",
    "df_normalized_scores_exper[\"Symmetry Span Session 21h00\"] = df_normalized_scores_exper[\"Symmetry Span Session 21h00\"] / 20\n",
    "df_normalized_scores_exper[\"Binding Task Session 09h00\"] = df_normalized_scores_exper[\"Binding Task Session 09h00\"] / 12\n",
    "df_normalized_scores_exper[\"Binding Task Session 13h00\"] = df_normalized_scores_exper[\"Binding Task Session 13h00\"] / 12\n",
    "df_normalized_scores_exper[\"Binding Task Session 17h00\"] = df_normalized_scores_exper[\"Binding Task Session 17h00\"] / 12\n",
    "df_normalized_scores_exper[\"Binding Task Session 21h00\"] = df_normalized_scores_exper[\"Binding Task Session 21h00\"] / 12\n",
    "df_normalized_scores_exper[\"Operation Span Session 09h00\"] = df_normalized_scores_exper[\"Operation Span Session 09h00\"] / 20\n",
    "df_normalized_scores_exper[\"Operation Span Session 13h00\"] = df_normalized_scores_exper[\"Operation Span Session 13h00\"] / 20\n",
    "df_normalized_scores_exper[\"Operation Span Session 17h00\"] = df_normalized_scores_exper[\"Operation Span Session 17h00\"] / 20\n",
    "df_normalized_scores_exper[\"Operation Span Session 21h00\"] = df_normalized_scores_exper[\"Operation Span Session 21h00\"] / 20\n",
    "\n",
    "cols_to_round = [\n",
    "    \"Reading Span Session 09h00\",\n",
    "    \"Reading Span Session 13h00\",\n",
    "    \"Reading Span Session 17h00\",\n",
    "    \"Reading Span Session 21h00\",\n",
    "    \"Updating Task Session 09h00\",\n",
    "    \"Updating Task Session 13h00\",\n",
    "    \"Updating Task Session 17h00\",\n",
    "    \"Updating Task Session 21h00\",\n",
    "    \"Symmetry Span Session 09h00\",\n",
    "    \"Symmetry Span Session 13h00\",\n",
    "    \"Symmetry Span Session 17h00\",\n",
    "    \"Symmetry Span Session 21h00\",\n",
    "    \"Binding Task Session 09h00\",\n",
    "    \"Binding Task Session 13h00\",\n",
    "    \"Binding Task Session 17h00\",\n",
    "    \"Binding Task Session 21h00\",\n",
    "    \"Operation Span Session 09h00\",\n",
    "    \"Operation Span Session 13h00\",\n",
    "    \"Operation Span Session 17h00\",\n",
    "    \"Operation Span Session 21h00\",\n",
    "]\n",
    "\n",
    "df_normalized_scores_exper[cols_to_round] = (\n",
    "    df_normalized_scores_exper[cols_to_round]\n",
    "    .apply(pd.to_numeric, errors=\"coerce\")  # converts text to numbers safely\n",
    "    .round(2)  # rounds to 2 decimal places\n",
    ")\n",
    "\n",
    "pd.set_option(\"display.max_columns\",None)\n",
    "df_normalized_scores_exper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1b20e6",
   "metadata": {},
   "source": [
    "\n",
    "# 6. Downloading of viewing the final processed DBs\n",
    "Downloading of viewing the final processed DBs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4230b55a",
   "metadata": {},
   "source": [
    "## 6.1. Downloading DBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c1c3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "with pd.ExcelWriter('BD_all_data_combined.xlsx') as writer:\n",
    "    df_excel_Screening.to_excel(writer, sheet_name='Screening_Part', index=False)\n",
    "    SD_df_excel_data_part.to_excel(writer, sheet_name='Sleep Diary', index=False)\n",
    "    AD_df_excel_data_part.to_excel(writer, sheet_name='Activity Diary', index=False)\n",
    "    df_Actigraphy.to_excel(writer,sheet_name=\"Actigraphy\", index=False)\n",
    "    df_raw_scores_exper.to_excel(writer, sheet_name='Raw Scores', index=False)\n",
    "    df_normalized_scores_exper.to_excel(writer, sheet_name='Normalized Scores', index=False)\n",
    "    df_Reading_Span_Experimental.to_excel(writer, sheet_name='Reading Span', index=False)\n",
    "    df_WMU_Task_Experimental.to_excel(writer, sheet_name='Updating Task', index=False)\n",
    "    df_Symmetry_Span_Experimental.to_excel(writer, sheet_name='Symmetry Span', index=False)\n",
    "    df_Binding_Task_Experimental.to_excel(writer, sheet_name='Binding Task', index=False)\n",
    "    df_Operation_Span_Experimental.to_excel(writer, sheet_name='Operation Span', index=False)\n",
    "    df_raw_scores_pract.to_excel(writer, sheet_name='Practice Raw Scores', index=False)\n",
    "    df_normalized_scores_pract.to_excel(writer, sheet_name='Practice Normalized Scores', index=False)\n",
    "    df_Reading_Span_Practice.to_excel(writer, sheet_name='Practice RS', index=False)\n",
    "    df_WMU_Task_Practice.to_excel(writer, sheet_name='Practice UT', index=False)\n",
    "    df_Symmetry_Span_Practice.to_excel(writer, sheet_name='Practice SS', index=False)\n",
    "    df_Binding_Task_Practice.to_excel(writer, sheet_name='Practice BT', index=False)\n",
    "    df_Operation_Span_Practice.to_excel(writer, sheet_name='Practice OS', index=False)\n",
    "\n",
    "file_path = \"BD_all_data_combined.xlsx\"\n",
    "FileLink(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d574524",
   "metadata": {},
   "source": [
    "## 6.2. Viewing DBs one by one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5295b69",
   "metadata": {},
   "source": [
    "### 6.2.1 Screening DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f4f1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",None)\n",
    "df_excel_Screening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f1271a",
   "metadata": {},
   "source": [
    "### 6.2.2. Sleep Diaries DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",None)\n",
    "SD_df_excel_data_part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464eb2b7",
   "metadata": {},
   "source": [
    "### 6.2.3. Activity Diaries DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e055ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",None)\n",
    "AD_df_excel_data_part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d220dbf0",
   "metadata": {},
   "source": [
    "### 6.2.4. Actigraphy DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f23167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",None)\n",
    "df_Actigraphy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9736f65b",
   "metadata": {},
   "source": [
    "### 6.2.5. WM tasks experimental raw DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b255ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",None)\n",
    "df_raw_scores_exper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fbcdd2",
   "metadata": {},
   "source": [
    "### 6.2.6. WM tasks experimental normalized DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c3e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",None)\n",
    "df_normalized_scores_exper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46e574a",
   "metadata": {},
   "source": [
    "### 6.2.7. WM tasks practice raw DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7351fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",None)\n",
    "df_raw_scores_pract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f927d49",
   "metadata": {},
   "source": [
    "### 6.2.8. WM tasks practice normalized DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cab45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",None)\n",
    "df_normalized_scores_pract"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
